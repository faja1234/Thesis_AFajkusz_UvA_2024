{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:13:41.786830800Z",
     "start_time": "2024-05-22T16:13:37.129728Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "from models.dataset import LCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                               Customer ID  \\\nLoan ID                                                                      \n14dd8831-6af5-400b-83ec-68e61888a048  981165ec-3274-42f5-a3b4-d104041a9ca9   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a  e777faab-98ae-45af-9a86-7ce5b33b1011   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd  4ffe99d3-7f2a-44db-afc1-40943f1f9750   \n273581de-85d8-4332-81a5-19b04ce68666  90a75dde-34d5-419c-90dc-1e58b04b3e35   \n8af915d9-9e91-44a0-b5a2-564a45c12089  af534dea-d27e-4fd6-9de8-efaa52a78ec0   \n\n                                      Loan Status  Current Loan Amount  \\\nLoan ID                                                                  \n14dd8831-6af5-400b-83ec-68e61888a048   Fully Paid             445412.0   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a   Fully Paid             347666.0   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd  Charged Off             206602.0   \n273581de-85d8-4332-81a5-19b04ce68666   Fully Paid             217646.0   \n8af915d9-9e91-44a0-b5a2-564a45c12089   Fully Paid             548746.0   \n\n                                            Term  Credit Score  Annual Income  \\\nLoan ID                                                                         \n14dd8831-6af5-400b-83ec-68e61888a048  Short Term         709.0      1167493.0   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a   Long Term         721.0       806949.0   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd  Short Term        7290.0       896857.0   \n273581de-85d8-4332-81a5-19b04ce68666  Short Term         730.0      1184194.0   \n8af915d9-9e91-44a0-b5a2-564a45c12089  Short Term         678.0      2559110.0   \n\n                                     Home Ownership             Purpose  \\\nLoan ID                                                                   \n14dd8831-6af5-400b-83ec-68e61888a048  Home Mortgage   Home Improvements   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a       Own Home  Debt Consolidation   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd  Home Mortgage  Debt Consolidation   \n273581de-85d8-4332-81a5-19b04ce68666  Home Mortgage  Debt Consolidation   \n8af915d9-9e91-44a0-b5a2-564a45c12089           Rent  Debt Consolidation   \n\n                                      Monthly Debt  Years of Credit History  \\\nLoan ID                                                                       \n14dd8831-6af5-400b-83ec-68e61888a048       5214.74                     17.2   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a       8741.90                     12.0   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd      16367.74                     17.3   \n273581de-85d8-4332-81a5-19b04ce68666      10855.08                     19.6   \n8af915d9-9e91-44a0-b5a2-564a45c12089      18660.28                     22.6   \n\n                                      Number of Open Accounts  \\\nLoan ID                                                         \n14dd8831-6af5-400b-83ec-68e61888a048                      6.0   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a                      9.0   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd                      6.0   \n273581de-85d8-4332-81a5-19b04ce68666                     13.0   \n8af915d9-9e91-44a0-b5a2-564a45c12089                      4.0   \n\n                                      Number of Credit Problems  \\\nLoan ID                                                           \n14dd8831-6af5-400b-83ec-68e61888a048                        1.0   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a                        0.0   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd                        0.0   \n273581de-85d8-4332-81a5-19b04ce68666                        1.0   \n8af915d9-9e91-44a0-b5a2-564a45c12089                        0.0   \n\n                                      Current Credit Balance  \\\nLoan ID                                                        \n14dd8831-6af5-400b-83ec-68e61888a048                228190.0   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a                256329.0   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd                215308.0   \n273581de-85d8-4332-81a5-19b04ce68666                122170.0   \n8af915d9-9e91-44a0-b5a2-564a45c12089                437171.0   \n\n                                      Maximum Open Credit  Bankruptcies  \\\nLoan ID                                                                   \n14dd8831-6af5-400b-83ec-68e61888a048             416746.0           1.0   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a             386958.0           0.0   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd             272448.0           0.0   \n273581de-85d8-4332-81a5-19b04ce68666             272052.0           1.0   \n8af915d9-9e91-44a0-b5a2-564a45c12089             555038.0           0.0   \n\n                                      Tax Liens  loan_status_num  \nLoan ID                                                           \n14dd8831-6af5-400b-83ec-68e61888a048        0.0                0  \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a        0.0                0  \n89d8cb0c-e5c2-4f54-b056-48a645c543dd        0.0                1  \n273581de-85d8-4332-81a5-19b04ce68666        0.0                0  \n8af915d9-9e91-44a0-b5a2-564a45c12089        0.0                0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Customer ID</th>\n      <th>Loan Status</th>\n      <th>Current Loan Amount</th>\n      <th>Term</th>\n      <th>Credit Score</th>\n      <th>Annual Income</th>\n      <th>Home Ownership</th>\n      <th>Purpose</th>\n      <th>Monthly Debt</th>\n      <th>Years of Credit History</th>\n      <th>Number of Open Accounts</th>\n      <th>Number of Credit Problems</th>\n      <th>Current Credit Balance</th>\n      <th>Maximum Open Credit</th>\n      <th>Bankruptcies</th>\n      <th>Tax Liens</th>\n      <th>loan_status_num</th>\n    </tr>\n    <tr>\n      <th>Loan ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14dd8831-6af5-400b-83ec-68e61888a048</th>\n      <td>981165ec-3274-42f5-a3b4-d104041a9ca9</td>\n      <td>Fully Paid</td>\n      <td>445412.0</td>\n      <td>Short Term</td>\n      <td>709.0</td>\n      <td>1167493.0</td>\n      <td>Home Mortgage</td>\n      <td>Home Improvements</td>\n      <td>5214.74</td>\n      <td>17.2</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>228190.0</td>\n      <td>416746.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a</th>\n      <td>e777faab-98ae-45af-9a86-7ce5b33b1011</td>\n      <td>Fully Paid</td>\n      <td>347666.0</td>\n      <td>Long Term</td>\n      <td>721.0</td>\n      <td>806949.0</td>\n      <td>Own Home</td>\n      <td>Debt Consolidation</td>\n      <td>8741.90</td>\n      <td>12.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>256329.0</td>\n      <td>386958.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>89d8cb0c-e5c2-4f54-b056-48a645c543dd</th>\n      <td>4ffe99d3-7f2a-44db-afc1-40943f1f9750</td>\n      <td>Charged Off</td>\n      <td>206602.0</td>\n      <td>Short Term</td>\n      <td>7290.0</td>\n      <td>896857.0</td>\n      <td>Home Mortgage</td>\n      <td>Debt Consolidation</td>\n      <td>16367.74</td>\n      <td>17.3</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>215308.0</td>\n      <td>272448.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>273581de-85d8-4332-81a5-19b04ce68666</th>\n      <td>90a75dde-34d5-419c-90dc-1e58b04b3e35</td>\n      <td>Fully Paid</td>\n      <td>217646.0</td>\n      <td>Short Term</td>\n      <td>730.0</td>\n      <td>1184194.0</td>\n      <td>Home Mortgage</td>\n      <td>Debt Consolidation</td>\n      <td>10855.08</td>\n      <td>19.6</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>122170.0</td>\n      <td>272052.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8af915d9-9e91-44a0-b5a2-564a45c12089</th>\n      <td>af534dea-d27e-4fd6-9de8-efaa52a78ec0</td>\n      <td>Fully Paid</td>\n      <td>548746.0</td>\n      <td>Short Term</td>\n      <td>678.0</td>\n      <td>2559110.0</td>\n      <td>Rent</td>\n      <td>Debt Consolidation</td>\n      <td>18660.28</td>\n      <td>22.6</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>437171.0</td>\n      <td>555038.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('data/backup_data.pkl')\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:13:44.607812500Z",
     "start_time": "2024-05-22T16:13:44.509313500Z"
    }
   },
   "id": "3f55943d9a06710"
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "data": {
      "text/plain": "50028"
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['loan_status_num'].sum()\n",
    "66242-16214"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T21:25:13.797709Z",
     "start_time": "2024-05-23T21:25:13.563607200Z"
    }
   },
   "id": "dfe478989700d811"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data.drop(['Loan Status', 'Customer ID'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:13:45.761711900Z",
     "start_time": "2024-05-22T16:13:45.730446200Z"
    }
   },
   "id": "fdd194905fc1b189"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Term', 'Home Ownership', 'Purpose']\n"
     ]
    }
   ],
   "source": [
    "print([column for column in data.columns if data[column].dtype == object])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:14:11.150556300Z",
     "start_time": "2024-05-22T16:14:11.103470700Z"
    }
   },
   "id": "4072a1d5701d9351"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "dummies = ['Term', 'Home Ownership', 'Purpose']\n",
    "data = pd.get_dummies(data, columns=dummies, drop_first=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:14:11.923484Z",
     "start_time": "2024-05-22T16:14:11.860274700Z"
    }
   },
   "id": "d1fa6c4f1093b0f7"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                      Current Loan Amount  Credit Score  \\\nLoan ID                                                                   \n14dd8831-6af5-400b-83ec-68e61888a048             445412.0         709.0   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a             347666.0         721.0   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd             206602.0        7290.0   \n273581de-85d8-4332-81a5-19b04ce68666             217646.0         730.0   \n8af915d9-9e91-44a0-b5a2-564a45c12089             548746.0         678.0   \n\n                                      Annual Income  Monthly Debt  \\\nLoan ID                                                             \n14dd8831-6af5-400b-83ec-68e61888a048      1167493.0       5214.74   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a       806949.0       8741.90   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd       896857.0      16367.74   \n273581de-85d8-4332-81a5-19b04ce68666      1184194.0      10855.08   \n8af915d9-9e91-44a0-b5a2-564a45c12089      2559110.0      18660.28   \n\n                                      Years of Credit History  \\\nLoan ID                                                         \n14dd8831-6af5-400b-83ec-68e61888a048                     17.2   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a                     12.0   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd                     17.3   \n273581de-85d8-4332-81a5-19b04ce68666                     19.6   \n8af915d9-9e91-44a0-b5a2-564a45c12089                     22.6   \n\n                                      Number of Open Accounts  \\\nLoan ID                                                         \n14dd8831-6af5-400b-83ec-68e61888a048                      6.0   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a                      9.0   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd                      6.0   \n273581de-85d8-4332-81a5-19b04ce68666                     13.0   \n8af915d9-9e91-44a0-b5a2-564a45c12089                      4.0   \n\n                                      Number of Credit Problems  \\\nLoan ID                                                           \n14dd8831-6af5-400b-83ec-68e61888a048                        1.0   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a                        0.0   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd                        0.0   \n273581de-85d8-4332-81a5-19b04ce68666                        1.0   \n8af915d9-9e91-44a0-b5a2-564a45c12089                        0.0   \n\n                                      Current Credit Balance  \\\nLoan ID                                                        \n14dd8831-6af5-400b-83ec-68e61888a048                228190.0   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a                256329.0   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd                215308.0   \n273581de-85d8-4332-81a5-19b04ce68666                122170.0   \n8af915d9-9e91-44a0-b5a2-564a45c12089                437171.0   \n\n                                      Maximum Open Credit  Bankruptcies  ...  \\\nLoan ID                                                                  ...   \n14dd8831-6af5-400b-83ec-68e61888a048             416746.0           1.0  ...   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a             386958.0           0.0  ...   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd             272448.0           0.0  ...   \n273581de-85d8-4332-81a5-19b04ce68666             272052.0           1.0  ...   \n8af915d9-9e91-44a0-b5a2-564a45c12089             555038.0           0.0  ...   \n\n                                      Purpose_Medical Bills  Purpose_Other  \\\nLoan ID                                                                      \n14dd8831-6af5-400b-83ec-68e61888a048                      0              0   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a                      0              0   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd                      0              0   \n273581de-85d8-4332-81a5-19b04ce68666                      0              0   \n8af915d9-9e91-44a0-b5a2-564a45c12089                      0              0   \n\n                                      Purpose_Take a Trip  \\\nLoan ID                                                     \n14dd8831-6af5-400b-83ec-68e61888a048                    0   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a                    0   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd                    0   \n273581de-85d8-4332-81a5-19b04ce68666                    0   \n8af915d9-9e91-44a0-b5a2-564a45c12089                    0   \n\n                                      Purpose_major_purchase  Purpose_moving  \\\nLoan ID                                                                        \n14dd8831-6af5-400b-83ec-68e61888a048                       0               0   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a                       0               0   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd                       0               0   \n273581de-85d8-4332-81a5-19b04ce68666                       0               0   \n8af915d9-9e91-44a0-b5a2-564a45c12089                       0               0   \n\n                                      Purpose_other  Purpose_renewable_energy  \\\nLoan ID                                                                         \n14dd8831-6af5-400b-83ec-68e61888a048              0                         0   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a              0                         0   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd              0                         0   \n273581de-85d8-4332-81a5-19b04ce68666              0                         0   \n8af915d9-9e91-44a0-b5a2-564a45c12089              0                         0   \n\n                                      Purpose_small_business  \\\nLoan ID                                                        \n14dd8831-6af5-400b-83ec-68e61888a048                       0   \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a                       0   \n89d8cb0c-e5c2-4f54-b056-48a645c543dd                       0   \n273581de-85d8-4332-81a5-19b04ce68666                       0   \n8af915d9-9e91-44a0-b5a2-564a45c12089                       0   \n\n                                      Purpose_vacation  Purpose_wedding  \nLoan ID                                                                  \n14dd8831-6af5-400b-83ec-68e61888a048                 0                0  \n77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a                 0                0  \n89d8cb0c-e5c2-4f54-b056-48a645c543dd                 0                0  \n273581de-85d8-4332-81a5-19b04ce68666                 0                0  \n8af915d9-9e91-44a0-b5a2-564a45c12089                 0                0  \n\n[5 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Current Loan Amount</th>\n      <th>Credit Score</th>\n      <th>Annual Income</th>\n      <th>Monthly Debt</th>\n      <th>Years of Credit History</th>\n      <th>Number of Open Accounts</th>\n      <th>Number of Credit Problems</th>\n      <th>Current Credit Balance</th>\n      <th>Maximum Open Credit</th>\n      <th>Bankruptcies</th>\n      <th>...</th>\n      <th>Purpose_Medical Bills</th>\n      <th>Purpose_Other</th>\n      <th>Purpose_Take a Trip</th>\n      <th>Purpose_major_purchase</th>\n      <th>Purpose_moving</th>\n      <th>Purpose_other</th>\n      <th>Purpose_renewable_energy</th>\n      <th>Purpose_small_business</th>\n      <th>Purpose_vacation</th>\n      <th>Purpose_wedding</th>\n    </tr>\n    <tr>\n      <th>Loan ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14dd8831-6af5-400b-83ec-68e61888a048</th>\n      <td>445412.0</td>\n      <td>709.0</td>\n      <td>1167493.0</td>\n      <td>5214.74</td>\n      <td>17.2</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>228190.0</td>\n      <td>416746.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>77598f7b-32e7-4e3b-a6e5-06ba0d98fe8a</th>\n      <td>347666.0</td>\n      <td>721.0</td>\n      <td>806949.0</td>\n      <td>8741.90</td>\n      <td>12.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>256329.0</td>\n      <td>386958.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>89d8cb0c-e5c2-4f54-b056-48a645c543dd</th>\n      <td>206602.0</td>\n      <td>7290.0</td>\n      <td>896857.0</td>\n      <td>16367.74</td>\n      <td>17.3</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>215308.0</td>\n      <td>272448.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>273581de-85d8-4332-81a5-19b04ce68666</th>\n      <td>217646.0</td>\n      <td>730.0</td>\n      <td>1184194.0</td>\n      <td>10855.08</td>\n      <td>19.6</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>122170.0</td>\n      <td>272052.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8af915d9-9e91-44a0-b5a2-564a45c12089</th>\n      <td>548746.0</td>\n      <td>678.0</td>\n      <td>2559110.0</td>\n      <td>18660.28</td>\n      <td>22.6</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>437171.0</td>\n      <td>555038.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:14:12.293564900Z",
     "start_time": "2024-05-22T16:14:12.246083300Z"
    }
   },
   "id": "c0413e3432b521db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparing data for the models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5022a27542051ec8"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X = data.drop(columns=['loan_status_num'])\n",
    "y = data['loan_status_num']\n",
    "X_alt = data.drop(columns=['loan_status_num'])\n",
    "X_alt_train, X_alt_temp, y_alt_train, y_alt_temp = train_test_split(X_alt, y, test_size=0.3, random_state=42)\n",
    "X_train_extra, X_test_extra, y_train_extra, y_test_extra = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "scaler = StandardScaler()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:14:15.106001700Z",
     "start_time": "2024-05-22T16:14:15.024012600Z"
    }
   },
   "id": "211f9e7b83586ec4"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Split data into training (70%) and temp (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split temp into validation (10%) and temp2 (20%)\n",
    "X_validation, X_temp2, y_validation, y_temp2 = train_test_split(X_temp, y_temp, test_size=0.67, random_state=42)\n",
    "\n",
    "# Split temp2 into calibration (10%) and test (10%)\n",
    "X_calibration, X_test, y_calibration, y_test = train_test_split(X_temp2, y_temp2, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_validation_scaled = scaler.transform(X_validation)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_calibration_scaled = scaler.transform(X_calibration)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_validation_tensor = torch.tensor(X_validation_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "X_calibration_tensor = torch.tensor(X_calibration_scaled, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).reshape(len(y_train),1)\n",
    "y_validation_tensor = torch.tensor(y_validation.values, dtype=torch.float32).reshape(len(y_validation),1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).reshape(len(y_test),1)\n",
    "y_calibration_tensor = torch.tensor(y_calibration.values, dtype=torch.float32).reshape(len(y_calibration),1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:14:15.667682100Z",
     "start_time": "2024-05-22T16:14:15.547697300Z"
    }
   },
   "id": "fbf20d91657cb48c"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- Credit Score <= 3300.50\n",
      "|   |--- Term_Short Term <= 0.50\n",
      "|   |   |--- Annual Income <= 1405107.00\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- Annual Income >  1405107.00\n",
      "|   |   |   |--- class: 0\n",
      "|   |--- Term_Short Term >  0.50\n",
      "|   |   |--- Credit Score <= 745.50\n",
      "|   |   |   |--- class: 0\n",
      "|   |   |--- Credit Score >  745.50\n",
      "|   |   |   |--- class: 0\n",
      "|--- Credit Score >  3300.50\n",
      "|   |--- class: 1\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84     14976\n",
      "           1       0.50      0.44      0.47      4897\n",
      "\n",
      "    accuracy                           0.75     19873\n",
      "   macro avg       0.66      0.65      0.65     19873\n",
      "weighted avg       0.74      0.75      0.75     19873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "# Create an instance of DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier(max_depth=3, class_weight='balanced')\n",
    "# Fit the model using X_train and y_train\n",
    "dt_model.fit(X_train_extra, y_train_extra)\n",
    "# Get the rules of the decision tree\n",
    "tree_rules = export_text(dt_model, feature_names=list(X_train_extra.columns))\n",
    "print(tree_rules)\n",
    "# Use the trained model to make predictions\n",
    "predictions_extra = dt_model.predict(X_test_extra)\n",
    "\n",
    "class_report = classification_report(y_test_extra, predictions_extra)\n",
    "print(\"Classification Report:\\n\", class_report)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:32:10.472365200Z",
     "start_time": "2024-05-22T16:32:10.198633100Z"
    }
   },
   "id": "d94e656bcf411497"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "classlabels = torch.tensor(data['loan_status_num'].values, dtype=torch.long)\n",
    "class_counts = torch.bincount(classlabels)\n",
    "\n",
    "# Compute inverse class frequencies\n",
    "class_weights_original = 1.0 / class_counts.float()\n",
    "\n",
    "# Normalize class weights\n",
    "class_weights_original /= class_weights_original.sum()\n",
    "class_weights = class_weights_original[y_train_tensor.long()]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:30:01.183619400Z",
     "start_time": "2024-05-22T16:30:01.152110200Z"
    }
   },
   "id": "3a6d19cb201f032a"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def evaluate_nn(true, pred, train=True):\n",
    "    if train:\n",
    "        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")\n",
    "\n",
    "    elif train==False:\n",
    "        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")\n",
    "\n",
    "def plot_learning_evolution(r):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(r.history['loss'], label='Loss')\n",
    "    plt.plot(r.history['val_loss'], label='val_Loss')\n",
    "    plt.title('Loss evolution during trainig')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(r.history['AUC'], label='AUC')\n",
    "    plt.plot(r.history['val_AUC'], label='val_AUC')\n",
    "    plt.title('AUC score evolution during trainig')\n",
    "    plt.legend();\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:17:42.668015300Z",
     "start_time": "2024-05-22T16:17:42.652174800Z"
    }
   },
   "id": "8991d4a1e48357db"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19252f911d968649"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from models.model import Logistic_Regression, MLP\n",
    "from torchinfo import summary"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:17:43.971938100Z",
     "start_time": "2024-05-22T16:17:43.940242400Z"
    }
   },
   "id": "7f5c972556e5b5f4"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "30"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating number of features\n",
    "n_features=len(data.drop(columns=['loan_status_num']).columns)\n",
    "n_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:17:44.570855400Z",
     "start_time": "2024-05-22T16:17:44.524104600Z"
    }
   },
   "id": "38f23ce1b2a2f82c"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nLogistic_Regression                      [46369, 1]                --\n├─Sequential: 1-1                        [46369, 1]                --\n│    └─Linear: 2-1                       [46369, 1]                31\n│    └─Sigmoid: 2-2                      [46369, 1]                --\n==========================================================================================\nTotal params: 31\nTrainable params: 31\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 1.44\n==========================================================================================\nInput size (MB): 5.56\nForward/backward pass size (MB): 0.37\nParams size (MB): 0.00\nEstimated Total Size (MB): 5.94\n=========================================================================================="
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = Logistic_Regression(num_features=n_features)\n",
    "summary(lr_model, input_size=X_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:17:45.301918700Z",
     "start_time": "2024-05-22T16:17:45.207603900Z"
    }
   },
   "id": "933424173a1a4fc0"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 1000"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:17:46.704074300Z",
     "start_time": "2024-05-22T16:17:46.684168200Z"
    }
   },
   "id": "7772e5ddd18d638c"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "loss_function = nn.BCELoss(weight=class_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:17:47.869801400Z",
     "start_time": "2024-05-22T16:17:47.822076600Z"
    }
   },
   "id": "dc69282fac5d2988"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(lr_model.parameters(), lr=LEARNING_RATE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:17:51.493711300Z",
     "start_time": "2024-05-22T16:17:48.247305700Z"
    }
   },
   "id": "8d1b76cbcaf31fe1"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def calculate_accuracy(preds, actuals):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        rounded_preds = torch.round(preds)\n",
    "        num_correct = torch.sum(rounded_preds == actuals)\n",
    "        accuracy = num_correct/len(preds)\n",
    "\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:17:51.511235300Z",
     "start_time": "2024-05-22T16:17:51.500710400Z"
    }
   },
   "id": "6e9f25c0a8911a7"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t| Train loss: 0.274 \t| Train acc: 0.45 \t| Test acc: 0.46\n",
      "Epoch: 100 \t| Train loss: 0.217 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 200 \t| Train loss: 0.215 \t| Train acc: 0.75 \t| Test acc: 0.75\n",
      "Epoch: 300 \t| Train loss: 0.214 \t| Train acc: 0.75 \t| Test acc: 0.75\n",
      "Epoch: 400 \t| Train loss: 0.214 \t| Train acc: 0.75 \t| Test acc: 0.75\n",
      "Epoch: 500 \t| Train loss: 0.214 \t| Train acc: 0.75 \t| Test acc: 0.75\n",
      "Epoch: 600 \t| Train loss: 0.214 \t| Train acc: 0.75 \t| Test acc: 0.75\n",
      "Epoch: 700 \t| Train loss: 0.213 \t| Train acc: 0.75 \t| Test acc: 0.75\n",
      "Epoch: 800 \t| Train loss: 0.213 \t| Train acc: 0.75 \t| Test acc: 0.75\n",
      "Epoch: 900 \t| Train loss: 0.213 \t| Train acc: 0.75 \t| Test acc: 0.75\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "#test_losses  = []\n",
    "train_accs = []\n",
    "test_accs  = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Forward propagation (predicting train data) #a\n",
    "    train_preds = lr_model(X_train_tensor)\n",
    "    train_loss  = loss_function(train_preds, y_train_tensor)\n",
    "\n",
    "    # Predicting test data #b\n",
    "    with torch.no_grad():\n",
    "        test_preds = lr_model(X_validation_tensor)\n",
    "        #test_loss  = loss_function(test_preds, y_test)\n",
    "\n",
    "    # Calculate accuracy #c\n",
    "    train_acc = calculate_accuracy(train_preds, y_train_tensor)\n",
    "    test_acc  = calculate_accuracy(test_preds, y_validation_tensor)\n",
    "\n",
    "    # Backward propagation #d\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "\n",
    "    # Gradient descent step #e\n",
    "    optimizer.step()\n",
    "\n",
    "    # Store training history #f\n",
    "    train_losses.append(train_loss.item())\n",
    "    #test_losses.append(test_loss.item())\n",
    "    train_accs.append(train_acc.item())\n",
    "    test_accs.append(test_acc.item())\n",
    "\n",
    "    # Print training data #g\n",
    "    if epoch%100==0:\n",
    "        print(f'Epoch: {epoch} \\t|' \\\n",
    "              f' Train loss: {np.round(train_loss.item(),3)} \\t|' \\\n",
    "                  #f' Test loss: {np.round(test_loss.item(),3)} \\t|' \\\n",
    "              f' Train acc: {np.round(train_acc.item(),2)} \\t|' \\\n",
    "              f' Test acc: {np.round(test_acc.item(),2)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:17:56.085724600Z",
     "start_time": "2024-05-22T16:17:51.508211Z"
    }
   },
   "id": "c840057d48645d98"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 74.93%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0.0           1.0  accuracy     macro avg  weighted avg\n",
      "precision      0.827247      0.485347  0.749251      0.656297      0.743802\n",
      "recall         0.844688      0.453654  0.749251      0.649171      0.749251\n",
      "f1-score       0.835877      0.468966  0.749251      0.652421      0.746327\n",
      "support    35052.000000  11317.000000  0.749251  46369.000000  46369.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[29608  5444]\n",
      " [ 6183  5134]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 74.81%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.823926     0.494367  0.748094     0.659146      0.741762\n",
      "recall        0.845013     0.456269  0.748094     0.650641      0.748094\n",
      "f1-score      0.834336     0.474555  0.748094     0.654445      0.744638\n",
      "support    4923.000000  1635.000000  0.748094  6558.000000   6558.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[4160  763]\n",
      " [ 889  746]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_nn(y_train_tensor.clone().detach(), train_preds.clone().detach().round(), train=True)\n",
    "evaluate_nn(y_validation_tensor.clone().detach(), test_preds.clone().detach().round(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:17:57.465754300Z",
     "start_time": "2024-05-22T16:17:57.259038900Z"
    }
   },
   "id": "776cbb301a2ad576"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 75.77%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.832005     0.505611  0.757735     0.668808      0.752097\n",
      "recall        0.851034     0.469939  0.757735     0.660486      0.757735\n",
      "f1-score      0.841412     0.487122  0.757735     0.664267      0.754675\n",
      "support    5028.000000  1630.000000  0.757735  6658.000000   6658.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[4279  749]\n",
      " [ 864  766]]\n"
     ]
    }
   ],
   "source": [
    "test_preds_lr = lr_model(X_test_tensor)\n",
    "evaluate_nn(y_test_tensor.clone().detach(), test_preds_lr.clone().detach().round(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:17:58.986298600Z",
     "start_time": "2024-05-22T16:17:58.876508300Z"
    }
   },
   "id": "90adf75673abf94b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Semantic Loss in Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a094b7846ac6dbb"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "from importlib import reload  # Python 3.4+\n",
    "import models.loss\n",
    "reload(models.loss)\n",
    "from models.loss import semantic_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:33:21.824514100Z",
     "start_time": "2024-05-22T16:33:21.799239900Z"
    }
   },
   "id": "eab2ed83c8cf5c18"
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nLogistic_Regression                      [46369, 1]                --\n├─Sequential: 1-1                        [46369, 1]                --\n│    └─Linear: 2-1                       [46369, 1]                31\n│    └─Sigmoid: 2-2                      [46369, 1]                --\n==========================================================================================\nTotal params: 31\nTrainable params: 31\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 1.44\n==========================================================================================\nInput size (MB): 5.56\nForward/backward pass size (MB): 0.37\nParams size (MB): 0.00\nEstimated Total Size (MB): 5.94\n=========================================================================================="
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl_model = Logistic_Regression(num_features=n_features)\n",
    "summary(sl_model, input_size=X_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:35:40.081329200Z",
     "start_time": "2024-05-22T16:35:40.018551400Z"
    }
   },
   "id": "b07a59f30bddcb7f"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "optimizer_sl = optim.Adam(sl_model.parameters(), lr=LEARNING_RATE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:35:40.419425600Z",
     "start_time": "2024-05-22T16:35:40.418919400Z"
    }
   },
   "id": "d32814576148d7f9"
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "credit_score = torch.tensor(X_alt_train['Credit Score'].values, dtype=torch.float32).reshape(len(y_train),1)\n",
    "short_term = torch.tensor(X_alt_train['Term_Short Term'].values, dtype=torch.float32).reshape(len(y_train),1)\n",
    "annual_income = torch.tensor(X_alt_train['Annual Income'].values, dtype=torch.float32).reshape(len(y_train),1)\n",
    "\n",
    "rule=credit_score>3300.5\n",
    "rule = torch.logical_or(credit_score>3300.5, torch.logical_and(credit_score<=3300.5,torch.logical_and(short_term<=0.5, annual_income<=1405107)))\n",
    "rule=rule.float()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:35:40.746838600Z",
     "start_time": "2024-05-22T16:35:40.742368Z"
    }
   },
   "id": "c4008f210984379b"
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "print(rule)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:35:41.254433700Z",
     "start_time": "2024-05-22T16:35:41.212572900Z"
    }
   },
   "id": "c7e99e243e47b0ac"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t| Train loss: 0.198 \t| Train acc: 0.75 \t| Test acc: 0.75\n",
      "Epoch: 100 \t| Train loss: 0.198 \t| Train acc: 0.75 \t| Test acc: 0.75\n",
      "Epoch: 200 \t| Train loss: 0.198 \t| Train acc: 0.75 \t| Test acc: 0.75\n",
      "Epoch: 300 \t| Train loss: 0.198 \t| Train acc: 0.75 \t| Test acc: 0.75\n",
      "Epoch: 400 \t| Train loss: 0.198 \t| Train acc: 0.75 \t| Test acc: 0.75\n",
      "Epoch: 500 \t| Train loss: 0.198 \t| Train acc: 0.75 \t| Test acc: 0.75\n",
      "Epoch: 600 \t| Train loss: 0.198 \t| Train acc: 0.75 \t| Test acc: 0.75\n",
      "Epoch: 700 \t| Train loss: 0.198 \t| Train acc: 0.75 \t| Test acc: 0.75\n",
      "Epoch: 800 \t| Train loss: 0.198 \t| Train acc: 0.75 \t| Test acc: 0.75\n",
      "Epoch: 900 \t| Train loss: 0.198 \t| Train acc: 0.75 \t| Test acc: 0.75\n"
     ]
    }
   ],
   "source": [
    "train_losses_sl = []\n",
    "#test_losses  = []\n",
    "train_accs_sl = []\n",
    "test_accs_sl  = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Forward propagation (predicting train data) #a\n",
    "    train_preds = sl_model(X_train_tensor)\n",
    "    #train_loss  = loss_function(train_preds, y_train_tensor)\n",
    "    train_loss = semantic_loss(train_preds, y_train_tensor, rule, class_weights, 0.002)\n",
    "\n",
    "    # Predicting test data #b\n",
    "    with torch.no_grad():\n",
    "        test_preds = sl_model(X_validation_tensor)\n",
    "        #test_loss  = loss_function(test_preds, y_test)\n",
    "\n",
    "    # Calculate accuracy #c\n",
    "    train_acc = calculate_accuracy(train_preds, y_train_tensor)\n",
    "    test_acc  = calculate_accuracy(test_preds, y_validation_tensor)\n",
    "\n",
    "    # Backward propagation #d\n",
    "    optimizer_sl.zero_grad()\n",
    "    train_loss.backward()\n",
    "\n",
    "    # Gradient descent step #e\n",
    "    optimizer_sl.step()\n",
    "\n",
    "    # Store training history #f\n",
    "    train_losses_sl.append(train_loss.item())\n",
    "    #test_losses.append(test_loss.item())\n",
    "    train_accs_sl.append(train_acc.item())\n",
    "    test_accs_sl.append(test_acc.item())\n",
    "\n",
    "    # Print training data #g\n",
    "    if epoch%100==0:\n",
    "        print(f'Epoch: {epoch} \\t|' \\\n",
    "              f' Train loss: {np.round(train_loss.item(),3)} \\t|' \\\n",
    "                  #f' Test loss: {np.round(test_loss.item(),3)} \\t|' \\\n",
    "              f' Train acc: {np.round(train_acc.item(),2)} \\t|' \\\n",
    "              f' Test acc: {np.round(test_acc.item(),2)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:36:24.597812700Z",
     "start_time": "2024-05-22T16:36:17.539894700Z"
    }
   },
   "id": "1b84e380b59acca7"
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 75.03%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0.0           1.0  accuracy     macro avg  weighted avg\n",
      "precision      0.827127      0.487468  0.750264      0.657297      0.744228\n",
      "recall         0.846571      0.451975  0.750264      0.649273      0.750264\n",
      "f1-score       0.836736      0.469051  0.750264      0.652893      0.746997\n",
      "support    35052.000000  11317.000000  0.750264  46369.000000  46369.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[29674  5378]\n",
      " [ 6202  5115]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 74.76%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.823180     0.493342  0.747636     0.658261      0.740947\n",
      "recall        0.845419     0.453211  0.747636     0.649315      0.747636\n",
      "f1-score      0.834152     0.472426  0.747636     0.653289      0.743968\n",
      "support    4923.000000  1635.000000  0.747636  6558.000000   6558.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[4162  761]\n",
      " [ 894  741]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_nn(y_train_tensor.clone().detach(), train_preds.clone().detach().round(), train=True)\n",
    "evaluate_nn(y_validation_tensor.clone().detach(), test_preds.clone().detach().round(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:36:24.868292100Z",
     "start_time": "2024-05-22T16:36:24.605368Z"
    }
   },
   "id": "3f92651b92d8c86c"
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 75.74%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.831681     0.504957  0.757435     0.668319      0.751693\n",
      "recall        0.851034     0.468712  0.757435     0.659873      0.757435\n",
      "f1-score      0.841246     0.486160  0.757435     0.663703      0.754315\n",
      "support    5028.000000  1630.000000  0.757435  6658.000000   6658.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[4279  749]\n",
      " [ 866  764]]\n"
     ]
    }
   ],
   "source": [
    "test_preds_sl = sl_model(X_test_tensor)\n",
    "evaluate_nn(y_test_tensor.clone().detach(), test_preds_sl.clone().detach().round(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:36:24.961937Z",
     "start_time": "2024-05-22T16:36:24.867281900Z"
    }
   },
   "id": "6ec2bb6eba9b77db"
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([6658, 1])"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_sl.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:40:38.953880200Z",
     "start_time": "2024-05-22T16:40:38.906957300Z"
    }
   },
   "id": "76c1a6106f849dfa"
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "rounded_preds_lr = torch.round(test_preds_lr)\n",
    "rounded_preds_sl = torch.round(test_preds_sl)\n",
    "\n",
    "different_predictions = (rounded_preds_lr != rounded_preds_sl)\n",
    "\n",
    "correct_predictions_lr = (rounded_preds_lr == y_test_tensor)\n",
    "correct_predictions_sl = (rounded_preds_sl == y_test_tensor)\n",
    "\n",
    "different_and_correct_lr = different_predictions & correct_predictions_lr\n",
    "different_and_correct_sl = different_predictions & correct_predictions_sl\n",
    "\n",
    "#indices where predictions are different and correct\n",
    "indices_different_and_correct_lr = torch.nonzero(different_and_correct_lr).flatten()\n",
    "indices_different_and_correct_sl = torch.nonzero(different_and_correct_sl).flatten()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:40:39.720395200Z",
     "start_time": "2024-05-22T16:40:39.657369900Z"
    }
   },
   "id": "d6832e307d7e3c3b"
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "only_sl_correct = torch.nonzero(different_and_correct_sl.float(), as_tuple=True)[0].tolist()\n",
    "only_lr_correct = torch.nonzero(different_and_correct_lr.float(), as_tuple=True)[0].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T14:19:13.606399600Z",
     "start_time": "2024-05-14T14:19:13.590509900Z"
    }
   },
   "id": "aec1eec68eb181a1"
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "rule_matched = torch.nonzero(rule, as_tuple=True)[0].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T14:16:34.956919700Z",
     "start_time": "2024-05-14T14:16:34.917141Z"
    }
   },
   "id": "ebbce3782208f229"
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "intersection_sl = [value for value in only_sl_correct if value in rule_matched]\n",
    "intersection_lr = [value for value in only_lr_correct if value in rule_matched]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T14:19:15.518691400Z",
     "start_time": "2024-05-14T14:19:15.437466600Z"
    }
   },
   "id": "ddc92b0ad27b4b1d"
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "data": {
      "text/plain": "                                      Current Loan Amount  Credit Score  \\\nLoan ID                                                                   \nab6d8e46-e8cb-4980-bae1-7bc6f1f0a912             740630.0         703.0   \nf2277c45-c54d-4bb8-b7bb-dc8c1d89df0b             323378.0         720.0   \ne66b0417-b36e-4643-b5ed-1fb53a0bae19             742852.0         720.0   \nfcb91331-dce9-4e6e-be95-9e056becec97             330374.0         718.0   \nc1af70a8-674c-4ece-9a50-6af68335b77f             535282.0         703.0   \nec255dfa-03d3-4805-bb05-a20fe1d8d707             785400.0         672.0   \n0bdc2e51-140d-42ba-b106-be65bf37dbfd             285956.0         720.0   \nd66b4fa6-a10b-43da-9b57-f17cca4c7069             499708.0         720.0   \nb1e2dfba-39ab-46d8-ab14-3d5353040580             763070.0         588.0   \na8eb2a83-e5a1-403a-86de-736222403408             523666.0         715.0   \n1ba79d3c-6730-4961-b920-b90de10e77e8             464882.0         746.0   \n74461c5d-6ce0-4ad0-b599-bc4f822b1046             292424.0         712.0   \n8230ce2d-be3c-48e8-a7f9-e4e8d9fc615f             754072.0         656.0   \n8978ffbc-22ee-403d-977a-e1cb9c319715             176572.0         670.0   \n1fc85793-f560-45c3-b8a5-b371765e7bac             431508.0         724.0   \n867a712c-4718-44fd-babf-9896cfd38add             258962.0         706.0   \nfe5356b5-cd98-42b0-8897-e563921e38a7             281292.0         613.0   \nd109e834-ffb3-4c27-82e5-175a04b99375             261338.0         659.0   \n4c357314-d701-43d4-a804-cb2881f7f983             607926.0         684.0   \nd1e0f054-33b4-413e-b6c5-0f8440f1a612             647130.0         653.0   \n26a1e86e-5b97-4a31-880c-1836067461f7             353628.0         649.0   \ndd64b2c7-3c07-44ed-9627-cd167bf97f68             201322.0         725.0   \n2081fc5f-ab00-4bea-b64f-0908c4d67378             622072.0         723.0   \n58391bf7-ae4c-4d11-95df-abb79c7fc085             447964.0         692.0   \n8f6bb03e-fa56-4b12-ac17-74d788861b02             479952.0         687.0   \n07f1ee98-740c-43ed-b4e6-46a22d77dae4             228052.0         652.0   \nb6b1cbac-c421-4f21-95ce-1a5b29586e2f             770154.0         677.0   \n8e50d9b2-34e1-46d2-ac65-70e4b22306a9             572528.0         698.0   \n28f82b04-a6ae-4131-a6c7-da35c5a4b917             593516.0         662.0   \na2338edc-ff9b-4c33-a159-d5367f46583e             336688.0         718.0   \nbcf05407-7d4c-4332-8785-d2d110ddc8e8             259930.0         659.0   \n94e63949-43ac-4a82-b7dd-4174c47ea565             216920.0         714.0   \n71bb6310-c768-414c-8810-f5082ef1cf12             371074.0         705.0   \naae08768-5c66-432f-abcb-433bbe674c6f             217492.0         704.0   \nd4da85b8-99c8-40e6-afe1-c2d31e40c6dc             337128.0         733.0   \nd13b0970-bbad-48ef-be1e-0cb8a215e534             304062.0         714.0   \n9a101069-703d-4405-a876-1028fa499cec             553256.0         710.0   \n3f368d12-2300-40be-8d3e-b72624c81e93             327888.0         694.0   \n148ceb21-5843-4e02-a188-382e68f36708             731412.0         675.0   \n152cb89f-2c82-4a51-a8e5-96923c39f957             438416.0         620.0   \nbcf887e4-17ee-444d-8ca2-35627b090928             413820.0         723.0   \n75fefb08-4d65-42a6-ab40-64509bca0098             385902.0         706.0   \na537c4b2-593c-4614-9fae-0990ee21cc09             532532.0         724.0   \n3e9c9da6-63e2-4e9a-b94d-5e5ef2ba5525             376684.0         708.0   \n5b969699-e102-4913-82d7-e028ddf433b1             237006.0         608.0   \n1e492a8c-f330-4d92-838d-4809f6b2bc61             556226.0         721.0   \n1d99fdde-4142-460b-b5f7-b5bf5635adb3             386980.0         711.0   \n82c42bc6-562d-41b4-b86b-597dc358d7f2             392282.0         697.0   \ne0443aff-a676-47ea-bbdb-cbc5d3dae03c             232122.0         737.0   \nc0751426-d75d-4d43-aba5-5e1ebb3d7533              87252.0         652.0   \n2a500e91-940e-456e-b83c-e6ae40311c63             373890.0         689.0   \n0f6790df-236e-409d-9e43-d8c2db0bbbbe             292160.0         720.0   \n54d46716-0844-4198-b8f1-0f34cbb905cb             332222.0         743.0   \n8e98a87d-6cce-41ce-880c-ec0551cb10f2             472098.0         722.0   \n6db24023-a63a-4f62-8a1f-cab2c86dd5bc             473220.0         681.0   \nd0f06abc-edd8-4e38-ac3f-bc3a93380e6c             683782.0         692.0   \nf17c6b5c-018d-42ca-8a86-7596572e184f             556226.0         716.0   \n\n                                      Annual Income  Monthly Debt  \\\nLoan ID                                                             \nab6d8e46-e8cb-4980-bae1-7bc6f1f0a912      1391522.0      23075.88   \nf2277c45-c54d-4bb8-b7bb-dc8c1d89df0b      1219477.0       8526.25   \ne66b0417-b36e-4643-b5ed-1fb53a0bae19      1336954.0      27184.63   \nfcb91331-dce9-4e6e-be95-9e056becec97      2187413.0      57054.72   \nc1af70a8-674c-4ece-9a50-6af68335b77f      2696708.0      49664.29   \nec255dfa-03d3-4805-bb05-a20fe1d8d707      1414740.0      26691.58   \n0bdc2e51-140d-42ba-b106-be65bf37dbfd       858971.0      11596.08   \nd66b4fa6-a10b-43da-9b57-f17cca4c7069      1541280.0      27999.92   \nb1e2dfba-39ab-46d8-ab14-3d5353040580      2074952.0      67090.14   \na8eb2a83-e5a1-403a-86de-736222403408      1291924.0      35635.45   \n1ba79d3c-6730-4961-b920-b90de10e77e8      1635710.0      27125.54   \n74461c5d-6ce0-4ad0-b599-bc4f822b1046       956650.0      14509.16   \n8230ce2d-be3c-48e8-a7f9-e4e8d9fc615f      2307227.0      49413.30   \n8978ffbc-22ee-403d-977a-e1cb9c319715       812079.0       3694.93   \n1fc85793-f560-45c3-b8a5-b371765e7bac       931665.0      19099.18   \n867a712c-4718-44fd-babf-9896cfd38add       838679.0      21036.61   \nfe5356b5-cd98-42b0-8897-e563921e38a7       854069.0      10177.54   \nd109e834-ffb3-4c27-82e5-175a04b99375      1316567.0      28086.75   \n4c357314-d701-43d4-a804-cb2881f7f983      1912616.0      23748.29   \nd1e0f054-33b4-413e-b6c5-0f8440f1a612      1502463.0      25917.52   \n26a1e86e-5b97-4a31-880c-1836067461f7      1049807.0      23883.19   \ndd64b2c7-3c07-44ed-9627-cd167bf97f68       985283.0      12964.65   \n2081fc5f-ab00-4bea-b64f-0908c4d67378      1481867.0      21116.60   \n58391bf7-ae4c-4d11-95df-abb79c7fc085      1160634.0      19769.50   \n8f6bb03e-fa56-4b12-ac17-74d788861b02      1420060.0      26034.56   \n07f1ee98-740c-43ed-b4e6-46a22d77dae4      1247730.0      29529.80   \nb6b1cbac-c421-4f21-95ce-1a5b29586e2f      1805361.0      36257.70   \n8e50d9b2-34e1-46d2-ac65-70e4b22306a9      1431574.0      37101.87   \n28f82b04-a6ae-4131-a6c7-da35c5a4b917      1223220.0      17328.95   \na2338edc-ff9b-4c33-a159-d5367f46583e       852435.0      18114.22   \nbcf05407-7d4c-4332-8785-d2d110ddc8e8       467685.0       7482.96   \n94e63949-43ac-4a82-b7dd-4174c47ea565       655690.0      10982.76   \n71bb6310-c768-414c-8810-f5082ef1cf12       915648.0      21365.12   \naae08768-5c66-432f-abcb-433bbe674c6f      1145795.0      25302.68   \nd4da85b8-99c8-40e6-afe1-c2d31e40c6dc       795834.0       9019.49   \nd13b0970-bbad-48ef-be1e-0cb8a215e534      1162914.0      12501.43   \n9a101069-703d-4405-a876-1028fa499cec      1337847.0      28875.06   \n3f368d12-2300-40be-8d3e-b72624c81e93      1321412.0      20459.77   \n148ceb21-5843-4e02-a188-382e68f36708      1683210.0      33285.34   \n152cb89f-2c82-4a51-a8e5-96923c39f957       759164.0       9236.47   \nbcf887e4-17ee-444d-8ca2-35627b090928      1410750.0      22219.36   \n75fefb08-4d65-42a6-ab40-64509bca0098       929670.0      10226.37   \na537c4b2-593c-4614-9fae-0990ee21cc09       958170.0      23634.86   \n3e9c9da6-63e2-4e9a-b94d-5e5ef2ba5525      1207108.0      31887.89   \n5b969699-e102-4913-82d7-e028ddf433b1      1155846.0      14736.97   \n1e492a8c-f330-4d92-838d-4809f6b2bc61      2094408.0      26180.10   \n1d99fdde-4142-460b-b5f7-b5bf5635adb3       771628.0      19612.37   \n82c42bc6-562d-41b4-b86b-597dc358d7f2       959899.0      16318.15   \ne0443aff-a676-47ea-bbdb-cbc5d3dae03c       763724.0       9928.45   \nc0751426-d75d-4d43-aba5-5e1ebb3d7533       861954.0      21764.50   \n2a500e91-940e-456e-b83c-e6ae40311c63      1787501.0      41559.27   \n0f6790df-236e-409d-9e43-d8c2db0bbbbe       784985.0      11774.87   \n54d46716-0844-4198-b8f1-0f34cbb905cb      1491937.0      18524.81   \n8e98a87d-6cce-41ce-880c-ec0551cb10f2      2223912.0      31505.42   \n6db24023-a63a-4f62-8a1f-cab2c86dd5bc      1175891.0      27045.36   \nd0f06abc-edd8-4e38-ac3f-bc3a93380e6c      2077460.0      44319.21   \nf17c6b5c-018d-42ca-8a86-7596572e184f      2497911.0      53288.73   \n\n                                      Years of Credit History  \\\nLoan ID                                                         \nab6d8e46-e8cb-4980-bae1-7bc6f1f0a912                     19.0   \nf2277c45-c54d-4bb8-b7bb-dc8c1d89df0b                     15.9   \ne66b0417-b36e-4643-b5ed-1fb53a0bae19                     13.5   \nfcb91331-dce9-4e6e-be95-9e056becec97                     22.6   \nc1af70a8-674c-4ece-9a50-6af68335b77f                     22.6   \nec255dfa-03d3-4805-bb05-a20fe1d8d707                     17.5   \n0bdc2e51-140d-42ba-b106-be65bf37dbfd                     18.6   \nd66b4fa6-a10b-43da-9b57-f17cca4c7069                     18.2   \nb1e2dfba-39ab-46d8-ab14-3d5353040580                     15.9   \na8eb2a83-e5a1-403a-86de-736222403408                     15.3   \n1ba79d3c-6730-4961-b920-b90de10e77e8                     18.0   \n74461c5d-6ce0-4ad0-b599-bc4f822b1046                     20.4   \n8230ce2d-be3c-48e8-a7f9-e4e8d9fc615f                     21.5   \n8978ffbc-22ee-403d-977a-e1cb9c319715                     11.2   \n1fc85793-f560-45c3-b8a5-b371765e7bac                     18.4   \n867a712c-4718-44fd-babf-9896cfd38add                     12.5   \nfe5356b5-cd98-42b0-8897-e563921e38a7                     18.4   \nd109e834-ffb3-4c27-82e5-175a04b99375                     14.5   \n4c357314-d701-43d4-a804-cb2881f7f983                     21.5   \nd1e0f054-33b4-413e-b6c5-0f8440f1a612                     15.8   \n26a1e86e-5b97-4a31-880c-1836067461f7                     12.6   \ndd64b2c7-3c07-44ed-9627-cd167bf97f68                     21.5   \n2081fc5f-ab00-4bea-b64f-0908c4d67378                     16.9   \n58391bf7-ae4c-4d11-95df-abb79c7fc085                     24.2   \n8f6bb03e-fa56-4b12-ac17-74d788861b02                     22.3   \n07f1ee98-740c-43ed-b4e6-46a22d77dae4                     24.4   \nb6b1cbac-c421-4f21-95ce-1a5b29586e2f                     20.0   \n8e50d9b2-34e1-46d2-ac65-70e4b22306a9                     16.0   \n28f82b04-a6ae-4131-a6c7-da35c5a4b917                     16.6   \na2338edc-ff9b-4c33-a159-d5367f46583e                     16.5   \nbcf05407-7d4c-4332-8785-d2d110ddc8e8                      5.6   \n94e63949-43ac-4a82-b7dd-4174c47ea565                     23.6   \n71bb6310-c768-414c-8810-f5082ef1cf12                      9.0   \naae08768-5c66-432f-abcb-433bbe674c6f                     13.8   \nd4da85b8-99c8-40e6-afe1-c2d31e40c6dc                     20.7   \nd13b0970-bbad-48ef-be1e-0cb8a215e534                     15.5   \n9a101069-703d-4405-a876-1028fa499cec                     25.5   \n3f368d12-2300-40be-8d3e-b72624c81e93                     19.5   \n148ceb21-5843-4e02-a188-382e68f36708                     22.2   \n152cb89f-2c82-4a51-a8e5-96923c39f957                     10.4   \nbcf887e4-17ee-444d-8ca2-35627b090928                     20.4   \n75fefb08-4d65-42a6-ab40-64509bca0098                     11.3   \na537c4b2-593c-4614-9fae-0990ee21cc09                     14.8   \n3e9c9da6-63e2-4e9a-b94d-5e5ef2ba5525                     16.9   \n5b969699-e102-4913-82d7-e028ddf433b1                     18.4   \n1e492a8c-f330-4d92-838d-4809f6b2bc61                     13.5   \n1d99fdde-4142-460b-b5f7-b5bf5635adb3                     15.9   \n82c42bc6-562d-41b4-b86b-597dc358d7f2                     20.4   \ne0443aff-a676-47ea-bbdb-cbc5d3dae03c                     12.6   \nc0751426-d75d-4d43-aba5-5e1ebb3d7533                     13.9   \n2a500e91-940e-456e-b83c-e6ae40311c63                      8.2   \n0f6790df-236e-409d-9e43-d8c2db0bbbbe                     16.5   \n54d46716-0844-4198-b8f1-0f34cbb905cb                     13.0   \n8e98a87d-6cce-41ce-880c-ec0551cb10f2                     30.8   \n6db24023-a63a-4f62-8a1f-cab2c86dd5bc                     17.0   \nd0f06abc-edd8-4e38-ac3f-bc3a93380e6c                     22.9   \nf17c6b5c-018d-42ca-8a86-7596572e184f                     28.0   \n\n                                      Number of Open Accounts  \\\nLoan ID                                                         \nab6d8e46-e8cb-4980-bae1-7bc6f1f0a912                      9.0   \nf2277c45-c54d-4bb8-b7bb-dc8c1d89df0b                     13.0   \ne66b0417-b36e-4643-b5ed-1fb53a0bae19                     12.0   \nfcb91331-dce9-4e6e-be95-9e056becec97                     11.0   \nc1af70a8-674c-4ece-9a50-6af68335b77f                     24.0   \nec255dfa-03d3-4805-bb05-a20fe1d8d707                     10.0   \n0bdc2e51-140d-42ba-b106-be65bf37dbfd                     10.0   \nd66b4fa6-a10b-43da-9b57-f17cca4c7069                     13.0   \nb1e2dfba-39ab-46d8-ab14-3d5353040580                     28.0   \na8eb2a83-e5a1-403a-86de-736222403408                     13.0   \n1ba79d3c-6730-4961-b920-b90de10e77e8                     18.0   \n74461c5d-6ce0-4ad0-b599-bc4f822b1046                     14.0   \n8230ce2d-be3c-48e8-a7f9-e4e8d9fc615f                     10.0   \n8978ffbc-22ee-403d-977a-e1cb9c319715                      3.0   \n1fc85793-f560-45c3-b8a5-b371765e7bac                     11.0   \n867a712c-4718-44fd-babf-9896cfd38add                     16.0   \nfe5356b5-cd98-42b0-8897-e563921e38a7                      6.0   \nd109e834-ffb3-4c27-82e5-175a04b99375                     17.0   \n4c357314-d701-43d4-a804-cb2881f7f983                     10.0   \nd1e0f054-33b4-413e-b6c5-0f8440f1a612                     13.0   \n26a1e86e-5b97-4a31-880c-1836067461f7                     17.0   \ndd64b2c7-3c07-44ed-9627-cd167bf97f68                      6.0   \n2081fc5f-ab00-4bea-b64f-0908c4d67378                      8.0   \n58391bf7-ae4c-4d11-95df-abb79c7fc085                      8.0   \n8f6bb03e-fa56-4b12-ac17-74d788861b02                     23.0   \n07f1ee98-740c-43ed-b4e6-46a22d77dae4                     12.0   \nb6b1cbac-c421-4f21-95ce-1a5b29586e2f                     15.0   \n8e50d9b2-34e1-46d2-ac65-70e4b22306a9                     18.0   \n28f82b04-a6ae-4131-a6c7-da35c5a4b917                      6.0   \na2338edc-ff9b-4c33-a159-d5367f46583e                     17.0   \nbcf05407-7d4c-4332-8785-d2d110ddc8e8                      8.0   \n94e63949-43ac-4a82-b7dd-4174c47ea565                     21.0   \n71bb6310-c768-414c-8810-f5082ef1cf12                     12.0   \naae08768-5c66-432f-abcb-433bbe674c6f                     25.0   \nd4da85b8-99c8-40e6-afe1-c2d31e40c6dc                      9.0   \nd13b0970-bbad-48ef-be1e-0cb8a215e534                     11.0   \n9a101069-703d-4405-a876-1028fa499cec                     12.0   \n3f368d12-2300-40be-8d3e-b72624c81e93                      9.0   \n148ceb21-5843-4e02-a188-382e68f36708                     18.0   \n152cb89f-2c82-4a51-a8e5-96923c39f957                     13.0   \nbcf887e4-17ee-444d-8ca2-35627b090928                     10.0   \n75fefb08-4d65-42a6-ab40-64509bca0098                      8.0   \na537c4b2-593c-4614-9fae-0990ee21cc09                     15.0   \n3e9c9da6-63e2-4e9a-b94d-5e5ef2ba5525                      8.0   \n5b969699-e102-4913-82d7-e028ddf433b1                     14.0   \n1e492a8c-f330-4d92-838d-4809f6b2bc61                      9.0   \n1d99fdde-4142-460b-b5f7-b5bf5635adb3                      9.0   \n82c42bc6-562d-41b4-b86b-597dc358d7f2                     16.0   \ne0443aff-a676-47ea-bbdb-cbc5d3dae03c                      6.0   \nc0751426-d75d-4d43-aba5-5e1ebb3d7533                      8.0   \n2a500e91-940e-456e-b83c-e6ae40311c63                     21.0   \n0f6790df-236e-409d-9e43-d8c2db0bbbbe                      7.0   \n54d46716-0844-4198-b8f1-0f34cbb905cb                     17.0   \n8e98a87d-6cce-41ce-880c-ec0551cb10f2                     18.0   \n6db24023-a63a-4f62-8a1f-cab2c86dd5bc                     14.0   \nd0f06abc-edd8-4e38-ac3f-bc3a93380e6c                     14.0   \nf17c6b5c-018d-42ca-8a86-7596572e184f                      7.0   \n\n                                      Number of Credit Problems  \\\nLoan ID                                                           \nab6d8e46-e8cb-4980-bae1-7bc6f1f0a912                        0.0   \nf2277c45-c54d-4bb8-b7bb-dc8c1d89df0b                        0.0   \ne66b0417-b36e-4643-b5ed-1fb53a0bae19                        0.0   \nfcb91331-dce9-4e6e-be95-9e056becec97                        0.0   \nc1af70a8-674c-4ece-9a50-6af68335b77f                        0.0   \nec255dfa-03d3-4805-bb05-a20fe1d8d707                        0.0   \n0bdc2e51-140d-42ba-b106-be65bf37dbfd                        1.0   \nd66b4fa6-a10b-43da-9b57-f17cca4c7069                        0.0   \nb1e2dfba-39ab-46d8-ab14-3d5353040580                        0.0   \na8eb2a83-e5a1-403a-86de-736222403408                        0.0   \n1ba79d3c-6730-4961-b920-b90de10e77e8                        0.0   \n74461c5d-6ce0-4ad0-b599-bc4f822b1046                        0.0   \n8230ce2d-be3c-48e8-a7f9-e4e8d9fc615f                        0.0   \n8978ffbc-22ee-403d-977a-e1cb9c319715                        0.0   \n1fc85793-f560-45c3-b8a5-b371765e7bac                        0.0   \n867a712c-4718-44fd-babf-9896cfd38add                        1.0   \nfe5356b5-cd98-42b0-8897-e563921e38a7                        0.0   \nd109e834-ffb3-4c27-82e5-175a04b99375                        0.0   \n4c357314-d701-43d4-a804-cb2881f7f983                        0.0   \nd1e0f054-33b4-413e-b6c5-0f8440f1a612                        0.0   \n26a1e86e-5b97-4a31-880c-1836067461f7                        0.0   \ndd64b2c7-3c07-44ed-9627-cd167bf97f68                        0.0   \n2081fc5f-ab00-4bea-b64f-0908c4d67378                        0.0   \n58391bf7-ae4c-4d11-95df-abb79c7fc085                        0.0   \n8f6bb03e-fa56-4b12-ac17-74d788861b02                        0.0   \n07f1ee98-740c-43ed-b4e6-46a22d77dae4                        1.0   \nb6b1cbac-c421-4f21-95ce-1a5b29586e2f                        0.0   \n8e50d9b2-34e1-46d2-ac65-70e4b22306a9                        0.0   \n28f82b04-a6ae-4131-a6c7-da35c5a4b917                        0.0   \na2338edc-ff9b-4c33-a159-d5367f46583e                        0.0   \nbcf05407-7d4c-4332-8785-d2d110ddc8e8                        0.0   \n94e63949-43ac-4a82-b7dd-4174c47ea565                        0.0   \n71bb6310-c768-414c-8810-f5082ef1cf12                        0.0   \naae08768-5c66-432f-abcb-433bbe674c6f                        0.0   \nd4da85b8-99c8-40e6-afe1-c2d31e40c6dc                        0.0   \nd13b0970-bbad-48ef-be1e-0cb8a215e534                        1.0   \n9a101069-703d-4405-a876-1028fa499cec                        0.0   \n3f368d12-2300-40be-8d3e-b72624c81e93                        0.0   \n148ceb21-5843-4e02-a188-382e68f36708                        0.0   \n152cb89f-2c82-4a51-a8e5-96923c39f957                        0.0   \nbcf887e4-17ee-444d-8ca2-35627b090928                        1.0   \n75fefb08-4d65-42a6-ab40-64509bca0098                        0.0   \na537c4b2-593c-4614-9fae-0990ee21cc09                        0.0   \n3e9c9da6-63e2-4e9a-b94d-5e5ef2ba5525                        0.0   \n5b969699-e102-4913-82d7-e028ddf433b1                        1.0   \n1e492a8c-f330-4d92-838d-4809f6b2bc61                        0.0   \n1d99fdde-4142-460b-b5f7-b5bf5635adb3                        0.0   \n82c42bc6-562d-41b4-b86b-597dc358d7f2                        1.0   \ne0443aff-a676-47ea-bbdb-cbc5d3dae03c                        0.0   \nc0751426-d75d-4d43-aba5-5e1ebb3d7533                        0.0   \n2a500e91-940e-456e-b83c-e6ae40311c63                        1.0   \n0f6790df-236e-409d-9e43-d8c2db0bbbbe                        0.0   \n54d46716-0844-4198-b8f1-0f34cbb905cb                        0.0   \n8e98a87d-6cce-41ce-880c-ec0551cb10f2                        0.0   \n6db24023-a63a-4f62-8a1f-cab2c86dd5bc                        0.0   \nd0f06abc-edd8-4e38-ac3f-bc3a93380e6c                        0.0   \nf17c6b5c-018d-42ca-8a86-7596572e184f                        0.0   \n\n                                      Current Credit Balance  \\\nLoan ID                                                        \nab6d8e46-e8cb-4980-bae1-7bc6f1f0a912                476007.0   \nf2277c45-c54d-4bb8-b7bb-dc8c1d89df0b                260585.0   \ne66b0417-b36e-4643-b5ed-1fb53a0bae19                314412.0   \nfcb91331-dce9-4e6e-be95-9e056becec97                957600.0   \nc1af70a8-674c-4ece-9a50-6af68335b77f                387695.0   \nec255dfa-03d3-4805-bb05-a20fe1d8d707                439318.0   \n0bdc2e51-140d-42ba-b106-be65bf37dbfd                126122.0   \nd66b4fa6-a10b-43da-9b57-f17cca4c7069                766327.0   \nb1e2dfba-39ab-46d8-ab14-3d5353040580               2266016.0   \na8eb2a83-e5a1-403a-86de-736222403408                322221.0   \n1ba79d3c-6730-4961-b920-b90de10e77e8                 78603.0   \n74461c5d-6ce0-4ad0-b599-bc4f822b1046                388037.0   \n8230ce2d-be3c-48e8-a7f9-e4e8d9fc615f                643302.0   \n8978ffbc-22ee-403d-977a-e1cb9c319715                142386.0   \n1fc85793-f560-45c3-b8a5-b371765e7bac                211584.0   \n867a712c-4718-44fd-babf-9896cfd38add                 77140.0   \nfe5356b5-cd98-42b0-8897-e563921e38a7                 36195.0   \nd109e834-ffb3-4c27-82e5-175a04b99375                135318.0   \n4c357314-d701-43d4-a804-cb2881f7f983                 96805.0   \nd1e0f054-33b4-413e-b6c5-0f8440f1a612                564870.0   \n26a1e86e-5b97-4a31-880c-1836067461f7                385567.0   \ndd64b2c7-3c07-44ed-9627-cd167bf97f68                143507.0   \n2081fc5f-ab00-4bea-b64f-0908c4d67378                506008.0   \n58391bf7-ae4c-4d11-95df-abb79c7fc085                277837.0   \n8f6bb03e-fa56-4b12-ac17-74d788861b02                292106.0   \n07f1ee98-740c-43ed-b4e6-46a22d77dae4                  8569.0   \nb6b1cbac-c421-4f21-95ce-1a5b29586e2f                547010.0   \n8e50d9b2-34e1-46d2-ac65-70e4b22306a9                654588.0   \n28f82b04-a6ae-4131-a6c7-da35c5a4b917                318269.0   \na2338edc-ff9b-4c33-a159-d5367f46583e                120346.0   \nbcf05407-7d4c-4332-8785-d2d110ddc8e8                254106.0   \n94e63949-43ac-4a82-b7dd-4174c47ea565                147554.0   \n71bb6310-c768-414c-8810-f5082ef1cf12                417240.0   \naae08768-5c66-432f-abcb-433bbe674c6f                643302.0   \nd4da85b8-99c8-40e6-afe1-c2d31e40c6dc                311790.0   \nd13b0970-bbad-48ef-be1e-0cb8a215e534                156997.0   \n9a101069-703d-4405-a876-1028fa499cec                330733.0   \n3f368d12-2300-40be-8d3e-b72624c81e93                263587.0   \n148ceb21-5843-4e02-a188-382e68f36708               1013308.0   \n152cb89f-2c82-4a51-a8e5-96923c39f957                416214.0   \nbcf887e4-17ee-444d-8ca2-35627b090928                210121.0   \n75fefb08-4d65-42a6-ab40-64509bca0098                 92568.0   \na537c4b2-593c-4614-9fae-0990ee21cc09                340784.0   \n3e9c9da6-63e2-4e9a-b94d-5e5ef2ba5525                211717.0   \n5b969699-e102-4913-82d7-e028ddf433b1                134254.0   \n1e492a8c-f330-4d92-838d-4809f6b2bc61                356782.0   \n1d99fdde-4142-460b-b5f7-b5bf5635adb3                156541.0   \n82c42bc6-562d-41b4-b86b-597dc358d7f2                645734.0   \ne0443aff-a676-47ea-bbdb-cbc5d3dae03c                 16872.0   \nc0751426-d75d-4d43-aba5-5e1ebb3d7533                411958.0   \n2a500e91-940e-456e-b83c-e6ae40311c63                178353.0   \n0f6790df-236e-409d-9e43-d8c2db0bbbbe                308389.0   \n54d46716-0844-4198-b8f1-0f34cbb905cb                111169.0   \n8e98a87d-6cce-41ce-880c-ec0551cb10f2                514178.0   \n6db24023-a63a-4f62-8a1f-cab2c86dd5bc                567967.0   \nd0f06abc-edd8-4e38-ac3f-bc3a93380e6c                413345.0   \nf17c6b5c-018d-42ca-8a86-7596572e184f                719891.0   \n\n                                      Maximum Open Credit  Bankruptcies  ...  \\\nLoan ID                                                                  ...   \nab6d8e46-e8cb-4980-bae1-7bc6f1f0a912            1003948.0           0.0  ...   \nf2277c45-c54d-4bb8-b7bb-dc8c1d89df0b             514888.0           0.0  ...   \ne66b0417-b36e-4643-b5ed-1fb53a0bae19            1106534.0           0.0  ...   \nfcb91331-dce9-4e6e-be95-9e056becec97            1152624.0           0.0  ...   \nc1af70a8-674c-4ece-9a50-6af68335b77f             722876.0           0.0  ...   \nec255dfa-03d3-4805-bb05-a20fe1d8d707             594946.0           0.0  ...   \n0bdc2e51-140d-42ba-b106-be65bf37dbfd             260788.0           1.0  ...   \nd66b4fa6-a10b-43da-9b57-f17cca4c7069            1039016.0           0.0  ...   \nb1e2dfba-39ab-46d8-ab14-3d5353040580            3604128.0           0.0  ...   \na8eb2a83-e5a1-403a-86de-736222403408             669812.0           0.0  ...   \n1ba79d3c-6730-4961-b920-b90de10e77e8            2459974.0           0.0  ...   \n74461c5d-6ce0-4ad0-b599-bc4f822b1046             591206.0           0.0  ...   \n8230ce2d-be3c-48e8-a7f9-e4e8d9fc615f            1225136.0           0.0  ...   \n8978ffbc-22ee-403d-977a-e1cb9c319715             291280.0           0.0  ...   \n1fc85793-f560-45c3-b8a5-b371765e7bac             539616.0           0.0  ...   \n867a712c-4718-44fd-babf-9896cfd38add             620268.0           1.0  ...   \nfe5356b5-cd98-42b0-8897-e563921e38a7              54912.0           0.0  ...   \nd109e834-ffb3-4c27-82e5-175a04b99375             307252.0           0.0  ...   \n4c357314-d701-43d4-a804-cb2881f7f983             737484.0           0.0  ...   \nd1e0f054-33b4-413e-b6c5-0f8440f1a612             964678.0           0.0  ...   \n26a1e86e-5b97-4a31-880c-1836067461f7             539176.0           0.0  ...   \ndd64b2c7-3c07-44ed-9627-cd167bf97f68             230450.0           0.0  ...   \n2081fc5f-ab00-4bea-b64f-0908c4d67378            1069178.0           0.0  ...   \n58391bf7-ae4c-4d11-95df-abb79c7fc085             951786.0           0.0  ...   \n8f6bb03e-fa56-4b12-ac17-74d788861b02            1386198.0           0.0  ...   \n07f1ee98-740c-43ed-b4e6-46a22d77dae4             132396.0           1.0  ...   \nb6b1cbac-c421-4f21-95ce-1a5b29586e2f             697532.0           0.0  ...   \n8e50d9b2-34e1-46d2-ac65-70e4b22306a9            1045440.0           0.0  ...   \n28f82b04-a6ae-4131-a6c7-da35c5a4b917             391204.0           0.0  ...   \na2338edc-ff9b-4c33-a159-d5367f46583e             881936.0           0.0  ...   \nbcf05407-7d4c-4332-8785-d2d110ddc8e8             610412.0           0.0  ...   \n94e63949-43ac-4a82-b7dd-4174c47ea565             223322.0           0.0  ...   \n71bb6310-c768-414c-8810-f5082ef1cf12             495022.0           0.0  ...   \naae08768-5c66-432f-abcb-433bbe674c6f            1171170.0           0.0  ...   \nd4da85b8-99c8-40e6-afe1-c2d31e40c6dc            1093994.0           0.0  ...   \nd13b0970-bbad-48ef-be1e-0cb8a215e534             319484.0           1.0  ...   \n9a101069-703d-4405-a876-1028fa499cec             692516.0           0.0  ...   \n3f368d12-2300-40be-8d3e-b72624c81e93             384868.0           0.0  ...   \n148ceb21-5843-4e02-a188-382e68f36708            1859418.0           0.0  ...   \n152cb89f-2c82-4a51-a8e5-96923c39f957             912736.0           0.0  ...   \nbcf887e4-17ee-444d-8ca2-35627b090928             494516.0           1.0  ...   \n75fefb08-4d65-42a6-ab40-64509bca0098             275550.0           0.0  ...   \na537c4b2-593c-4614-9fae-0990ee21cc09             621412.0           0.0  ...   \n3e9c9da6-63e2-4e9a-b94d-5e5ef2ba5525             453970.0           0.0  ...   \n5b969699-e102-4913-82d7-e028ddf433b1             352506.0           1.0  ...   \n1e492a8c-f330-4d92-838d-4809f6b2bc61             545006.0           0.0  ...   \n1d99fdde-4142-460b-b5f7-b5bf5635adb3             366190.0           0.0  ...   \n82c42bc6-562d-41b4-b86b-597dc358d7f2            1028478.0           0.0  ...   \ne0443aff-a676-47ea-bbdb-cbc5d3dae03c             257158.0           0.0  ...   \nc0751426-d75d-4d43-aba5-5e1ebb3d7533             560516.0           0.0  ...   \n2a500e91-940e-456e-b83c-e6ae40311c63             300608.0           1.0  ...   \n0f6790df-236e-409d-9e43-d8c2db0bbbbe             393690.0           0.0  ...   \n54d46716-0844-4198-b8f1-0f34cbb905cb             436348.0           0.0  ...   \n8e98a87d-6cce-41ce-880c-ec0551cb10f2            1102552.0           0.0  ...   \n6db24023-a63a-4f62-8a1f-cab2c86dd5bc             815936.0           0.0  ...   \nd0f06abc-edd8-4e38-ac3f-bc3a93380e6c             720786.0           0.0  ...   \nf17c6b5c-018d-42ca-8a86-7596572e184f             913990.0           0.0  ...   \n\n                                      Purpose_Medical Bills  Purpose_Other  \\\nLoan ID                                                                      \nab6d8e46-e8cb-4980-bae1-7bc6f1f0a912                      0              0   \nf2277c45-c54d-4bb8-b7bb-dc8c1d89df0b                      0              0   \ne66b0417-b36e-4643-b5ed-1fb53a0bae19                      0              0   \nfcb91331-dce9-4e6e-be95-9e056becec97                      0              0   \nc1af70a8-674c-4ece-9a50-6af68335b77f                      0              0   \nec255dfa-03d3-4805-bb05-a20fe1d8d707                      0              0   \n0bdc2e51-140d-42ba-b106-be65bf37dbfd                      0              0   \nd66b4fa6-a10b-43da-9b57-f17cca4c7069                      0              0   \nb1e2dfba-39ab-46d8-ab14-3d5353040580                      0              0   \na8eb2a83-e5a1-403a-86de-736222403408                      0              0   \n1ba79d3c-6730-4961-b920-b90de10e77e8                      0              0   \n74461c5d-6ce0-4ad0-b599-bc4f822b1046                      0              0   \n8230ce2d-be3c-48e8-a7f9-e4e8d9fc615f                      0              0   \n8978ffbc-22ee-403d-977a-e1cb9c319715                      0              0   \n1fc85793-f560-45c3-b8a5-b371765e7bac                      0              0   \n867a712c-4718-44fd-babf-9896cfd38add                      0              0   \nfe5356b5-cd98-42b0-8897-e563921e38a7                      0              0   \nd109e834-ffb3-4c27-82e5-175a04b99375                      0              0   \n4c357314-d701-43d4-a804-cb2881f7f983                      0              0   \nd1e0f054-33b4-413e-b6c5-0f8440f1a612                      0              0   \n26a1e86e-5b97-4a31-880c-1836067461f7                      0              0   \ndd64b2c7-3c07-44ed-9627-cd167bf97f68                      0              0   \n2081fc5f-ab00-4bea-b64f-0908c4d67378                      0              0   \n58391bf7-ae4c-4d11-95df-abb79c7fc085                      0              0   \n8f6bb03e-fa56-4b12-ac17-74d788861b02                      0              0   \n07f1ee98-740c-43ed-b4e6-46a22d77dae4                      0              0   \nb6b1cbac-c421-4f21-95ce-1a5b29586e2f                      0              0   \n8e50d9b2-34e1-46d2-ac65-70e4b22306a9                      0              0   \n28f82b04-a6ae-4131-a6c7-da35c5a4b917                      0              0   \na2338edc-ff9b-4c33-a159-d5367f46583e                      0              0   \nbcf05407-7d4c-4332-8785-d2d110ddc8e8                      0              0   \n94e63949-43ac-4a82-b7dd-4174c47ea565                      0              0   \n71bb6310-c768-414c-8810-f5082ef1cf12                      0              0   \naae08768-5c66-432f-abcb-433bbe674c6f                      0              0   \nd4da85b8-99c8-40e6-afe1-c2d31e40c6dc                      0              0   \nd13b0970-bbad-48ef-be1e-0cb8a215e534                      0              0   \n9a101069-703d-4405-a876-1028fa499cec                      0              0   \n3f368d12-2300-40be-8d3e-b72624c81e93                      0              0   \n148ceb21-5843-4e02-a188-382e68f36708                      0              0   \n152cb89f-2c82-4a51-a8e5-96923c39f957                      0              0   \nbcf887e4-17ee-444d-8ca2-35627b090928                      0              0   \n75fefb08-4d65-42a6-ab40-64509bca0098                      0              0   \na537c4b2-593c-4614-9fae-0990ee21cc09                      0              0   \n3e9c9da6-63e2-4e9a-b94d-5e5ef2ba5525                      0              0   \n5b969699-e102-4913-82d7-e028ddf433b1                      0              0   \n1e492a8c-f330-4d92-838d-4809f6b2bc61                      0              0   \n1d99fdde-4142-460b-b5f7-b5bf5635adb3                      0              0   \n82c42bc6-562d-41b4-b86b-597dc358d7f2                      0              0   \ne0443aff-a676-47ea-bbdb-cbc5d3dae03c                      0              0   \nc0751426-d75d-4d43-aba5-5e1ebb3d7533                      0              0   \n2a500e91-940e-456e-b83c-e6ae40311c63                      0              0   \n0f6790df-236e-409d-9e43-d8c2db0bbbbe                      0              0   \n54d46716-0844-4198-b8f1-0f34cbb905cb                      0              0   \n8e98a87d-6cce-41ce-880c-ec0551cb10f2                      0              0   \n6db24023-a63a-4f62-8a1f-cab2c86dd5bc                      0              0   \nd0f06abc-edd8-4e38-ac3f-bc3a93380e6c                      0              0   \nf17c6b5c-018d-42ca-8a86-7596572e184f                      0              0   \n\n                                      Purpose_Take a Trip  \\\nLoan ID                                                     \nab6d8e46-e8cb-4980-bae1-7bc6f1f0a912                    0   \nf2277c45-c54d-4bb8-b7bb-dc8c1d89df0b                    0   \ne66b0417-b36e-4643-b5ed-1fb53a0bae19                    0   \nfcb91331-dce9-4e6e-be95-9e056becec97                    0   \nc1af70a8-674c-4ece-9a50-6af68335b77f                    0   \nec255dfa-03d3-4805-bb05-a20fe1d8d707                    0   \n0bdc2e51-140d-42ba-b106-be65bf37dbfd                    0   \nd66b4fa6-a10b-43da-9b57-f17cca4c7069                    0   \nb1e2dfba-39ab-46d8-ab14-3d5353040580                    0   \na8eb2a83-e5a1-403a-86de-736222403408                    0   \n1ba79d3c-6730-4961-b920-b90de10e77e8                    0   \n74461c5d-6ce0-4ad0-b599-bc4f822b1046                    0   \n8230ce2d-be3c-48e8-a7f9-e4e8d9fc615f                    0   \n8978ffbc-22ee-403d-977a-e1cb9c319715                    0   \n1fc85793-f560-45c3-b8a5-b371765e7bac                    0   \n867a712c-4718-44fd-babf-9896cfd38add                    0   \nfe5356b5-cd98-42b0-8897-e563921e38a7                    0   \nd109e834-ffb3-4c27-82e5-175a04b99375                    0   \n4c357314-d701-43d4-a804-cb2881f7f983                    0   \nd1e0f054-33b4-413e-b6c5-0f8440f1a612                    0   \n26a1e86e-5b97-4a31-880c-1836067461f7                    0   \ndd64b2c7-3c07-44ed-9627-cd167bf97f68                    0   \n2081fc5f-ab00-4bea-b64f-0908c4d67378                    0   \n58391bf7-ae4c-4d11-95df-abb79c7fc085                    0   \n8f6bb03e-fa56-4b12-ac17-74d788861b02                    0   \n07f1ee98-740c-43ed-b4e6-46a22d77dae4                    0   \nb6b1cbac-c421-4f21-95ce-1a5b29586e2f                    0   \n8e50d9b2-34e1-46d2-ac65-70e4b22306a9                    0   \n28f82b04-a6ae-4131-a6c7-da35c5a4b917                    0   \na2338edc-ff9b-4c33-a159-d5367f46583e                    0   \nbcf05407-7d4c-4332-8785-d2d110ddc8e8                    0   \n94e63949-43ac-4a82-b7dd-4174c47ea565                    0   \n71bb6310-c768-414c-8810-f5082ef1cf12                    0   \naae08768-5c66-432f-abcb-433bbe674c6f                    0   \nd4da85b8-99c8-40e6-afe1-c2d31e40c6dc                    0   \nd13b0970-bbad-48ef-be1e-0cb8a215e534                    0   \n9a101069-703d-4405-a876-1028fa499cec                    0   \n3f368d12-2300-40be-8d3e-b72624c81e93                    0   \n148ceb21-5843-4e02-a188-382e68f36708                    0   \n152cb89f-2c82-4a51-a8e5-96923c39f957                    0   \nbcf887e4-17ee-444d-8ca2-35627b090928                    0   \n75fefb08-4d65-42a6-ab40-64509bca0098                    0   \na537c4b2-593c-4614-9fae-0990ee21cc09                    0   \n3e9c9da6-63e2-4e9a-b94d-5e5ef2ba5525                    0   \n5b969699-e102-4913-82d7-e028ddf433b1                    0   \n1e492a8c-f330-4d92-838d-4809f6b2bc61                    0   \n1d99fdde-4142-460b-b5f7-b5bf5635adb3                    0   \n82c42bc6-562d-41b4-b86b-597dc358d7f2                    0   \ne0443aff-a676-47ea-bbdb-cbc5d3dae03c                    0   \nc0751426-d75d-4d43-aba5-5e1ebb3d7533                    0   \n2a500e91-940e-456e-b83c-e6ae40311c63                    0   \n0f6790df-236e-409d-9e43-d8c2db0bbbbe                    0   \n54d46716-0844-4198-b8f1-0f34cbb905cb                    0   \n8e98a87d-6cce-41ce-880c-ec0551cb10f2                    0   \n6db24023-a63a-4f62-8a1f-cab2c86dd5bc                    0   \nd0f06abc-edd8-4e38-ac3f-bc3a93380e6c                    0   \nf17c6b5c-018d-42ca-8a86-7596572e184f                    0   \n\n                                      Purpose_major_purchase  Purpose_moving  \\\nLoan ID                                                                        \nab6d8e46-e8cb-4980-bae1-7bc6f1f0a912                       0               0   \nf2277c45-c54d-4bb8-b7bb-dc8c1d89df0b                       0               0   \ne66b0417-b36e-4643-b5ed-1fb53a0bae19                       0               0   \nfcb91331-dce9-4e6e-be95-9e056becec97                       0               0   \nc1af70a8-674c-4ece-9a50-6af68335b77f                       0               0   \nec255dfa-03d3-4805-bb05-a20fe1d8d707                       0               0   \n0bdc2e51-140d-42ba-b106-be65bf37dbfd                       0               0   \nd66b4fa6-a10b-43da-9b57-f17cca4c7069                       0               0   \nb1e2dfba-39ab-46d8-ab14-3d5353040580                       0               0   \na8eb2a83-e5a1-403a-86de-736222403408                       0               0   \n1ba79d3c-6730-4961-b920-b90de10e77e8                       0               0   \n74461c5d-6ce0-4ad0-b599-bc4f822b1046                       0               0   \n8230ce2d-be3c-48e8-a7f9-e4e8d9fc615f                       0               0   \n8978ffbc-22ee-403d-977a-e1cb9c319715                       0               0   \n1fc85793-f560-45c3-b8a5-b371765e7bac                       0               0   \n867a712c-4718-44fd-babf-9896cfd38add                       0               0   \nfe5356b5-cd98-42b0-8897-e563921e38a7                       0               0   \nd109e834-ffb3-4c27-82e5-175a04b99375                       0               0   \n4c357314-d701-43d4-a804-cb2881f7f983                       0               0   \nd1e0f054-33b4-413e-b6c5-0f8440f1a612                       0               0   \n26a1e86e-5b97-4a31-880c-1836067461f7                       0               0   \ndd64b2c7-3c07-44ed-9627-cd167bf97f68                       0               0   \n2081fc5f-ab00-4bea-b64f-0908c4d67378                       0               0   \n58391bf7-ae4c-4d11-95df-abb79c7fc085                       0               0   \n8f6bb03e-fa56-4b12-ac17-74d788861b02                       0               0   \n07f1ee98-740c-43ed-b4e6-46a22d77dae4                       0               0   \nb6b1cbac-c421-4f21-95ce-1a5b29586e2f                       0               0   \n8e50d9b2-34e1-46d2-ac65-70e4b22306a9                       0               0   \n28f82b04-a6ae-4131-a6c7-da35c5a4b917                       0               0   \na2338edc-ff9b-4c33-a159-d5367f46583e                       0               0   \nbcf05407-7d4c-4332-8785-d2d110ddc8e8                       0               0   \n94e63949-43ac-4a82-b7dd-4174c47ea565                       0               0   \n71bb6310-c768-414c-8810-f5082ef1cf12                       0               0   \naae08768-5c66-432f-abcb-433bbe674c6f                       0               0   \nd4da85b8-99c8-40e6-afe1-c2d31e40c6dc                       0               0   \nd13b0970-bbad-48ef-be1e-0cb8a215e534                       0               0   \n9a101069-703d-4405-a876-1028fa499cec                       0               0   \n3f368d12-2300-40be-8d3e-b72624c81e93                       0               0   \n148ceb21-5843-4e02-a188-382e68f36708                       0               0   \n152cb89f-2c82-4a51-a8e5-96923c39f957                       0               0   \nbcf887e4-17ee-444d-8ca2-35627b090928                       0               0   \n75fefb08-4d65-42a6-ab40-64509bca0098                       0               0   \na537c4b2-593c-4614-9fae-0990ee21cc09                       0               0   \n3e9c9da6-63e2-4e9a-b94d-5e5ef2ba5525                       0               0   \n5b969699-e102-4913-82d7-e028ddf433b1                       0               0   \n1e492a8c-f330-4d92-838d-4809f6b2bc61                       0               0   \n1d99fdde-4142-460b-b5f7-b5bf5635adb3                       0               0   \n82c42bc6-562d-41b4-b86b-597dc358d7f2                       0               0   \ne0443aff-a676-47ea-bbdb-cbc5d3dae03c                       0               0   \nc0751426-d75d-4d43-aba5-5e1ebb3d7533                       0               0   \n2a500e91-940e-456e-b83c-e6ae40311c63                       0               0   \n0f6790df-236e-409d-9e43-d8c2db0bbbbe                       0               0   \n54d46716-0844-4198-b8f1-0f34cbb905cb                       0               0   \n8e98a87d-6cce-41ce-880c-ec0551cb10f2                       0               0   \n6db24023-a63a-4f62-8a1f-cab2c86dd5bc                       0               0   \nd0f06abc-edd8-4e38-ac3f-bc3a93380e6c                       0               0   \nf17c6b5c-018d-42ca-8a86-7596572e184f                       0               0   \n\n                                      Purpose_other  Purpose_renewable_energy  \\\nLoan ID                                                                         \nab6d8e46-e8cb-4980-bae1-7bc6f1f0a912              0                         0   \nf2277c45-c54d-4bb8-b7bb-dc8c1d89df0b              0                         0   \ne66b0417-b36e-4643-b5ed-1fb53a0bae19              0                         0   \nfcb91331-dce9-4e6e-be95-9e056becec97              0                         0   \nc1af70a8-674c-4ece-9a50-6af68335b77f              0                         0   \nec255dfa-03d3-4805-bb05-a20fe1d8d707              0                         0   \n0bdc2e51-140d-42ba-b106-be65bf37dbfd              0                         0   \nd66b4fa6-a10b-43da-9b57-f17cca4c7069              0                         0   \nb1e2dfba-39ab-46d8-ab14-3d5353040580              0                         0   \na8eb2a83-e5a1-403a-86de-736222403408              0                         0   \n1ba79d3c-6730-4961-b920-b90de10e77e8              0                         0   \n74461c5d-6ce0-4ad0-b599-bc4f822b1046              0                         0   \n8230ce2d-be3c-48e8-a7f9-e4e8d9fc615f              0                         0   \n8978ffbc-22ee-403d-977a-e1cb9c319715              1                         0   \n1fc85793-f560-45c3-b8a5-b371765e7bac              0                         0   \n867a712c-4718-44fd-babf-9896cfd38add              0                         0   \nfe5356b5-cd98-42b0-8897-e563921e38a7              0                         0   \nd109e834-ffb3-4c27-82e5-175a04b99375              0                         0   \n4c357314-d701-43d4-a804-cb2881f7f983              0                         0   \nd1e0f054-33b4-413e-b6c5-0f8440f1a612              0                         0   \n26a1e86e-5b97-4a31-880c-1836067461f7              0                         0   \ndd64b2c7-3c07-44ed-9627-cd167bf97f68              0                         0   \n2081fc5f-ab00-4bea-b64f-0908c4d67378              0                         0   \n58391bf7-ae4c-4d11-95df-abb79c7fc085              0                         0   \n8f6bb03e-fa56-4b12-ac17-74d788861b02              0                         0   \n07f1ee98-740c-43ed-b4e6-46a22d77dae4              0                         0   \nb6b1cbac-c421-4f21-95ce-1a5b29586e2f              0                         0   \n8e50d9b2-34e1-46d2-ac65-70e4b22306a9              0                         0   \n28f82b04-a6ae-4131-a6c7-da35c5a4b917              0                         0   \na2338edc-ff9b-4c33-a159-d5367f46583e              0                         0   \nbcf05407-7d4c-4332-8785-d2d110ddc8e8              0                         0   \n94e63949-43ac-4a82-b7dd-4174c47ea565              0                         0   \n71bb6310-c768-414c-8810-f5082ef1cf12              0                         0   \naae08768-5c66-432f-abcb-433bbe674c6f              0                         0   \nd4da85b8-99c8-40e6-afe1-c2d31e40c6dc              0                         0   \nd13b0970-bbad-48ef-be1e-0cb8a215e534              0                         0   \n9a101069-703d-4405-a876-1028fa499cec              0                         0   \n3f368d12-2300-40be-8d3e-b72624c81e93              0                         0   \n148ceb21-5843-4e02-a188-382e68f36708              0                         0   \n152cb89f-2c82-4a51-a8e5-96923c39f957              0                         0   \nbcf887e4-17ee-444d-8ca2-35627b090928              0                         0   \n75fefb08-4d65-42a6-ab40-64509bca0098              0                         0   \na537c4b2-593c-4614-9fae-0990ee21cc09              0                         0   \n3e9c9da6-63e2-4e9a-b94d-5e5ef2ba5525              0                         0   \n5b969699-e102-4913-82d7-e028ddf433b1              0                         0   \n1e492a8c-f330-4d92-838d-4809f6b2bc61              0                         0   \n1d99fdde-4142-460b-b5f7-b5bf5635adb3              0                         0   \n82c42bc6-562d-41b4-b86b-597dc358d7f2              0                         0   \ne0443aff-a676-47ea-bbdb-cbc5d3dae03c              0                         0   \nc0751426-d75d-4d43-aba5-5e1ebb3d7533              1                         0   \n2a500e91-940e-456e-b83c-e6ae40311c63              0                         0   \n0f6790df-236e-409d-9e43-d8c2db0bbbbe              0                         0   \n54d46716-0844-4198-b8f1-0f34cbb905cb              0                         0   \n8e98a87d-6cce-41ce-880c-ec0551cb10f2              0                         0   \n6db24023-a63a-4f62-8a1f-cab2c86dd5bc              0                         0   \nd0f06abc-edd8-4e38-ac3f-bc3a93380e6c              0                         0   \nf17c6b5c-018d-42ca-8a86-7596572e184f              0                         0   \n\n                                      Purpose_small_business  \\\nLoan ID                                                        \nab6d8e46-e8cb-4980-bae1-7bc6f1f0a912                       0   \nf2277c45-c54d-4bb8-b7bb-dc8c1d89df0b                       0   \ne66b0417-b36e-4643-b5ed-1fb53a0bae19                       0   \nfcb91331-dce9-4e6e-be95-9e056becec97                       0   \nc1af70a8-674c-4ece-9a50-6af68335b77f                       0   \nec255dfa-03d3-4805-bb05-a20fe1d8d707                       0   \n0bdc2e51-140d-42ba-b106-be65bf37dbfd                       0   \nd66b4fa6-a10b-43da-9b57-f17cca4c7069                       0   \nb1e2dfba-39ab-46d8-ab14-3d5353040580                       0   \na8eb2a83-e5a1-403a-86de-736222403408                       0   \n1ba79d3c-6730-4961-b920-b90de10e77e8                       0   \n74461c5d-6ce0-4ad0-b599-bc4f822b1046                       0   \n8230ce2d-be3c-48e8-a7f9-e4e8d9fc615f                       0   \n8978ffbc-22ee-403d-977a-e1cb9c319715                       0   \n1fc85793-f560-45c3-b8a5-b371765e7bac                       0   \n867a712c-4718-44fd-babf-9896cfd38add                       0   \nfe5356b5-cd98-42b0-8897-e563921e38a7                       0   \nd109e834-ffb3-4c27-82e5-175a04b99375                       0   \n4c357314-d701-43d4-a804-cb2881f7f983                       0   \nd1e0f054-33b4-413e-b6c5-0f8440f1a612                       0   \n26a1e86e-5b97-4a31-880c-1836067461f7                       0   \ndd64b2c7-3c07-44ed-9627-cd167bf97f68                       0   \n2081fc5f-ab00-4bea-b64f-0908c4d67378                       0   \n58391bf7-ae4c-4d11-95df-abb79c7fc085                       0   \n8f6bb03e-fa56-4b12-ac17-74d788861b02                       0   \n07f1ee98-740c-43ed-b4e6-46a22d77dae4                       0   \nb6b1cbac-c421-4f21-95ce-1a5b29586e2f                       0   \n8e50d9b2-34e1-46d2-ac65-70e4b22306a9                       0   \n28f82b04-a6ae-4131-a6c7-da35c5a4b917                       0   \na2338edc-ff9b-4c33-a159-d5367f46583e                       0   \nbcf05407-7d4c-4332-8785-d2d110ddc8e8                       0   \n94e63949-43ac-4a82-b7dd-4174c47ea565                       0   \n71bb6310-c768-414c-8810-f5082ef1cf12                       0   \naae08768-5c66-432f-abcb-433bbe674c6f                       0   \nd4da85b8-99c8-40e6-afe1-c2d31e40c6dc                       0   \nd13b0970-bbad-48ef-be1e-0cb8a215e534                       0   \n9a101069-703d-4405-a876-1028fa499cec                       0   \n3f368d12-2300-40be-8d3e-b72624c81e93                       0   \n148ceb21-5843-4e02-a188-382e68f36708                       0   \n152cb89f-2c82-4a51-a8e5-96923c39f957                       0   \nbcf887e4-17ee-444d-8ca2-35627b090928                       0   \n75fefb08-4d65-42a6-ab40-64509bca0098                       0   \na537c4b2-593c-4614-9fae-0990ee21cc09                       0   \n3e9c9da6-63e2-4e9a-b94d-5e5ef2ba5525                       0   \n5b969699-e102-4913-82d7-e028ddf433b1                       0   \n1e492a8c-f330-4d92-838d-4809f6b2bc61                       0   \n1d99fdde-4142-460b-b5f7-b5bf5635adb3                       0   \n82c42bc6-562d-41b4-b86b-597dc358d7f2                       0   \ne0443aff-a676-47ea-bbdb-cbc5d3dae03c                       0   \nc0751426-d75d-4d43-aba5-5e1ebb3d7533                       0   \n2a500e91-940e-456e-b83c-e6ae40311c63                       0   \n0f6790df-236e-409d-9e43-d8c2db0bbbbe                       0   \n54d46716-0844-4198-b8f1-0f34cbb905cb                       0   \n8e98a87d-6cce-41ce-880c-ec0551cb10f2                       0   \n6db24023-a63a-4f62-8a1f-cab2c86dd5bc                       0   \nd0f06abc-edd8-4e38-ac3f-bc3a93380e6c                       0   \nf17c6b5c-018d-42ca-8a86-7596572e184f                       0   \n\n                                      Purpose_vacation  Purpose_wedding  \nLoan ID                                                                  \nab6d8e46-e8cb-4980-bae1-7bc6f1f0a912                 0                0  \nf2277c45-c54d-4bb8-b7bb-dc8c1d89df0b                 0                0  \ne66b0417-b36e-4643-b5ed-1fb53a0bae19                 0                0  \nfcb91331-dce9-4e6e-be95-9e056becec97                 0                0  \nc1af70a8-674c-4ece-9a50-6af68335b77f                 0                0  \nec255dfa-03d3-4805-bb05-a20fe1d8d707                 0                0  \n0bdc2e51-140d-42ba-b106-be65bf37dbfd                 0                0  \nd66b4fa6-a10b-43da-9b57-f17cca4c7069                 0                0  \nb1e2dfba-39ab-46d8-ab14-3d5353040580                 0                0  \na8eb2a83-e5a1-403a-86de-736222403408                 0                0  \n1ba79d3c-6730-4961-b920-b90de10e77e8                 0                0  \n74461c5d-6ce0-4ad0-b599-bc4f822b1046                 0                0  \n8230ce2d-be3c-48e8-a7f9-e4e8d9fc615f                 0                0  \n8978ffbc-22ee-403d-977a-e1cb9c319715                 0                0  \n1fc85793-f560-45c3-b8a5-b371765e7bac                 0                0  \n867a712c-4718-44fd-babf-9896cfd38add                 0                0  \nfe5356b5-cd98-42b0-8897-e563921e38a7                 0                0  \nd109e834-ffb3-4c27-82e5-175a04b99375                 0                0  \n4c357314-d701-43d4-a804-cb2881f7f983                 0                0  \nd1e0f054-33b4-413e-b6c5-0f8440f1a612                 0                0  \n26a1e86e-5b97-4a31-880c-1836067461f7                 0                0  \ndd64b2c7-3c07-44ed-9627-cd167bf97f68                 0                0  \n2081fc5f-ab00-4bea-b64f-0908c4d67378                 0                0  \n58391bf7-ae4c-4d11-95df-abb79c7fc085                 0                0  \n8f6bb03e-fa56-4b12-ac17-74d788861b02                 0                0  \n07f1ee98-740c-43ed-b4e6-46a22d77dae4                 0                0  \nb6b1cbac-c421-4f21-95ce-1a5b29586e2f                 0                0  \n8e50d9b2-34e1-46d2-ac65-70e4b22306a9                 0                0  \n28f82b04-a6ae-4131-a6c7-da35c5a4b917                 0                0  \na2338edc-ff9b-4c33-a159-d5367f46583e                 0                0  \nbcf05407-7d4c-4332-8785-d2d110ddc8e8                 0                0  \n94e63949-43ac-4a82-b7dd-4174c47ea565                 0                0  \n71bb6310-c768-414c-8810-f5082ef1cf12                 0                0  \naae08768-5c66-432f-abcb-433bbe674c6f                 0                0  \nd4da85b8-99c8-40e6-afe1-c2d31e40c6dc                 0                0  \nd13b0970-bbad-48ef-be1e-0cb8a215e534                 0                0  \n9a101069-703d-4405-a876-1028fa499cec                 0                0  \n3f368d12-2300-40be-8d3e-b72624c81e93                 0                0  \n148ceb21-5843-4e02-a188-382e68f36708                 0                0  \n152cb89f-2c82-4a51-a8e5-96923c39f957                 0                0  \nbcf887e4-17ee-444d-8ca2-35627b090928                 0                0  \n75fefb08-4d65-42a6-ab40-64509bca0098                 0                0  \na537c4b2-593c-4614-9fae-0990ee21cc09                 0                0  \n3e9c9da6-63e2-4e9a-b94d-5e5ef2ba5525                 0                0  \n5b969699-e102-4913-82d7-e028ddf433b1                 0                0  \n1e492a8c-f330-4d92-838d-4809f6b2bc61                 0                0  \n1d99fdde-4142-460b-b5f7-b5bf5635adb3                 0                0  \n82c42bc6-562d-41b4-b86b-597dc358d7f2                 0                0  \ne0443aff-a676-47ea-bbdb-cbc5d3dae03c                 0                0  \nc0751426-d75d-4d43-aba5-5e1ebb3d7533                 0                0  \n2a500e91-940e-456e-b83c-e6ae40311c63                 0                0  \n0f6790df-236e-409d-9e43-d8c2db0bbbbe                 0                0  \n54d46716-0844-4198-b8f1-0f34cbb905cb                 0                0  \n8e98a87d-6cce-41ce-880c-ec0551cb10f2                 0                0  \n6db24023-a63a-4f62-8a1f-cab2c86dd5bc                 0                0  \nd0f06abc-edd8-4e38-ac3f-bc3a93380e6c                 0                0  \nf17c6b5c-018d-42ca-8a86-7596572e184f                 0                0  \n\n[57 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Current Loan Amount</th>\n      <th>Credit Score</th>\n      <th>Annual Income</th>\n      <th>Monthly Debt</th>\n      <th>Years of Credit History</th>\n      <th>Number of Open Accounts</th>\n      <th>Number of Credit Problems</th>\n      <th>Current Credit Balance</th>\n      <th>Maximum Open Credit</th>\n      <th>Bankruptcies</th>\n      <th>...</th>\n      <th>Purpose_Medical Bills</th>\n      <th>Purpose_Other</th>\n      <th>Purpose_Take a Trip</th>\n      <th>Purpose_major_purchase</th>\n      <th>Purpose_moving</th>\n      <th>Purpose_other</th>\n      <th>Purpose_renewable_energy</th>\n      <th>Purpose_small_business</th>\n      <th>Purpose_vacation</th>\n      <th>Purpose_wedding</th>\n    </tr>\n    <tr>\n      <th>Loan ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ab6d8e46-e8cb-4980-bae1-7bc6f1f0a912</th>\n      <td>740630.0</td>\n      <td>703.0</td>\n      <td>1391522.0</td>\n      <td>23075.88</td>\n      <td>19.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>476007.0</td>\n      <td>1003948.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>f2277c45-c54d-4bb8-b7bb-dc8c1d89df0b</th>\n      <td>323378.0</td>\n      <td>720.0</td>\n      <td>1219477.0</td>\n      <td>8526.25</td>\n      <td>15.9</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>260585.0</td>\n      <td>514888.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>e66b0417-b36e-4643-b5ed-1fb53a0bae19</th>\n      <td>742852.0</td>\n      <td>720.0</td>\n      <td>1336954.0</td>\n      <td>27184.63</td>\n      <td>13.5</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>314412.0</td>\n      <td>1106534.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>fcb91331-dce9-4e6e-be95-9e056becec97</th>\n      <td>330374.0</td>\n      <td>718.0</td>\n      <td>2187413.0</td>\n      <td>57054.72</td>\n      <td>22.6</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>957600.0</td>\n      <td>1152624.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>c1af70a8-674c-4ece-9a50-6af68335b77f</th>\n      <td>535282.0</td>\n      <td>703.0</td>\n      <td>2696708.0</td>\n      <td>49664.29</td>\n      <td>22.6</td>\n      <td>24.0</td>\n      <td>0.0</td>\n      <td>387695.0</td>\n      <td>722876.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>ec255dfa-03d3-4805-bb05-a20fe1d8d707</th>\n      <td>785400.0</td>\n      <td>672.0</td>\n      <td>1414740.0</td>\n      <td>26691.58</td>\n      <td>17.5</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>439318.0</td>\n      <td>594946.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0bdc2e51-140d-42ba-b106-be65bf37dbfd</th>\n      <td>285956.0</td>\n      <td>720.0</td>\n      <td>858971.0</td>\n      <td>11596.08</td>\n      <td>18.6</td>\n      <td>10.0</td>\n      <td>1.0</td>\n      <td>126122.0</td>\n      <td>260788.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>d66b4fa6-a10b-43da-9b57-f17cca4c7069</th>\n      <td>499708.0</td>\n      <td>720.0</td>\n      <td>1541280.0</td>\n      <td>27999.92</td>\n      <td>18.2</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>766327.0</td>\n      <td>1039016.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>b1e2dfba-39ab-46d8-ab14-3d5353040580</th>\n      <td>763070.0</td>\n      <td>588.0</td>\n      <td>2074952.0</td>\n      <td>67090.14</td>\n      <td>15.9</td>\n      <td>28.0</td>\n      <td>0.0</td>\n      <td>2266016.0</td>\n      <td>3604128.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>a8eb2a83-e5a1-403a-86de-736222403408</th>\n      <td>523666.0</td>\n      <td>715.0</td>\n      <td>1291924.0</td>\n      <td>35635.45</td>\n      <td>15.3</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>322221.0</td>\n      <td>669812.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1ba79d3c-6730-4961-b920-b90de10e77e8</th>\n      <td>464882.0</td>\n      <td>746.0</td>\n      <td>1635710.0</td>\n      <td>27125.54</td>\n      <td>18.0</td>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>78603.0</td>\n      <td>2459974.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74461c5d-6ce0-4ad0-b599-bc4f822b1046</th>\n      <td>292424.0</td>\n      <td>712.0</td>\n      <td>956650.0</td>\n      <td>14509.16</td>\n      <td>20.4</td>\n      <td>14.0</td>\n      <td>0.0</td>\n      <td>388037.0</td>\n      <td>591206.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8230ce2d-be3c-48e8-a7f9-e4e8d9fc615f</th>\n      <td>754072.0</td>\n      <td>656.0</td>\n      <td>2307227.0</td>\n      <td>49413.30</td>\n      <td>21.5</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>643302.0</td>\n      <td>1225136.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8978ffbc-22ee-403d-977a-e1cb9c319715</th>\n      <td>176572.0</td>\n      <td>670.0</td>\n      <td>812079.0</td>\n      <td>3694.93</td>\n      <td>11.2</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>142386.0</td>\n      <td>291280.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1fc85793-f560-45c3-b8a5-b371765e7bac</th>\n      <td>431508.0</td>\n      <td>724.0</td>\n      <td>931665.0</td>\n      <td>19099.18</td>\n      <td>18.4</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>211584.0</td>\n      <td>539616.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>867a712c-4718-44fd-babf-9896cfd38add</th>\n      <td>258962.0</td>\n      <td>706.0</td>\n      <td>838679.0</td>\n      <td>21036.61</td>\n      <td>12.5</td>\n      <td>16.0</td>\n      <td>1.0</td>\n      <td>77140.0</td>\n      <td>620268.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>fe5356b5-cd98-42b0-8897-e563921e38a7</th>\n      <td>281292.0</td>\n      <td>613.0</td>\n      <td>854069.0</td>\n      <td>10177.54</td>\n      <td>18.4</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>36195.0</td>\n      <td>54912.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>d109e834-ffb3-4c27-82e5-175a04b99375</th>\n      <td>261338.0</td>\n      <td>659.0</td>\n      <td>1316567.0</td>\n      <td>28086.75</td>\n      <td>14.5</td>\n      <td>17.0</td>\n      <td>0.0</td>\n      <td>135318.0</td>\n      <td>307252.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4c357314-d701-43d4-a804-cb2881f7f983</th>\n      <td>607926.0</td>\n      <td>684.0</td>\n      <td>1912616.0</td>\n      <td>23748.29</td>\n      <td>21.5</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>96805.0</td>\n      <td>737484.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>d1e0f054-33b4-413e-b6c5-0f8440f1a612</th>\n      <td>647130.0</td>\n      <td>653.0</td>\n      <td>1502463.0</td>\n      <td>25917.52</td>\n      <td>15.8</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>564870.0</td>\n      <td>964678.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26a1e86e-5b97-4a31-880c-1836067461f7</th>\n      <td>353628.0</td>\n      <td>649.0</td>\n      <td>1049807.0</td>\n      <td>23883.19</td>\n      <td>12.6</td>\n      <td>17.0</td>\n      <td>0.0</td>\n      <td>385567.0</td>\n      <td>539176.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>dd64b2c7-3c07-44ed-9627-cd167bf97f68</th>\n      <td>201322.0</td>\n      <td>725.0</td>\n      <td>985283.0</td>\n      <td>12964.65</td>\n      <td>21.5</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>143507.0</td>\n      <td>230450.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2081fc5f-ab00-4bea-b64f-0908c4d67378</th>\n      <td>622072.0</td>\n      <td>723.0</td>\n      <td>1481867.0</td>\n      <td>21116.60</td>\n      <td>16.9</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>506008.0</td>\n      <td>1069178.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>58391bf7-ae4c-4d11-95df-abb79c7fc085</th>\n      <td>447964.0</td>\n      <td>692.0</td>\n      <td>1160634.0</td>\n      <td>19769.50</td>\n      <td>24.2</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>277837.0</td>\n      <td>951786.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8f6bb03e-fa56-4b12-ac17-74d788861b02</th>\n      <td>479952.0</td>\n      <td>687.0</td>\n      <td>1420060.0</td>\n      <td>26034.56</td>\n      <td>22.3</td>\n      <td>23.0</td>\n      <td>0.0</td>\n      <td>292106.0</td>\n      <td>1386198.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>07f1ee98-740c-43ed-b4e6-46a22d77dae4</th>\n      <td>228052.0</td>\n      <td>652.0</td>\n      <td>1247730.0</td>\n      <td>29529.80</td>\n      <td>24.4</td>\n      <td>12.0</td>\n      <td>1.0</td>\n      <td>8569.0</td>\n      <td>132396.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>b6b1cbac-c421-4f21-95ce-1a5b29586e2f</th>\n      <td>770154.0</td>\n      <td>677.0</td>\n      <td>1805361.0</td>\n      <td>36257.70</td>\n      <td>20.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>547010.0</td>\n      <td>697532.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8e50d9b2-34e1-46d2-ac65-70e4b22306a9</th>\n      <td>572528.0</td>\n      <td>698.0</td>\n      <td>1431574.0</td>\n      <td>37101.87</td>\n      <td>16.0</td>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>654588.0</td>\n      <td>1045440.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28f82b04-a6ae-4131-a6c7-da35c5a4b917</th>\n      <td>593516.0</td>\n      <td>662.0</td>\n      <td>1223220.0</td>\n      <td>17328.95</td>\n      <td>16.6</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>318269.0</td>\n      <td>391204.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>a2338edc-ff9b-4c33-a159-d5367f46583e</th>\n      <td>336688.0</td>\n      <td>718.0</td>\n      <td>852435.0</td>\n      <td>18114.22</td>\n      <td>16.5</td>\n      <td>17.0</td>\n      <td>0.0</td>\n      <td>120346.0</td>\n      <td>881936.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>bcf05407-7d4c-4332-8785-d2d110ddc8e8</th>\n      <td>259930.0</td>\n      <td>659.0</td>\n      <td>467685.0</td>\n      <td>7482.96</td>\n      <td>5.6</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>254106.0</td>\n      <td>610412.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>94e63949-43ac-4a82-b7dd-4174c47ea565</th>\n      <td>216920.0</td>\n      <td>714.0</td>\n      <td>655690.0</td>\n      <td>10982.76</td>\n      <td>23.6</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>147554.0</td>\n      <td>223322.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>71bb6310-c768-414c-8810-f5082ef1cf12</th>\n      <td>371074.0</td>\n      <td>705.0</td>\n      <td>915648.0</td>\n      <td>21365.12</td>\n      <td>9.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>417240.0</td>\n      <td>495022.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>aae08768-5c66-432f-abcb-433bbe674c6f</th>\n      <td>217492.0</td>\n      <td>704.0</td>\n      <td>1145795.0</td>\n      <td>25302.68</td>\n      <td>13.8</td>\n      <td>25.0</td>\n      <td>0.0</td>\n      <td>643302.0</td>\n      <td>1171170.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>d4da85b8-99c8-40e6-afe1-c2d31e40c6dc</th>\n      <td>337128.0</td>\n      <td>733.0</td>\n      <td>795834.0</td>\n      <td>9019.49</td>\n      <td>20.7</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>311790.0</td>\n      <td>1093994.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>d13b0970-bbad-48ef-be1e-0cb8a215e534</th>\n      <td>304062.0</td>\n      <td>714.0</td>\n      <td>1162914.0</td>\n      <td>12501.43</td>\n      <td>15.5</td>\n      <td>11.0</td>\n      <td>1.0</td>\n      <td>156997.0</td>\n      <td>319484.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9a101069-703d-4405-a876-1028fa499cec</th>\n      <td>553256.0</td>\n      <td>710.0</td>\n      <td>1337847.0</td>\n      <td>28875.06</td>\n      <td>25.5</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>330733.0</td>\n      <td>692516.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3f368d12-2300-40be-8d3e-b72624c81e93</th>\n      <td>327888.0</td>\n      <td>694.0</td>\n      <td>1321412.0</td>\n      <td>20459.77</td>\n      <td>19.5</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>263587.0</td>\n      <td>384868.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>148ceb21-5843-4e02-a188-382e68f36708</th>\n      <td>731412.0</td>\n      <td>675.0</td>\n      <td>1683210.0</td>\n      <td>33285.34</td>\n      <td>22.2</td>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>1013308.0</td>\n      <td>1859418.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>152cb89f-2c82-4a51-a8e5-96923c39f957</th>\n      <td>438416.0</td>\n      <td>620.0</td>\n      <td>759164.0</td>\n      <td>9236.47</td>\n      <td>10.4</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>416214.0</td>\n      <td>912736.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>bcf887e4-17ee-444d-8ca2-35627b090928</th>\n      <td>413820.0</td>\n      <td>723.0</td>\n      <td>1410750.0</td>\n      <td>22219.36</td>\n      <td>20.4</td>\n      <td>10.0</td>\n      <td>1.0</td>\n      <td>210121.0</td>\n      <td>494516.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>75fefb08-4d65-42a6-ab40-64509bca0098</th>\n      <td>385902.0</td>\n      <td>706.0</td>\n      <td>929670.0</td>\n      <td>10226.37</td>\n      <td>11.3</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>92568.0</td>\n      <td>275550.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>a537c4b2-593c-4614-9fae-0990ee21cc09</th>\n      <td>532532.0</td>\n      <td>724.0</td>\n      <td>958170.0</td>\n      <td>23634.86</td>\n      <td>14.8</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>340784.0</td>\n      <td>621412.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3e9c9da6-63e2-4e9a-b94d-5e5ef2ba5525</th>\n      <td>376684.0</td>\n      <td>708.0</td>\n      <td>1207108.0</td>\n      <td>31887.89</td>\n      <td>16.9</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>211717.0</td>\n      <td>453970.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5b969699-e102-4913-82d7-e028ddf433b1</th>\n      <td>237006.0</td>\n      <td>608.0</td>\n      <td>1155846.0</td>\n      <td>14736.97</td>\n      <td>18.4</td>\n      <td>14.0</td>\n      <td>1.0</td>\n      <td>134254.0</td>\n      <td>352506.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1e492a8c-f330-4d92-838d-4809f6b2bc61</th>\n      <td>556226.0</td>\n      <td>721.0</td>\n      <td>2094408.0</td>\n      <td>26180.10</td>\n      <td>13.5</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>356782.0</td>\n      <td>545006.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1d99fdde-4142-460b-b5f7-b5bf5635adb3</th>\n      <td>386980.0</td>\n      <td>711.0</td>\n      <td>771628.0</td>\n      <td>19612.37</td>\n      <td>15.9</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>156541.0</td>\n      <td>366190.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>82c42bc6-562d-41b4-b86b-597dc358d7f2</th>\n      <td>392282.0</td>\n      <td>697.0</td>\n      <td>959899.0</td>\n      <td>16318.15</td>\n      <td>20.4</td>\n      <td>16.0</td>\n      <td>1.0</td>\n      <td>645734.0</td>\n      <td>1028478.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>e0443aff-a676-47ea-bbdb-cbc5d3dae03c</th>\n      <td>232122.0</td>\n      <td>737.0</td>\n      <td>763724.0</td>\n      <td>9928.45</td>\n      <td>12.6</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>16872.0</td>\n      <td>257158.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>c0751426-d75d-4d43-aba5-5e1ebb3d7533</th>\n      <td>87252.0</td>\n      <td>652.0</td>\n      <td>861954.0</td>\n      <td>21764.50</td>\n      <td>13.9</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>411958.0</td>\n      <td>560516.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2a500e91-940e-456e-b83c-e6ae40311c63</th>\n      <td>373890.0</td>\n      <td>689.0</td>\n      <td>1787501.0</td>\n      <td>41559.27</td>\n      <td>8.2</td>\n      <td>21.0</td>\n      <td>1.0</td>\n      <td>178353.0</td>\n      <td>300608.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0f6790df-236e-409d-9e43-d8c2db0bbbbe</th>\n      <td>292160.0</td>\n      <td>720.0</td>\n      <td>784985.0</td>\n      <td>11774.87</td>\n      <td>16.5</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>308389.0</td>\n      <td>393690.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>54d46716-0844-4198-b8f1-0f34cbb905cb</th>\n      <td>332222.0</td>\n      <td>743.0</td>\n      <td>1491937.0</td>\n      <td>18524.81</td>\n      <td>13.0</td>\n      <td>17.0</td>\n      <td>0.0</td>\n      <td>111169.0</td>\n      <td>436348.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8e98a87d-6cce-41ce-880c-ec0551cb10f2</th>\n      <td>472098.0</td>\n      <td>722.0</td>\n      <td>2223912.0</td>\n      <td>31505.42</td>\n      <td>30.8</td>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>514178.0</td>\n      <td>1102552.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6db24023-a63a-4f62-8a1f-cab2c86dd5bc</th>\n      <td>473220.0</td>\n      <td>681.0</td>\n      <td>1175891.0</td>\n      <td>27045.36</td>\n      <td>17.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n      <td>567967.0</td>\n      <td>815936.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>d0f06abc-edd8-4e38-ac3f-bc3a93380e6c</th>\n      <td>683782.0</td>\n      <td>692.0</td>\n      <td>2077460.0</td>\n      <td>44319.21</td>\n      <td>22.9</td>\n      <td>14.0</td>\n      <td>0.0</td>\n      <td>413345.0</td>\n      <td>720786.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>f17c6b5c-018d-42ca-8a86-7596572e184f</th>\n      <td>556226.0</td>\n      <td>716.0</td>\n      <td>2497911.0</td>\n      <td>53288.73</td>\n      <td>28.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>719891.0</td>\n      <td>913990.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>57 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[intersection_sl]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T14:47:08.810236200Z",
     "start_time": "2024-05-14T14:47:06.126741500Z"
    }
   },
   "id": "a131c6799e0c6729"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multilayer perceptrons"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9588f5ad65a8d9fc"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "from importlib import reload  # Python 3.4+\n",
    "import models.loss\n",
    "reload(models.loss)\n",
    "from models.loss import semantic_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:37:37.061185900Z",
     "start_time": "2024-05-23T14:37:37.013312100Z"
    }
   },
   "id": "b7bedaae61d6eb10"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "from importlib import reload  # Python 3.4+\n",
    "import models.model\n",
    "reload(models.model)\n",
    "from models.model import MLP"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:37:49.009965400Z",
     "start_time": "2024-05-23T14:37:48.899874Z"
    }
   },
   "id": "6f3ed7b5dcc89fe"
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "credit_score_index = X_alt_train.columns.get_loc('Credit Score')\n",
    "short_term_index = X_alt_train.columns.get_loc('Term_Short Term')\n",
    "annual_income_index = X_alt_train.columns.get_loc('Annual Income')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:39:55.254420600Z",
     "start_time": "2024-05-23T14:39:55.207172700Z"
    }
   },
   "id": "42c540d1c26b57af"
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "dataset = LCDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=5000, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:40:06.276812700Z",
     "start_time": "2024-05-23T14:40:06.182067300Z"
    }
   },
   "id": "10e7d8b1ef14dc64"
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nMLP                                      [46369, 1]                --\n├─Sequential: 1-1                        [46369, 1]                --\n│    └─Linear: 2-1                       [46369, 3]                93\n│    └─ReLU: 2-2                         [46369, 3]                --\n│    └─Linear: 2-3                       [46369, 1]                4\n│    └─Sigmoid: 2-4                      [46369, 1]                --\n==========================================================================================\nTotal params: 97\nTrainable params: 97\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 4.50\n==========================================================================================\nInput size (MB): 5.56\nForward/backward pass size (MB): 1.48\nParams size (MB): 0.00\nEstimated Total Size (MB): 7.05\n=========================================================================================="
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model = MLP(num_features=n_features)\n",
    "summary(mlp_model, input_size=X_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:40:17.409214Z",
     "start_time": "2024-05-23T14:40:17.244477900Z"
    }
   },
   "id": "d8fc4f5e8a062773"
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "optimizer_mlp = optim.Adam(mlp_model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:40:28.379759200Z",
     "start_time": "2024-05-23T14:40:28.301319200Z"
    }
   },
   "id": "64975a352a636960"
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t| Train loss: 0.215 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 1 \t| Train loss: 0.22 \t| Train acc: 0.72 \t| Test acc: 0.73\n",
      "Epoch: 2 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 3 \t| Train loss: 0.204 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 4 \t| Train loss: 0.225 \t| Train acc: 0.72 \t| Test acc: 0.74\n",
      "Epoch: 5 \t| Train loss: 0.207 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 6 \t| Train loss: 0.211 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 7 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 8 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 9 \t| Train loss: 0.21 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 10 \t| Train loss: 0.223 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 11 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 12 \t| Train loss: 0.21 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 13 \t| Train loss: 0.216 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 14 \t| Train loss: 0.222 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 15 \t| Train loss: 0.221 \t| Train acc: 0.72 \t| Test acc: 0.73\n",
      "Epoch: 16 \t| Train loss: 0.219 \t| Train acc: 0.72 \t| Test acc: 0.73\n",
      "Epoch: 17 \t| Train loss: 0.219 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 18 \t| Train loss: 0.206 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 19 \t| Train loss: 0.221 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 20 \t| Train loss: 0.222 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 21 \t| Train loss: 0.215 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 22 \t| Train loss: 0.218 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 23 \t| Train loss: 0.217 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 24 \t| Train loss: 0.209 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 25 \t| Train loss: 0.207 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 26 \t| Train loss: 0.221 \t| Train acc: 0.72 \t| Test acc: 0.74\n",
      "Epoch: 27 \t| Train loss: 0.23 \t| Train acc: 0.72 \t| Test acc: 0.73\n",
      "Epoch: 28 \t| Train loss: 0.206 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 29 \t| Train loss: 0.216 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 30 \t| Train loss: 0.218 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 31 \t| Train loss: 0.213 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 32 \t| Train loss: 0.21 \t| Train acc: 0.76 \t| Test acc: 0.73\n",
      "Epoch: 33 \t| Train loss: 0.217 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 34 \t| Train loss: 0.216 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 35 \t| Train loss: 0.21 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 36 \t| Train loss: 0.218 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 37 \t| Train loss: 0.217 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 38 \t| Train loss: 0.219 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 39 \t| Train loss: 0.227 \t| Train acc: 0.72 \t| Test acc: 0.74\n",
      "Epoch: 40 \t| Train loss: 0.213 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 41 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 42 \t| Train loss: 0.219 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 43 \t| Train loss: 0.224 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 44 \t| Train loss: 0.221 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 45 \t| Train loss: 0.211 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 46 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 47 \t| Train loss: 0.214 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 48 \t| Train loss: 0.205 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 49 \t| Train loss: 0.213 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 50 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 51 \t| Train loss: 0.209 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 52 \t| Train loss: 0.219 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 53 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 54 \t| Train loss: 0.208 \t| Train acc: 0.76 \t| Test acc: 0.73\n",
      "Epoch: 55 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 56 \t| Train loss: 0.227 \t| Train acc: 0.72 \t| Test acc: 0.74\n",
      "Epoch: 57 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 58 \t| Train loss: 0.216 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 59 \t| Train loss: 0.216 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 60 \t| Train loss: 0.212 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 61 \t| Train loss: 0.221 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 62 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 63 \t| Train loss: 0.213 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 64 \t| Train loss: 0.223 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 65 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 66 \t| Train loss: 0.204 \t| Train acc: 0.76 \t| Test acc: 0.73\n",
      "Epoch: 67 \t| Train loss: 0.211 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 68 \t| Train loss: 0.216 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 69 \t| Train loss: 0.22 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 70 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 71 \t| Train loss: 0.216 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 72 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 73 \t| Train loss: 0.214 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 74 \t| Train loss: 0.217 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 75 \t| Train loss: 0.209 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 76 \t| Train loss: 0.218 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 77 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 78 \t| Train loss: 0.208 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 79 \t| Train loss: 0.222 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 80 \t| Train loss: 0.214 \t| Train acc: 0.72 \t| Test acc: 0.73\n",
      "Epoch: 81 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 82 \t| Train loss: 0.225 \t| Train acc: 0.71 \t| Test acc: 0.73\n",
      "Epoch: 83 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 84 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 85 \t| Train loss: 0.206 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 86 \t| Train loss: 0.227 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 87 \t| Train loss: 0.215 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 88 \t| Train loss: 0.217 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 89 \t| Train loss: 0.218 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 90 \t| Train loss: 0.21 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 91 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 92 \t| Train loss: 0.218 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 93 \t| Train loss: 0.213 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 94 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 95 \t| Train loss: 0.207 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 96 \t| Train loss: 0.209 \t| Train acc: 0.76 \t| Test acc: 0.73\n",
      "Epoch: 97 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 98 \t| Train loss: 0.216 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 99 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 100 \t| Train loss: 0.22 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 101 \t| Train loss: 0.22 \t| Train acc: 0.72 \t| Test acc: 0.73\n",
      "Epoch: 102 \t| Train loss: 0.212 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 103 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 104 \t| Train loss: 0.209 \t| Train acc: 0.76 \t| Test acc: 0.73\n",
      "Epoch: 105 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.73\n",
      "Epoch: 106 \t| Train loss: 0.219 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 107 \t| Train loss: 0.218 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 108 \t| Train loss: 0.218 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 109 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 110 \t| Train loss: 0.209 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 111 \t| Train loss: 0.216 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 112 \t| Train loss: 0.212 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 113 \t| Train loss: 0.216 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 114 \t| Train loss: 0.214 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 115 \t| Train loss: 0.221 \t| Train acc: 0.72 \t| Test acc: 0.73\n",
      "Epoch: 116 \t| Train loss: 0.216 \t| Train acc: 0.72 \t| Test acc: 0.73\n",
      "Epoch: 117 \t| Train loss: 0.217 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 118 \t| Train loss: 0.213 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 119 \t| Train loss: 0.217 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 120 \t| Train loss: 0.212 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 121 \t| Train loss: 0.207 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 122 \t| Train loss: 0.211 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 123 \t| Train loss: 0.219 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 124 \t| Train loss: 0.216 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 125 \t| Train loss: 0.215 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 126 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 127 \t| Train loss: 0.227 \t| Train acc: 0.72 \t| Test acc: 0.74\n",
      "Epoch: 128 \t| Train loss: 0.217 \t| Train acc: 0.71 \t| Test acc: 0.73\n",
      "Epoch: 129 \t| Train loss: 0.221 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 130 \t| Train loss: 0.209 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 131 \t| Train loss: 0.209 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 132 \t| Train loss: 0.209 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 133 \t| Train loss: 0.215 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 134 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 135 \t| Train loss: 0.212 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 136 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 137 \t| Train loss: 0.207 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 138 \t| Train loss: 0.21 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 139 \t| Train loss: 0.21 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 140 \t| Train loss: 0.213 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 141 \t| Train loss: 0.213 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 142 \t| Train loss: 0.226 \t| Train acc: 0.7 \t| Test acc: 0.73\n",
      "Epoch: 143 \t| Train loss: 0.211 \t| Train acc: 0.72 \t| Test acc: 0.73\n",
      "Epoch: 144 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 145 \t| Train loss: 0.211 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 146 \t| Train loss: 0.215 \t| Train acc: 0.72 \t| Test acc: 0.74\n",
      "Epoch: 147 \t| Train loss: 0.208 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 148 \t| Train loss: 0.22 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 149 \t| Train loss: 0.211 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 150 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 151 \t| Train loss: 0.222 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 152 \t| Train loss: 0.213 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 153 \t| Train loss: 0.221 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 154 \t| Train loss: 0.225 \t| Train acc: 0.72 \t| Test acc: 0.73\n",
      "Epoch: 155 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 156 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 157 \t| Train loss: 0.207 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 158 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 159 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 160 \t| Train loss: 0.212 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 161 \t| Train loss: 0.225 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 162 \t| Train loss: 0.212 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 163 \t| Train loss: 0.215 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 164 \t| Train loss: 0.215 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 165 \t| Train loss: 0.211 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 166 \t| Train loss: 0.214 \t| Train acc: 0.72 \t| Test acc: 0.73\n",
      "Epoch: 167 \t| Train loss: 0.21 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 168 \t| Train loss: 0.209 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 169 \t| Train loss: 0.214 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 170 \t| Train loss: 0.216 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 171 \t| Train loss: 0.211 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 172 \t| Train loss: 0.215 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 173 \t| Train loss: 0.22 \t| Train acc: 0.72 \t| Test acc: 0.73\n",
      "Epoch: 174 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 175 \t| Train loss: 0.213 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 176 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 177 \t| Train loss: 0.22 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 178 \t| Train loss: 0.216 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 179 \t| Train loss: 0.21 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 180 \t| Train loss: 0.205 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 181 \t| Train loss: 0.212 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 182 \t| Train loss: 0.211 \t| Train acc: 0.76 \t| Test acc: 0.73\n",
      "Epoch: 183 \t| Train loss: 0.217 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 184 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 185 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 186 \t| Train loss: 0.21 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 187 \t| Train loss: 0.205 \t| Train acc: 0.78 \t| Test acc: 0.74\n",
      "Epoch: 188 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 189 \t| Train loss: 0.213 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 190 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 191 \t| Train loss: 0.208 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 192 \t| Train loss: 0.22 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 193 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 194 \t| Train loss: 0.206 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 195 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 196 \t| Train loss: 0.221 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 197 \t| Train loss: 0.213 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 198 \t| Train loss: 0.216 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 199 \t| Train loss: 0.215 \t| Train acc: 0.73 \t| Test acc: 0.73\n"
     ]
    }
   ],
   "source": [
    "train_losses_mlp = []\n",
    "#test_losses  = []\n",
    "train_accs_mlp = []\n",
    "test_accs_mlp  = []\n",
    "\n",
    "for epoch in range(200):\n",
    "    # Forward propagation (predicting train data)\n",
    "    for features, labels in data_loader:\n",
    "        train_preds_mlp = mlp_model(features)\n",
    "        class_weights_batch = class_weights_original[labels.long()]\n",
    "        loss_function = nn.BCELoss(weight=class_weights_batch)\n",
    "\n",
    "        train_loss_mlp  = loss_function(train_preds_mlp, labels)\n",
    "\n",
    "        # Predicting test data #b\n",
    "        with torch.no_grad():\n",
    "            test_preds_mlp = mlp_model(X_validation_tensor)\n",
    "            #test_loss  = loss_function(test_preds, y_test)\n",
    "\n",
    "        # Calculate accuracy #c\n",
    "        train_acc = calculate_accuracy(train_preds_mlp, labels)\n",
    "        test_acc  = calculate_accuracy(test_preds_mlp, y_validation_tensor)\n",
    "\n",
    "        # Backward propagation #d\n",
    "        optimizer_mlp.zero_grad()\n",
    "        train_loss_mlp.backward()\n",
    "\n",
    "        # Gradient descent step #e\n",
    "        optimizer_mlp.step()\n",
    "\n",
    "        # Store training history #f\n",
    "        train_losses_mlp.append(train_loss_mlp.item())\n",
    "        #test_losses.append(test_loss.item())\n",
    "        train_accs_mlp.append(train_acc.item())\n",
    "        test_accs_mlp.append(test_acc.item())\n",
    "\n",
    "    # Print training data #g\n",
    "    #if epoch%100==0:\n",
    "    print(f'Epoch: {epoch} \\t|' \\\n",
    "          f' Train loss: {np.round(train_loss_mlp.item(),3)} \\t|' \\\n",
    "              #f' Test loss: {np.round(test_loss.item(),3)} \\t|' \\\n",
    "          f' Train acc: {np.round(train_acc.item(),2)} \\t|' \\\n",
    "          f' Test acc: {np.round(test_acc.item(),2)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:46:24.330706900Z",
     "start_time": "2024-05-23T14:43:41.796102500Z"
    }
   },
   "id": "718bb73160f9cee1"
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 73.41%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.823925     0.466990  0.734065     0.645457      0.734936\n",
      "recall        0.821247     0.471560  0.734065     0.646403      0.734065\n",
      "f1-score      0.822584     0.469264  0.734065     0.645924      0.734496\n",
      "support    4923.000000  1635.000000  0.734065  6558.000000   6558.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[4043  880]\n",
      " [ 864  771]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_nn(y_validation_tensor.clone().detach(), test_preds_mlp.clone().detach().round(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:47:09.004736700Z",
     "start_time": "2024-05-23T14:47:08.863671500Z"
    }
   },
   "id": "996699d17abfca1c"
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 74.80%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.836075     0.485663  0.747972     0.660869      0.750288\n",
      "recall        0.828759     0.498773  0.747972     0.663766      0.747972\n",
      "f1-score      0.832401     0.492131  0.747972     0.662266      0.749097\n",
      "support    5028.000000  1630.000000  0.747972  6658.000000   6658.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[4167  861]\n",
      " [ 817  813]]\n"
     ]
    }
   ],
   "source": [
    "test_preds_mlp = mlp_model(X_test_tensor)\n",
    "evaluate_nn(y_test_tensor.clone().detach(), test_preds_mlp.clone().detach().round(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:47:22.278549300Z",
     "start_time": "2024-05-23T14:47:22.130004400Z"
    }
   },
   "id": "b4140036003b14e6"
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nMLP                                      [46369, 1]                --\n├─Sequential: 1-1                        [46369, 1]                --\n│    └─Linear: 2-1                       [46369, 3]                93\n│    └─ReLU: 2-2                         [46369, 3]                --\n│    └─Linear: 2-3                       [46369, 1]                4\n│    └─Sigmoid: 2-4                      [46369, 1]                --\n==========================================================================================\nTotal params: 97\nTrainable params: 97\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 4.50\n==========================================================================================\nInput size (MB): 5.56\nForward/backward pass size (MB): 1.48\nParams size (MB): 0.00\nEstimated Total Size (MB): 7.05\n=========================================================================================="
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpsl_model = MLP(num_features=n_features)\n",
    "summary(mlpsl_model, input_size=X_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:47:42.679990600Z",
     "start_time": "2024-05-23T14:47:42.569884800Z"
    }
   },
   "id": "fc49c948f7d3404c"
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "optimizer_mlpsl = optim.Adam(mlpsl_model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:47:52.598518900Z",
     "start_time": "2024-05-23T14:47:52.503784Z"
    }
   },
   "id": "e603715e2d52a06a"
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t| Train loss: 0.244 \t| Train acc: 0.72 \t| Test acc: 0.72\n",
      "Epoch: 1 \t| Train loss: 0.239 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 2 \t| Train loss: 0.242 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 3 \t| Train loss: 0.239 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 4 \t| Train loss: 0.232 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 5 \t| Train loss: 0.237 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 6 \t| Train loss: 0.241 \t| Train acc: 0.73 \t| Test acc: 0.72\n",
      "Epoch: 7 \t| Train loss: 0.236 \t| Train acc: 0.71 \t| Test acc: 0.71\n",
      "Epoch: 8 \t| Train loss: 0.233 \t| Train acc: 0.71 \t| Test acc: 0.7\n",
      "Epoch: 9 \t| Train loss: 0.233 \t| Train acc: 0.69 \t| Test acc: 0.69\n",
      "Epoch: 10 \t| Train loss: 0.24 \t| Train acc: 0.67 \t| Test acc: 0.69\n",
      "Epoch: 11 \t| Train loss: 0.227 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 12 \t| Train loss: 0.229 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 13 \t| Train loss: 0.225 \t| Train acc: 0.68 \t| Test acc: 0.66\n",
      "Epoch: 14 \t| Train loss: 0.225 \t| Train acc: 0.66 \t| Test acc: 0.66\n",
      "Epoch: 15 \t| Train loss: 0.222 \t| Train acc: 0.65 \t| Test acc: 0.65\n",
      "Epoch: 16 \t| Train loss: 0.223 \t| Train acc: 0.64 \t| Test acc: 0.65\n",
      "Epoch: 17 \t| Train loss: 0.212 \t| Train acc: 0.67 \t| Test acc: 0.65\n",
      "Epoch: 18 \t| Train loss: 0.221 \t| Train acc: 0.66 \t| Test acc: 0.65\n",
      "Epoch: 19 \t| Train loss: 0.216 \t| Train acc: 0.67 \t| Test acc: 0.65\n",
      "Epoch: 20 \t| Train loss: 0.212 \t| Train acc: 0.66 \t| Test acc: 0.66\n",
      "Epoch: 21 \t| Train loss: 0.213 \t| Train acc: 0.68 \t| Test acc: 0.67\n",
      "Epoch: 22 \t| Train loss: 0.208 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 23 \t| Train loss: 0.214 \t| Train acc: 0.68 \t| Test acc: 0.68\n",
      "Epoch: 24 \t| Train loss: 0.215 \t| Train acc: 0.66 \t| Test acc: 0.68\n",
      "Epoch: 25 \t| Train loss: 0.206 \t| Train acc: 0.68 \t| Test acc: 0.68\n",
      "Epoch: 26 \t| Train loss: 0.202 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 27 \t| Train loss: 0.196 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 28 \t| Train loss: 0.207 \t| Train acc: 0.69 \t| Test acc: 0.7\n",
      "Epoch: 29 \t| Train loss: 0.201 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 30 \t| Train loss: 0.202 \t| Train acc: 0.69 \t| Test acc: 0.7\n",
      "Epoch: 31 \t| Train loss: 0.195 \t| Train acc: 0.72 \t| Test acc: 0.71\n",
      "Epoch: 32 \t| Train loss: 0.201 \t| Train acc: 0.69 \t| Test acc: 0.71\n",
      "Epoch: 33 \t| Train loss: 0.2 \t| Train acc: 0.72 \t| Test acc: 0.71\n",
      "Epoch: 34 \t| Train loss: 0.201 \t| Train acc: 0.75 \t| Test acc: 0.72\n",
      "Epoch: 35 \t| Train loss: 0.195 \t| Train acc: 0.73 \t| Test acc: 0.72\n",
      "Epoch: 36 \t| Train loss: 0.186 \t| Train acc: 0.74 \t| Test acc: 0.72\n",
      "Epoch: 37 \t| Train loss: 0.202 \t| Train acc: 0.71 \t| Test acc: 0.72\n",
      "Epoch: 38 \t| Train loss: 0.195 \t| Train acc: 0.71 \t| Test acc: 0.72\n",
      "Epoch: 39 \t| Train loss: 0.205 \t| Train acc: 0.72 \t| Test acc: 0.73\n",
      "Epoch: 40 \t| Train loss: 0.187 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 41 \t| Train loss: 0.193 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 42 \t| Train loss: 0.202 \t| Train acc: 0.71 \t| Test acc: 0.73\n",
      "Epoch: 43 \t| Train loss: 0.205 \t| Train acc: 0.72 \t| Test acc: 0.73\n",
      "Epoch: 44 \t| Train loss: 0.199 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 45 \t| Train loss: 0.203 \t| Train acc: 0.74 \t| Test acc: 0.73\n",
      "Epoch: 46 \t| Train loss: 0.188 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 47 \t| Train loss: 0.186 \t| Train acc: 0.78 \t| Test acc: 0.74\n",
      "Epoch: 48 \t| Train loss: 0.189 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 49 \t| Train loss: 0.192 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 50 \t| Train loss: 0.194 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 51 \t| Train loss: 0.193 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 52 \t| Train loss: 0.201 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 53 \t| Train loss: 0.192 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 54 \t| Train loss: 0.186 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 55 \t| Train loss: 0.187 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 56 \t| Train loss: 0.197 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 57 \t| Train loss: 0.194 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 58 \t| Train loss: 0.195 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 59 \t| Train loss: 0.198 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 60 \t| Train loss: 0.196 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 61 \t| Train loss: 0.188 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 62 \t| Train loss: 0.2 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 63 \t| Train loss: 0.187 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 64 \t| Train loss: 0.187 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 65 \t| Train loss: 0.186 \t| Train acc: 0.77 \t| Test acc: 0.74\n",
      "Epoch: 66 \t| Train loss: 0.177 \t| Train acc: 0.79 \t| Test acc: 0.74\n",
      "Epoch: 67 \t| Train loss: 0.194 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 68 \t| Train loss: 0.191 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 69 \t| Train loss: 0.197 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 70 \t| Train loss: 0.202 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 71 \t| Train loss: 0.186 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 72 \t| Train loss: 0.184 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 73 \t| Train loss: 0.19 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 74 \t| Train loss: 0.195 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 75 \t| Train loss: 0.187 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 76 \t| Train loss: 0.191 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 77 \t| Train loss: 0.202 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 78 \t| Train loss: 0.199 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 79 \t| Train loss: 0.197 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 80 \t| Train loss: 0.191 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 81 \t| Train loss: 0.189 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 82 \t| Train loss: 0.186 \t| Train acc: 0.76 \t| Test acc: 0.75\n",
      "Epoch: 83 \t| Train loss: 0.2 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 84 \t| Train loss: 0.186 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 85 \t| Train loss: 0.19 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 86 \t| Train loss: 0.191 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 87 \t| Train loss: 0.192 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 88 \t| Train loss: 0.2 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 89 \t| Train loss: 0.198 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 90 \t| Train loss: 0.187 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 91 \t| Train loss: 0.186 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 92 \t| Train loss: 0.19 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 93 \t| Train loss: 0.194 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 94 \t| Train loss: 0.191 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 95 \t| Train loss: 0.193 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 96 \t| Train loss: 0.196 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 97 \t| Train loss: 0.188 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 98 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 99 \t| Train loss: 0.193 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 100 \t| Train loss: 0.197 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 101 \t| Train loss: 0.186 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 102 \t| Train loss: 0.183 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 103 \t| Train loss: 0.185 \t| Train acc: 0.76 \t| Test acc: 0.75\n",
      "Epoch: 104 \t| Train loss: 0.185 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 105 \t| Train loss: 0.192 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 106 \t| Train loss: 0.197 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 107 \t| Train loss: 0.197 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 108 \t| Train loss: 0.189 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 109 \t| Train loss: 0.197 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 110 \t| Train loss: 0.198 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 111 \t| Train loss: 0.198 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 112 \t| Train loss: 0.182 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 113 \t| Train loss: 0.193 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 114 \t| Train loss: 0.192 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 115 \t| Train loss: 0.187 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 116 \t| Train loss: 0.188 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 117 \t| Train loss: 0.183 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 118 \t| Train loss: 0.189 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 119 \t| Train loss: 0.189 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 120 \t| Train loss: 0.2 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 121 \t| Train loss: 0.192 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 122 \t| Train loss: 0.189 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 123 \t| Train loss: 0.196 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 124 \t| Train loss: 0.188 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 125 \t| Train loss: 0.191 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 126 \t| Train loss: 0.192 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 127 \t| Train loss: 0.189 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 128 \t| Train loss: 0.192 \t| Train acc: 0.71 \t| Test acc: 0.74\n",
      "Epoch: 129 \t| Train loss: 0.188 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 130 \t| Train loss: 0.19 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 131 \t| Train loss: 0.191 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 132 \t| Train loss: 0.191 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 133 \t| Train loss: 0.183 \t| Train acc: 0.77 \t| Test acc: 0.74\n",
      "Epoch: 134 \t| Train loss: 0.192 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 135 \t| Train loss: 0.185 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 136 \t| Train loss: 0.199 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 137 \t| Train loss: 0.185 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 138 \t| Train loss: 0.191 \t| Train acc: 0.75 \t| Test acc: 0.75\n",
      "Epoch: 139 \t| Train loss: 0.192 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 140 \t| Train loss: 0.194 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 141 \t| Train loss: 0.193 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 142 \t| Train loss: 0.18 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 143 \t| Train loss: 0.194 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 144 \t| Train loss: 0.192 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 145 \t| Train loss: 0.197 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 146 \t| Train loss: 0.182 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 147 \t| Train loss: 0.194 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 148 \t| Train loss: 0.195 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 149 \t| Train loss: 0.197 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 150 \t| Train loss: 0.194 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 151 \t| Train loss: 0.191 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 152 \t| Train loss: 0.196 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 153 \t| Train loss: 0.197 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 154 \t| Train loss: 0.2 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 155 \t| Train loss: 0.193 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 156 \t| Train loss: 0.178 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 157 \t| Train loss: 0.181 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 158 \t| Train loss: 0.188 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 159 \t| Train loss: 0.189 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 160 \t| Train loss: 0.199 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 161 \t| Train loss: 0.192 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 162 \t| Train loss: 0.19 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 163 \t| Train loss: 0.198 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 164 \t| Train loss: 0.194 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 165 \t| Train loss: 0.185 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 166 \t| Train loss: 0.188 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 167 \t| Train loss: 0.186 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 168 \t| Train loss: 0.19 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 169 \t| Train loss: 0.193 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 170 \t| Train loss: 0.19 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 171 \t| Train loss: 0.186 \t| Train acc: 0.72 \t| Test acc: 0.74\n",
      "Epoch: 172 \t| Train loss: 0.19 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 173 \t| Train loss: 0.197 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 174 \t| Train loss: 0.199 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 175 \t| Train loss: 0.193 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 176 \t| Train loss: 0.188 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 177 \t| Train loss: 0.191 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 178 \t| Train loss: 0.192 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 179 \t| Train loss: 0.192 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 180 \t| Train loss: 0.2 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 181 \t| Train loss: 0.189 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 182 \t| Train loss: 0.193 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 183 \t| Train loss: 0.182 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 184 \t| Train loss: 0.186 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 185 \t| Train loss: 0.197 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 186 \t| Train loss: 0.19 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 187 \t| Train loss: 0.186 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 188 \t| Train loss: 0.196 \t| Train acc: 0.76 \t| Test acc: 0.74\n",
      "Epoch: 189 \t| Train loss: 0.193 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 190 \t| Train loss: 0.193 \t| Train acc: 0.72 \t| Test acc: 0.74\n",
      "Epoch: 191 \t| Train loss: 0.196 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 192 \t| Train loss: 0.192 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 193 \t| Train loss: 0.193 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 194 \t| Train loss: 0.193 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 195 \t| Train loss: 0.196 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 196 \t| Train loss: 0.189 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 197 \t| Train loss: 0.195 \t| Train acc: 0.73 \t| Test acc: 0.73\n",
      "Epoch: 198 \t| Train loss: 0.195 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 199 \t| Train loss: 0.193 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 200 \t| Train loss: 0.192 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 201 \t| Train loss: 0.197 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 202 \t| Train loss: 0.194 \t| Train acc: 0.71 \t| Test acc: 0.74\n",
      "Epoch: 203 \t| Train loss: 0.191 \t| Train acc: 0.75 \t| Test acc: 0.74\n",
      "Epoch: 204 \t| Train loss: 0.193 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 205 \t| Train loss: 0.195 \t| Train acc: 0.73 \t| Test acc: 0.74\n",
      "Epoch: 206 \t| Train loss: 0.197 \t| Train acc: 0.75 \t| Test acc: 0.73\n",
      "Epoch: 207 \t| Train loss: 0.194 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 208 \t| Train loss: 0.185 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 209 \t| Train loss: 0.193 \t| Train acc: 0.74 \t| Test acc: 0.74\n",
      "Epoch: 210 \t| Train loss: 0.189 \t| Train acc: 0.74 \t| Test acc: 0.74\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[144], line 8\u001B[0m\n\u001B[0;32m      4\u001B[0m test_accs_mlpsl  \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m400\u001B[39m):\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;66;03m# Forward propagation (predicting train data)\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m features, labels \u001B[38;5;129;01min\u001B[39;00m data_loader:\n\u001B[0;32m      9\u001B[0m         train_preds_mlpsl \u001B[38;5;241m=\u001B[39m mlpsl_model(features)\n\u001B[0;32m     10\u001B[0m         class_weights_batch \u001B[38;5;241m=\u001B[39m class_weights_original[labels\u001B[38;5;241m.\u001B[39mlong()]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Thesis_AFajkusz_UvA_2024\\models\\dataset.py:18\u001B[0m, in \u001B[0;36mLCDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__len__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;66;03m# Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]\u001B[39;00m\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m---> 18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;66;03m# Return the idx-th data point of the dataset\u001B[39;00m\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;66;03m# If we have multiple things to return (data point and label), we can return them as tuple\u001B[39;00m\n\u001B[0;32m     21\u001B[0m     data_point \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata[idx]\n\u001B[0;32m     22\u001B[0m     data_label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabel[idx]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_losses_mlpsl = []\n",
    "#test_losses  = []\n",
    "train_accs_mlpsl = []\n",
    "test_accs_mlpsl  = []\n",
    "\n",
    "for epoch in range(400):\n",
    "    # Forward propagation (predicting train data)\n",
    "    for features, labels in data_loader:\n",
    "        train_preds_mlpsl = mlpsl_model(features)\n",
    "        class_weights_batch = class_weights_original[labels.long()]\n",
    "        loss_function = nn.BCELoss(weight=class_weights_batch)\n",
    "        credit_score_mlpsl = features[:, credit_score_index].reshape(-1, 1)\n",
    "        short_term_mlpsl = features[:, short_term_index].reshape(-1, 1)\n",
    "        annual_income_mlpsl = features[:, annual_income_index].reshape(-1, 1)\n",
    "        \n",
    "        rule_mlpsl = torch.logical_or(credit_score_mlpsl>3300.5, torch.logical_and(credit_score_mlpsl<=3300.5,torch.logical_and(short_term_mlpsl<=0.5, annual_income_mlpsl<=1405107))).float()\n",
    "        #train_loss_mlp  = loss_function(train_preds_mlp, labels)\n",
    "        train_loss_mlpsl = semantic_loss(train_preds_mlpsl, labels, rule_mlpsl, class_weights_batch, 0.005)\n",
    "\n",
    "        # Predicting test data #b\n",
    "        with torch.no_grad():\n",
    "            test_preds_mlpsl = mlpsl_model(X_validation_tensor)\n",
    "            #test_loss  = loss_function(test_preds, y_test)\n",
    "\n",
    "        # Calculate accuracy #c\n",
    "        train_acc = calculate_accuracy(train_preds_mlpsl, labels)\n",
    "        test_acc  = calculate_accuracy(test_preds_mlpsl, y_validation_tensor)\n",
    "\n",
    "        # Backward propagation #d\n",
    "        optimizer_mlpsl.zero_grad()\n",
    "        train_loss_mlpsl.backward()\n",
    "\n",
    "        # Gradient descent step #e\n",
    "        optimizer_mlpsl.step()\n",
    "\n",
    "        # Store training history #f\n",
    "        train_losses_mlpsl.append(train_loss_mlpsl.item())\n",
    "        #test_losses.append(test_loss.item())\n",
    "        train_accs_mlpsl.append(train_acc.item())\n",
    "        test_accs_mlpsl.append(test_acc.item())\n",
    "\n",
    "    # Print training data #g\n",
    "    #if epoch%100==0:\n",
    "    print(f'Epoch: {epoch} \\t|' \\\n",
    "          f' Train loss: {np.round(train_loss_mlpsl.item(),3)} \\t|' \\\n",
    "              #f' Test loss: {np.round(test_loss.item(),3)} \\t|' \\\n",
    "          f' Train acc: {np.round(train_acc.item(),2)} \\t|' \\\n",
    "          f' Test acc: {np.round(test_acc.item(),2)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:53:30.139507100Z",
     "start_time": "2024-05-23T14:50:38.847109800Z"
    }
   },
   "id": "c5bc6befd8dc27a5"
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 73.92%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.827523     0.477314   0.73925     0.652418      0.740211\n",
      "recall        0.824497     0.482569   0.73925     0.653533      0.739250\n",
      "f1-score      0.826007     0.479927   0.73925     0.652967      0.739725\n",
      "support    4923.000000  1635.000000   0.73925  6558.000000   6558.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[4059  864]\n",
      " [ 846  789]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_nn(y_validation_tensor.clone().detach(), test_preds_mlpsl.clone().detach().round(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:53:44.461191400Z",
     "start_time": "2024-05-23T14:53:44.320063800Z"
    }
   },
   "id": "73d4f72a1a024935"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 75.08%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.835892     0.491175  0.750826     0.663534      0.751499\n",
      "recall        0.833731     0.495092  0.750826     0.664412      0.750826\n",
      "f1-score      0.834810     0.493126  0.750826     0.663968      0.751160\n",
      "support    5028.000000  1630.000000  0.750826  6658.000000   6658.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[4192  836]\n",
      " [ 823  807]]\n"
     ]
    }
   ],
   "source": [
    "test_preds_mlpsl = mlpsl_model(X_test_tensor)\n",
    "evaluate_nn(y_test_tensor.clone().detach(), test_preds_mlpsl.clone().detach().round(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:53:55.981842Z",
     "start_time": "2024-05-23T14:53:55.825007100Z"
    }
   },
   "id": "b54127431d199cbd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tree-based predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdfa39e3e1f8d00f"
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 74.76%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.825888     0.493523  0.747636     0.659705      0.743025\n",
      "recall        0.841154     0.466055  0.747636     0.653604      0.747636\n",
      "f1-score      0.833451     0.479396  0.747636     0.656423      0.745180\n",
      "support    4923.000000  1635.000000  0.747636  6558.000000   6558.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[4141  782]\n",
      " [ 873  762]]\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(class_weight='balanced')\n",
    "# Fit the model using X_train and y_train\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "predictions_dt = dt_model.predict(X_validation_scaled)\n",
    "\n",
    "class_report = classification_report(y_validation, predictions_dt)\n",
    "evaluate_nn(y_validation_tensor.clone().detach(), predictions_dt.round(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:54:51.772104400Z",
     "start_time": "2024-05-23T14:54:47.764705800Z"
    }
   },
   "id": "80c220832c16762f"
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 75.82%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.830817     0.506702  0.758186     0.668760      0.751468\n",
      "recall        0.853620     0.463804  0.758186     0.658712      0.758186\n",
      "f1-score      0.842064     0.484305  0.758186     0.663184      0.754478\n",
      "support    5028.000000  1630.000000  0.758186  6658.000000   6658.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[4292  736]\n",
      " [ 874  756]]\n"
     ]
    }
   ],
   "source": [
    "test_preds_dt = dt_model.predict(X_test_scaled)\n",
    "evaluate_nn(y_test_tensor.clone().detach(), test_preds_dt.round(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:55:03.280168Z",
     "start_time": "2024-05-23T14:55:03.137110600Z"
    }
   },
   "id": "d37ff0047c0f8de6"
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83      4923\n",
      "           1       0.49      0.54      0.51      1635\n",
      "\n",
      "    accuracy                           0.74      6558\n",
      "   macro avg       0.66      0.67      0.67      6558\n",
      "weighted avg       0.75      0.74      0.75      6558\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 74.26%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.840885     0.485383  0.742604     0.663134      0.752254\n",
      "recall        0.810481     0.538226  0.742604     0.674354      0.742604\n",
      "f1-score      0.825403     0.510441  0.742604     0.667922      0.746879\n",
      "support    4923.000000  1635.000000  0.742604  6558.000000   6558.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[3990  933]\n",
      " [ 755  880]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Define the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(scale_pos_weight=(len(y_train) - sum(y_train)) / sum(y_train))\n",
    "\n",
    "# Fit the model using X_train_scaled and y_train\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions_xgb = xgb_model.predict(X_validation_scaled)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "class_report_xgb = classification_report(y_validation, predictions_xgb)\n",
    "print(\"XGBoost Classification Report:\\n\", class_report_xgb)\n",
    "evaluate_nn(y_validation_tensor.clone().detach(), predictions_xgb.round(), train=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:55:20.307158400Z",
     "start_time": "2024-05-23T14:55:16.039683700Z"
    }
   },
   "id": "14ea60a51e676b56"
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 74.68%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.845820     0.484666  0.746771     0.665243      0.757403\n",
      "recall        0.812848     0.542945  0.746771     0.677896      0.746771\n",
      "f1-score      0.829006     0.512153  0.746771     0.670579      0.751435\n",
      "support    5028.000000  1630.000000  0.746771  6658.000000   6658.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[4087  941]\n",
      " [ 745  885]]\n"
     ]
    }
   ],
   "source": [
    "test_preds_xgb = xgb_model.predict(X_test_scaled)\n",
    "evaluate_nn(y_test_tensor.clone().detach(), test_preds_xgb.round(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:55:29.672400100Z",
     "start_time": "2024-05-23T14:55:29.515156200Z"
    }
   },
   "id": "87de10f5c61be50b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Limited data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d13ee8d32a079de"
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Current Loan Amount', 'Credit Score', 'Annual Income', 'Monthly Debt',\n       'Years of Credit History', 'Number of Open Accounts',\n       'Number of Credit Problems', 'Current Credit Balance',\n       'Maximum Open Credit', 'Bankruptcies', 'Tax Liens', 'Term_Short Term',\n       'Home Ownership_Home Mortgage', 'Home Ownership_Own Home',\n       'Home Ownership_Rent', 'Purpose_Buy House', 'Purpose_Buy a Car',\n       'Purpose_Debt Consolidation', 'Purpose_Educational Expenses',\n       'Purpose_Home Improvements', 'Purpose_Medical Bills', 'Purpose_Other',\n       'Purpose_Take a Trip', 'Purpose_major_purchase', 'Purpose_moving',\n       'Purpose_other', 'Purpose_renewable_energy', 'Purpose_small_business',\n       'Purpose_vacation', 'Purpose_wedding'],\n      dtype='object')"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:57:56.768513Z",
     "start_time": "2024-05-23T14:57:56.688853900Z"
    }
   },
   "id": "b26fb4167f5a951d"
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([231, 1])"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_alt = X_train[['Current Loan Amount', 'Term_Short Term', 'Credit Score', 'Annual Income', 'Tax Liens', 'Years of Credit History']]\n",
    "X_train_lim, X_remain, y_train_lim, y_remain = train_test_split(X_train_alt, y_train, test_size=0.995, random_state=42)\n",
    "X_train_lim_scaled = scaler.fit_transform(X_train_lim)\n",
    "X_validation_alt = X_validation[['Current Loan Amount', 'Term_Short Term', 'Credit Score', 'Annual Income', 'Tax Liens', 'Years of Credit History']]\n",
    "X_validation_lim_scaled = scaler.transform(X_validation_alt)\n",
    "X_validation_tensor_lim = torch.tensor(X_validation_lim_scaled, dtype=torch.float32)\n",
    "X_train_tensor_lim = torch.tensor(X_train_lim_scaled, dtype=torch.float32)\n",
    "y_train_tensor_lim = torch.tensor(y_train_lim.values, dtype=torch.float32).reshape(len(y_train_lim),1)\n",
    "X_train_tensor_lim.shape\n",
    "y_train_tensor_lim.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:16:12.777151900Z",
     "start_time": "2024-05-23T15:16:12.682721300Z"
    }
   },
   "id": "3a0ad88ea95a8570"
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "X_test_alt = X_test[['Current Loan Amount', 'Term_Short Term', 'Credit Score', 'Annual Income', 'Tax Liens', 'Years of Credit History']]\n",
    "X_test_lim_scaled = scaler.transform(X_test_alt)\n",
    "X_test_tensor_lim = torch.tensor(X_test_lim_scaled, dtype=torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:16:16.268370600Z",
     "start_time": "2024-05-23T15:16:16.213439800Z"
    }
   },
   "id": "2e0ef190f8f371cc"
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "credit_score_index_lim = X_train_lim.columns.get_loc('Credit Score')\n",
    "short_term_index_lim = X_train_lim.columns.get_loc('Term_Short Term')\n",
    "annual_income_index_lim = X_train_lim.columns.get_loc('Annual Income')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:03:52.255379100Z",
     "start_time": "2024-05-23T15:03:52.201269Z"
    }
   },
   "id": "31cef1c4a16d0d11"
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "credit_score_lim = torch.tensor(X_train_lim['Credit Score'].values, dtype=torch.float32).reshape(len(y_train_lim),1)\n",
    "short_term_lim = torch.tensor(X_train_lim['Term_Short Term'].values, dtype=torch.float32).reshape(len(y_train_lim),1)\n",
    "annual_income_lim = torch.tensor(X_train_lim['Annual Income'].values, dtype=torch.float32).reshape(len(y_train_lim),1)\n",
    "\n",
    "#rule=credit_score>3300.5\n",
    "rule_lim = torch.logical_or(credit_score_lim>3300.5, torch.logical_and(credit_score_lim<=3300.5,torch.logical_and(short_term_lim<=0.5, annual_income_lim<=1405107)))\n",
    "rule_lim=rule_lim.float()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:06:53.388335200Z",
     "start_time": "2024-05-23T15:06:53.309825500Z"
    }
   },
   "id": "e82ba00f6971e02b"
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t| Train loss: 0.128 \t| Train acc: 0.45 \t| Test acc: 0.45\n",
      "Epoch: 100 \t| Train loss: 0.057 \t| Train acc: 0.8 \t| Test acc: 0.81\n",
      "Epoch: 200 \t| Train loss: 0.057 \t| Train acc: 0.81 \t| Test acc: 0.82\n",
      "Epoch: 300 \t| Train loss: 0.057 \t| Train acc: 0.81 \t| Test acc: 0.82\n",
      "Epoch: 400 \t| Train loss: 0.057 \t| Train acc: 0.81 \t| Test acc: 0.82\n",
      "Epoch: 500 \t| Train loss: 0.057 \t| Train acc: 0.81 \t| Test acc: 0.82\n",
      "Epoch: 600 \t| Train loss: 0.057 \t| Train acc: 0.81 \t| Test acc: 0.82\n",
      "Epoch: 700 \t| Train loss: 0.057 \t| Train acc: 0.81 \t| Test acc: 0.82\n",
      "Epoch: 800 \t| Train loss: 0.057 \t| Train acc: 0.81 \t| Test acc: 0.82\n",
      "Epoch: 900 \t| Train loss: 0.057 \t| Train acc: 0.81 \t| Test acc: 0.82\n"
     ]
    }
   ],
   "source": [
    "small_model = Logistic_Regression(num_features=6)\n",
    "optimizer_small = optim.Adam(small_model.parameters(), lr=LEARNING_RATE)\n",
    "class_weights_lim = class_weights_original[y_train_tensor_lim.long()]\n",
    "loss_function_lim=nn.BCELoss(weight=class_weights_lim)\n",
    "train_losses = []\n",
    "#test_losses  = []\n",
    "train_accs = []\n",
    "test_accs  = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Forward propagation (predicting train data) #a\n",
    "    train_preds_lim = small_model(X_train_tensor_lim)\n",
    "    #train_loss  = loss_function(train_preds, y_train_tensor)\n",
    "\n",
    "    #print(torch.min(train_preds_lim), torch.max(train_preds_lim))\n",
    "    train_loss = semantic_loss(train_preds_lim, y_train_tensor_lim, rule_lim, class_weights_lim, 0.07)\n",
    "    #train_loss = loss_function_lim(train_preds_lim, y_train_tensor_lim)\n",
    "\n",
    "    # Predicting test data #b\n",
    "    with torch.no_grad():\n",
    "        test_preds = small_model(X_validation_tensor_lim)\n",
    "        #test_loss  = loss_function(test_preds, y_test)\n",
    "\n",
    "    # Calculate accuracy #c\n",
    "    train_acc = calculate_accuracy(train_preds_lim, y_train_tensor_lim)\n",
    "    test_acc  = calculate_accuracy(test_preds, y_validation_tensor)\n",
    "\n",
    "    # Backward propagation #d\n",
    "    optimizer_small.zero_grad()\n",
    "    train_loss.backward()\n",
    "\n",
    "    # Gradient descent step #e\n",
    "    optimizer_small.step()\n",
    "\n",
    "    # Store training history #f\n",
    "    train_losses.append(train_loss.item())\n",
    "    #test_losses.append(test_loss.item())\n",
    "    train_accs.append(train_acc.item())\n",
    "    test_accs.append(test_acc.item())\n",
    "\n",
    "    # Print training data #g\n",
    "    if epoch%100==0:\n",
    "        print(f'Epoch: {epoch} \\t|' \\\n",
    "              f' Train loss: {np.round(train_loss.item(),3)} \\t|' \\\n",
    "                  #f' Test loss: {np.round(test_loss.item(),3)} \\t|' \\\n",
    "              f' Train acc: {np.round(train_acc.item(),2)} \\t|' \\\n",
    "              f' Test acc: {np.round(test_acc.item(),2)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:57:15.928970700Z",
     "start_time": "2024-05-23T15:57:13.807008400Z"
    }
   },
   "id": "89ad52068c6bce72"
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 80.52%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                  0.0        1.0  accuracy   macro avg  weighted avg\n",
      "precision    0.795349   0.937500  0.805195    0.866424      0.831656\n",
      "recall       0.994186   0.254237  0.805195    0.624212      0.805195\n",
      "f1-score     0.883721   0.400000  0.805195    0.641860      0.760173\n",
      "support    172.000000  59.000000  0.805195  231.000000    231.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[171   1]\n",
      " [ 44  15]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 81.99%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.806923     0.991342  0.819915     0.899132      0.852901\n",
      "recall        0.999187     0.280122  0.819915     0.639655      0.819915\n",
      "f1-score      0.892821     0.436814  0.819915     0.664818      0.779133\n",
      "support    4923.000000  1635.000000  0.819915  6558.000000   6558.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[4919    4]\n",
      " [1177  458]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_nn(y_train_tensor_lim.clone().detach(), train_preds_lim.clone().detach().round(), train=True)\n",
    "evaluate_nn(y_validation_tensor.clone().detach(), test_preds.clone().detach().round(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:57:16.818904300Z",
     "start_time": "2024-05-23T15:57:16.756038100Z"
    }
   },
   "id": "e43be9fd06bc073"
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 82.22%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.810000     0.986900  0.822169     0.898450      0.853308\n",
      "recall        0.998807     0.277301  0.822169     0.638054      0.822169\n",
      "f1-score      0.894549     0.432950  0.822169     0.663750      0.781541\n",
      "support    5028.000000  1630.000000  0.822169  6658.000000   6658.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[5022    6]\n",
      " [1178  452]]\n"
     ]
    }
   ],
   "source": [
    "test_preds_lim = small_model(X_test_tensor_lim)\n",
    "evaluate_nn(y_test_tensor.clone().detach(), test_preds_lim.clone().detach().round(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:57:18.602708200Z",
     "start_time": "2024-05-23T15:57:18.445630600Z"
    }
   },
   "id": "a862e41dd8e102ad"
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [],
   "source": [
    "dataset_lim = LCDataset(X_train_tensor_lim, y_train_tensor_lim)\n",
    "\n",
    "data_loader_lim = DataLoader(dataset_lim, batch_size=300, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:38:38.498848Z",
     "start_time": "2024-05-23T15:38:38.404480800Z"
    }
   },
   "id": "4c2bb3735e909785"
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nMLP                                      [231, 1]                  --\n├─Sequential: 1-1                        [231, 1]                  --\n│    └─Linear: 2-1                       [231, 3]                  21\n│    └─ReLU: 2-2                         [231, 3]                  --\n│    └─Linear: 2-3                       [231, 1]                  4\n│    └─Sigmoid: 2-4                      [231, 1]                  --\n==========================================================================================\nTotal params: 25\nTrainable params: 25\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 0.01\n==========================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.01\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.01\n=========================================================================================="
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model_lim = MLP(num_features=6)\n",
    "summary(mlp_model_lim, input_size=X_train_lim.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:40:02.755034300Z",
     "start_time": "2024-05-23T15:40:02.688542Z"
    }
   },
   "id": "c2ad199e102a005b"
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "optimizer_mlp_lim = optim.Adam(mlp_model_lim.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:40:03.266683300Z",
     "start_time": "2024-05-23T15:40:03.219346100Z"
    }
   },
   "id": "8a5dc2a52e9a07c7"
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t| Train loss: 0.272 \t| Train acc: 0.27 \t| Test acc: 0.28\n",
      "Epoch: 1 \t| Train loss: 0.272 \t| Train acc: 0.27 \t| Test acc: 0.28\n",
      "Epoch: 2 \t| Train loss: 0.272 \t| Train acc: 0.27 \t| Test acc: 0.28\n",
      "Epoch: 3 \t| Train loss: 0.271 \t| Train acc: 0.27 \t| Test acc: 0.28\n",
      "Epoch: 4 \t| Train loss: 0.271 \t| Train acc: 0.28 \t| Test acc: 0.28\n",
      "Epoch: 5 \t| Train loss: 0.271 \t| Train acc: 0.28 \t| Test acc: 0.28\n",
      "Epoch: 6 \t| Train loss: 0.271 \t| Train acc: 0.28 \t| Test acc: 0.28\n",
      "Epoch: 7 \t| Train loss: 0.271 \t| Train acc: 0.27 \t| Test acc: 0.28\n",
      "Epoch: 8 \t| Train loss: 0.271 \t| Train acc: 0.27 \t| Test acc: 0.28\n",
      "Epoch: 9 \t| Train loss: 0.27 \t| Train acc: 0.27 \t| Test acc: 0.28\n",
      "Epoch: 10 \t| Train loss: 0.27 \t| Train acc: 0.27 \t| Test acc: 0.28\n",
      "Epoch: 11 \t| Train loss: 0.27 \t| Train acc: 0.27 \t| Test acc: 0.28\n",
      "Epoch: 12 \t| Train loss: 0.27 \t| Train acc: 0.27 \t| Test acc: 0.28\n",
      "Epoch: 13 \t| Train loss: 0.27 \t| Train acc: 0.27 \t| Test acc: 0.28\n",
      "Epoch: 14 \t| Train loss: 0.27 \t| Train acc: 0.27 \t| Test acc: 0.28\n",
      "Epoch: 15 \t| Train loss: 0.269 \t| Train acc: 0.27 \t| Test acc: 0.28\n",
      "Epoch: 16 \t| Train loss: 0.269 \t| Train acc: 0.27 \t| Test acc: 0.28\n",
      "Epoch: 17 \t| Train loss: 0.269 \t| Train acc: 0.27 \t| Test acc: 0.28\n",
      "Epoch: 18 \t| Train loss: 0.269 \t| Train acc: 0.27 \t| Test acc: 0.28\n",
      "Epoch: 19 \t| Train loss: 0.269 \t| Train acc: 0.27 \t| Test acc: 0.28\n",
      "Epoch: 20 \t| Train loss: 0.269 \t| Train acc: 0.28 \t| Test acc: 0.28\n",
      "Epoch: 21 \t| Train loss: 0.269 \t| Train acc: 0.28 \t| Test acc: 0.28\n",
      "Epoch: 22 \t| Train loss: 0.268 \t| Train acc: 0.28 \t| Test acc: 0.28\n",
      "Epoch: 23 \t| Train loss: 0.268 \t| Train acc: 0.28 \t| Test acc: 0.28\n",
      "Epoch: 24 \t| Train loss: 0.268 \t| Train acc: 0.28 \t| Test acc: 0.28\n",
      "Epoch: 25 \t| Train loss: 0.268 \t| Train acc: 0.28 \t| Test acc: 0.28\n",
      "Epoch: 26 \t| Train loss: 0.268 \t| Train acc: 0.28 \t| Test acc: 0.28\n",
      "Epoch: 27 \t| Train loss: 0.268 \t| Train acc: 0.28 \t| Test acc: 0.28\n",
      "Epoch: 28 \t| Train loss: 0.268 \t| Train acc: 0.29 \t| Test acc: 0.28\n",
      "Epoch: 29 \t| Train loss: 0.267 \t| Train acc: 0.29 \t| Test acc: 0.28\n",
      "Epoch: 30 \t| Train loss: 0.267 \t| Train acc: 0.29 \t| Test acc: 0.28\n",
      "Epoch: 31 \t| Train loss: 0.267 \t| Train acc: 0.29 \t| Test acc: 0.28\n",
      "Epoch: 32 \t| Train loss: 0.267 \t| Train acc: 0.28 \t| Test acc: 0.28\n",
      "Epoch: 33 \t| Train loss: 0.267 \t| Train acc: 0.28 \t| Test acc: 0.28\n",
      "Epoch: 34 \t| Train loss: 0.267 \t| Train acc: 0.28 \t| Test acc: 0.28\n",
      "Epoch: 35 \t| Train loss: 0.267 \t| Train acc: 0.28 \t| Test acc: 0.28\n",
      "Epoch: 36 \t| Train loss: 0.266 \t| Train acc: 0.28 \t| Test acc: 0.28\n",
      "Epoch: 37 \t| Train loss: 0.266 \t| Train acc: 0.28 \t| Test acc: 0.28\n",
      "Epoch: 38 \t| Train loss: 0.266 \t| Train acc: 0.28 \t| Test acc: 0.28\n",
      "Epoch: 39 \t| Train loss: 0.266 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 40 \t| Train loss: 0.266 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 41 \t| Train loss: 0.266 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 42 \t| Train loss: 0.266 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 43 \t| Train loss: 0.266 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 44 \t| Train loss: 0.266 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 45 \t| Train loss: 0.265 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 46 \t| Train loss: 0.265 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 47 \t| Train loss: 0.265 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 48 \t| Train loss: 0.265 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 49 \t| Train loss: 0.265 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 50 \t| Train loss: 0.265 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 51 \t| Train loss: 0.265 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 52 \t| Train loss: 0.265 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 53 \t| Train loss: 0.264 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 54 \t| Train loss: 0.264 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 55 \t| Train loss: 0.264 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 56 \t| Train loss: 0.264 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 57 \t| Train loss: 0.264 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 58 \t| Train loss: 0.264 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 59 \t| Train loss: 0.264 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 60 \t| Train loss: 0.264 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 61 \t| Train loss: 0.264 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 62 \t| Train loss: 0.264 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 63 \t| Train loss: 0.263 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 64 \t| Train loss: 0.263 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 65 \t| Train loss: 0.263 \t| Train acc: 0.28 \t| Test acc: 0.29\n",
      "Epoch: 66 \t| Train loss: 0.263 \t| Train acc: 0.29 \t| Test acc: 0.29\n",
      "Epoch: 67 \t| Train loss: 0.263 \t| Train acc: 0.29 \t| Test acc: 0.3\n",
      "Epoch: 68 \t| Train loss: 0.263 \t| Train acc: 0.29 \t| Test acc: 0.3\n",
      "Epoch: 69 \t| Train loss: 0.263 \t| Train acc: 0.29 \t| Test acc: 0.3\n",
      "Epoch: 70 \t| Train loss: 0.263 \t| Train acc: 0.29 \t| Test acc: 0.3\n",
      "Epoch: 71 \t| Train loss: 0.263 \t| Train acc: 0.29 \t| Test acc: 0.3\n",
      "Epoch: 72 \t| Train loss: 0.263 \t| Train acc: 0.29 \t| Test acc: 0.3\n",
      "Epoch: 73 \t| Train loss: 0.263 \t| Train acc: 0.29 \t| Test acc: 0.3\n",
      "Epoch: 74 \t| Train loss: 0.262 \t| Train acc: 0.29 \t| Test acc: 0.3\n",
      "Epoch: 75 \t| Train loss: 0.262 \t| Train acc: 0.29 \t| Test acc: 0.3\n",
      "Epoch: 76 \t| Train loss: 0.262 \t| Train acc: 0.29 \t| Test acc: 0.3\n",
      "Epoch: 77 \t| Train loss: 0.262 \t| Train acc: 0.29 \t| Test acc: 0.3\n",
      "Epoch: 78 \t| Train loss: 0.262 \t| Train acc: 0.29 \t| Test acc: 0.31\n",
      "Epoch: 79 \t| Train loss: 0.262 \t| Train acc: 0.3 \t| Test acc: 0.31\n",
      "Epoch: 80 \t| Train loss: 0.262 \t| Train acc: 0.3 \t| Test acc: 0.31\n",
      "Epoch: 81 \t| Train loss: 0.262 \t| Train acc: 0.3 \t| Test acc: 0.31\n",
      "Epoch: 82 \t| Train loss: 0.262 \t| Train acc: 0.3 \t| Test acc: 0.31\n",
      "Epoch: 83 \t| Train loss: 0.262 \t| Train acc: 0.31 \t| Test acc: 0.32\n",
      "Epoch: 84 \t| Train loss: 0.262 \t| Train acc: 0.31 \t| Test acc: 0.32\n",
      "Epoch: 85 \t| Train loss: 0.261 \t| Train acc: 0.31 \t| Test acc: 0.32\n",
      "Epoch: 86 \t| Train loss: 0.261 \t| Train acc: 0.31 \t| Test acc: 0.32\n",
      "Epoch: 87 \t| Train loss: 0.261 \t| Train acc: 0.31 \t| Test acc: 0.32\n",
      "Epoch: 88 \t| Train loss: 0.261 \t| Train acc: 0.31 \t| Test acc: 0.32\n",
      "Epoch: 89 \t| Train loss: 0.261 \t| Train acc: 0.31 \t| Test acc: 0.33\n",
      "Epoch: 90 \t| Train loss: 0.261 \t| Train acc: 0.32 \t| Test acc: 0.33\n",
      "Epoch: 91 \t| Train loss: 0.261 \t| Train acc: 0.32 \t| Test acc: 0.33\n",
      "Epoch: 92 \t| Train loss: 0.261 \t| Train acc: 0.33 \t| Test acc: 0.33\n",
      "Epoch: 93 \t| Train loss: 0.261 \t| Train acc: 0.33 \t| Test acc: 0.33\n",
      "Epoch: 94 \t| Train loss: 0.261 \t| Train acc: 0.34 \t| Test acc: 0.34\n",
      "Epoch: 95 \t| Train loss: 0.261 \t| Train acc: 0.35 \t| Test acc: 0.34\n",
      "Epoch: 96 \t| Train loss: 0.261 \t| Train acc: 0.35 \t| Test acc: 0.34\n",
      "Epoch: 97 \t| Train loss: 0.26 \t| Train acc: 0.34 \t| Test acc: 0.34\n",
      "Epoch: 98 \t| Train loss: 0.26 \t| Train acc: 0.34 \t| Test acc: 0.34\n",
      "Epoch: 99 \t| Train loss: 0.26 \t| Train acc: 0.34 \t| Test acc: 0.35\n",
      "Epoch: 100 \t| Train loss: 0.26 \t| Train acc: 0.35 \t| Test acc: 0.35\n",
      "Epoch: 101 \t| Train loss: 0.26 \t| Train acc: 0.35 \t| Test acc: 0.35\n",
      "Epoch: 102 \t| Train loss: 0.26 \t| Train acc: 0.36 \t| Test acc: 0.35\n",
      "Epoch: 103 \t| Train loss: 0.26 \t| Train acc: 0.36 \t| Test acc: 0.36\n",
      "Epoch: 104 \t| Train loss: 0.26 \t| Train acc: 0.37 \t| Test acc: 0.36\n",
      "Epoch: 105 \t| Train loss: 0.26 \t| Train acc: 0.36 \t| Test acc: 0.36\n",
      "Epoch: 106 \t| Train loss: 0.26 \t| Train acc: 0.36 \t| Test acc: 0.36\n",
      "Epoch: 107 \t| Train loss: 0.26 \t| Train acc: 0.36 \t| Test acc: 0.37\n",
      "Epoch: 108 \t| Train loss: 0.26 \t| Train acc: 0.36 \t| Test acc: 0.37\n",
      "Epoch: 109 \t| Train loss: 0.26 \t| Train acc: 0.36 \t| Test acc: 0.37\n",
      "Epoch: 110 \t| Train loss: 0.259 \t| Train acc: 0.37 \t| Test acc: 0.37\n",
      "Epoch: 111 \t| Train loss: 0.259 \t| Train acc: 0.38 \t| Test acc: 0.38\n",
      "Epoch: 112 \t| Train loss: 0.259 \t| Train acc: 0.38 \t| Test acc: 0.38\n",
      "Epoch: 113 \t| Train loss: 0.259 \t| Train acc: 0.38 \t| Test acc: 0.38\n",
      "Epoch: 114 \t| Train loss: 0.259 \t| Train acc: 0.39 \t| Test acc: 0.38\n",
      "Epoch: 115 \t| Train loss: 0.259 \t| Train acc: 0.38 \t| Test acc: 0.39\n",
      "Epoch: 116 \t| Train loss: 0.259 \t| Train acc: 0.38 \t| Test acc: 0.39\n",
      "Epoch: 117 \t| Train loss: 0.259 \t| Train acc: 0.38 \t| Test acc: 0.39\n",
      "Epoch: 118 \t| Train loss: 0.259 \t| Train acc: 0.38 \t| Test acc: 0.4\n",
      "Epoch: 119 \t| Train loss: 0.259 \t| Train acc: 0.38 \t| Test acc: 0.4\n",
      "Epoch: 120 \t| Train loss: 0.259 \t| Train acc: 0.38 \t| Test acc: 0.4\n",
      "Epoch: 121 \t| Train loss: 0.259 \t| Train acc: 0.39 \t| Test acc: 0.4\n",
      "Epoch: 122 \t| Train loss: 0.259 \t| Train acc: 0.39 \t| Test acc: 0.4\n",
      "Epoch: 123 \t| Train loss: 0.259 \t| Train acc: 0.4 \t| Test acc: 0.41\n",
      "Epoch: 124 \t| Train loss: 0.259 \t| Train acc: 0.4 \t| Test acc: 0.41\n",
      "Epoch: 125 \t| Train loss: 0.258 \t| Train acc: 0.4 \t| Test acc: 0.41\n",
      "Epoch: 126 \t| Train loss: 0.258 \t| Train acc: 0.4 \t| Test acc: 0.41\n",
      "Epoch: 127 \t| Train loss: 0.258 \t| Train acc: 0.4 \t| Test acc: 0.41\n",
      "Epoch: 128 \t| Train loss: 0.258 \t| Train acc: 0.41 \t| Test acc: 0.42\n",
      "Epoch: 129 \t| Train loss: 0.258 \t| Train acc: 0.41 \t| Test acc: 0.42\n",
      "Epoch: 130 \t| Train loss: 0.258 \t| Train acc: 0.42 \t| Test acc: 0.42\n",
      "Epoch: 131 \t| Train loss: 0.258 \t| Train acc: 0.42 \t| Test acc: 0.42\n",
      "Epoch: 132 \t| Train loss: 0.258 \t| Train acc: 0.42 \t| Test acc: 0.43\n",
      "Epoch: 133 \t| Train loss: 0.258 \t| Train acc: 0.42 \t| Test acc: 0.43\n",
      "Epoch: 134 \t| Train loss: 0.258 \t| Train acc: 0.43 \t| Test acc: 0.43\n",
      "Epoch: 135 \t| Train loss: 0.258 \t| Train acc: 0.43 \t| Test acc: 0.43\n",
      "Epoch: 136 \t| Train loss: 0.258 \t| Train acc: 0.43 \t| Test acc: 0.44\n",
      "Epoch: 137 \t| Train loss: 0.258 \t| Train acc: 0.43 \t| Test acc: 0.44\n",
      "Epoch: 138 \t| Train loss: 0.258 \t| Train acc: 0.45 \t| Test acc: 0.44\n",
      "Epoch: 139 \t| Train loss: 0.258 \t| Train acc: 0.46 \t| Test acc: 0.44\n",
      "Epoch: 140 \t| Train loss: 0.257 \t| Train acc: 0.47 \t| Test acc: 0.45\n",
      "Epoch: 141 \t| Train loss: 0.257 \t| Train acc: 0.47 \t| Test acc: 0.45\n",
      "Epoch: 142 \t| Train loss: 0.257 \t| Train acc: 0.47 \t| Test acc: 0.45\n",
      "Epoch: 143 \t| Train loss: 0.257 \t| Train acc: 0.48 \t| Test acc: 0.45\n",
      "Epoch: 144 \t| Train loss: 0.257 \t| Train acc: 0.48 \t| Test acc: 0.45\n",
      "Epoch: 145 \t| Train loss: 0.257 \t| Train acc: 0.48 \t| Test acc: 0.46\n",
      "Epoch: 146 \t| Train loss: 0.257 \t| Train acc: 0.48 \t| Test acc: 0.46\n",
      "Epoch: 147 \t| Train loss: 0.257 \t| Train acc: 0.48 \t| Test acc: 0.46\n",
      "Epoch: 148 \t| Train loss: 0.257 \t| Train acc: 0.48 \t| Test acc: 0.46\n",
      "Epoch: 149 \t| Train loss: 0.257 \t| Train acc: 0.49 \t| Test acc: 0.46\n",
      "Epoch: 150 \t| Train loss: 0.257 \t| Train acc: 0.49 \t| Test acc: 0.47\n",
      "Epoch: 151 \t| Train loss: 0.257 \t| Train acc: 0.49 \t| Test acc: 0.47\n",
      "Epoch: 152 \t| Train loss: 0.257 \t| Train acc: 0.49 \t| Test acc: 0.47\n",
      "Epoch: 153 \t| Train loss: 0.257 \t| Train acc: 0.5 \t| Test acc: 0.47\n",
      "Epoch: 154 \t| Train loss: 0.257 \t| Train acc: 0.5 \t| Test acc: 0.47\n",
      "Epoch: 155 \t| Train loss: 0.257 \t| Train acc: 0.5 \t| Test acc: 0.47\n",
      "Epoch: 156 \t| Train loss: 0.256 \t| Train acc: 0.5 \t| Test acc: 0.48\n",
      "Epoch: 157 \t| Train loss: 0.256 \t| Train acc: 0.5 \t| Test acc: 0.48\n",
      "Epoch: 158 \t| Train loss: 0.256 \t| Train acc: 0.51 \t| Test acc: 0.48\n",
      "Epoch: 159 \t| Train loss: 0.256 \t| Train acc: 0.51 \t| Test acc: 0.48\n",
      "Epoch: 160 \t| Train loss: 0.256 \t| Train acc: 0.51 \t| Test acc: 0.48\n",
      "Epoch: 161 \t| Train loss: 0.256 \t| Train acc: 0.52 \t| Test acc: 0.48\n",
      "Epoch: 162 \t| Train loss: 0.256 \t| Train acc: 0.51 \t| Test acc: 0.49\n",
      "Epoch: 163 \t| Train loss: 0.256 \t| Train acc: 0.51 \t| Test acc: 0.49\n",
      "Epoch: 164 \t| Train loss: 0.256 \t| Train acc: 0.51 \t| Test acc: 0.49\n",
      "Epoch: 165 \t| Train loss: 0.256 \t| Train acc: 0.52 \t| Test acc: 0.49\n",
      "Epoch: 166 \t| Train loss: 0.256 \t| Train acc: 0.52 \t| Test acc: 0.49\n",
      "Epoch: 167 \t| Train loss: 0.256 \t| Train acc: 0.52 \t| Test acc: 0.49\n",
      "Epoch: 168 \t| Train loss: 0.256 \t| Train acc: 0.52 \t| Test acc: 0.49\n",
      "Epoch: 169 \t| Train loss: 0.256 \t| Train acc: 0.52 \t| Test acc: 0.5\n",
      "Epoch: 170 \t| Train loss: 0.256 \t| Train acc: 0.52 \t| Test acc: 0.5\n",
      "Epoch: 171 \t| Train loss: 0.256 \t| Train acc: 0.53 \t| Test acc: 0.5\n",
      "Epoch: 172 \t| Train loss: 0.256 \t| Train acc: 0.53 \t| Test acc: 0.5\n",
      "Epoch: 173 \t| Train loss: 0.255 \t| Train acc: 0.54 \t| Test acc: 0.5\n",
      "Epoch: 174 \t| Train loss: 0.255 \t| Train acc: 0.54 \t| Test acc: 0.5\n",
      "Epoch: 175 \t| Train loss: 0.255 \t| Train acc: 0.54 \t| Test acc: 0.51\n",
      "Epoch: 176 \t| Train loss: 0.255 \t| Train acc: 0.54 \t| Test acc: 0.51\n",
      "Epoch: 177 \t| Train loss: 0.255 \t| Train acc: 0.54 \t| Test acc: 0.51\n",
      "Epoch: 178 \t| Train loss: 0.255 \t| Train acc: 0.54 \t| Test acc: 0.51\n",
      "Epoch: 179 \t| Train loss: 0.255 \t| Train acc: 0.55 \t| Test acc: 0.51\n",
      "Epoch: 180 \t| Train loss: 0.255 \t| Train acc: 0.55 \t| Test acc: 0.51\n",
      "Epoch: 181 \t| Train loss: 0.255 \t| Train acc: 0.55 \t| Test acc: 0.51\n",
      "Epoch: 182 \t| Train loss: 0.255 \t| Train acc: 0.55 \t| Test acc: 0.51\n",
      "Epoch: 183 \t| Train loss: 0.255 \t| Train acc: 0.55 \t| Test acc: 0.51\n",
      "Epoch: 184 \t| Train loss: 0.255 \t| Train acc: 0.55 \t| Test acc: 0.52\n",
      "Epoch: 185 \t| Train loss: 0.255 \t| Train acc: 0.55 \t| Test acc: 0.52\n",
      "Epoch: 186 \t| Train loss: 0.255 \t| Train acc: 0.55 \t| Test acc: 0.52\n",
      "Epoch: 187 \t| Train loss: 0.255 \t| Train acc: 0.55 \t| Test acc: 0.52\n",
      "Epoch: 188 \t| Train loss: 0.255 \t| Train acc: 0.55 \t| Test acc: 0.52\n",
      "Epoch: 189 \t| Train loss: 0.255 \t| Train acc: 0.55 \t| Test acc: 0.52\n",
      "Epoch: 190 \t| Train loss: 0.255 \t| Train acc: 0.56 \t| Test acc: 0.52\n",
      "Epoch: 191 \t| Train loss: 0.254 \t| Train acc: 0.56 \t| Test acc: 0.52\n",
      "Epoch: 192 \t| Train loss: 0.254 \t| Train acc: 0.56 \t| Test acc: 0.52\n",
      "Epoch: 193 \t| Train loss: 0.254 \t| Train acc: 0.56 \t| Test acc: 0.53\n",
      "Epoch: 194 \t| Train loss: 0.254 \t| Train acc: 0.56 \t| Test acc: 0.53\n",
      "Epoch: 195 \t| Train loss: 0.254 \t| Train acc: 0.56 \t| Test acc: 0.53\n",
      "Epoch: 196 \t| Train loss: 0.254 \t| Train acc: 0.56 \t| Test acc: 0.53\n",
      "Epoch: 197 \t| Train loss: 0.254 \t| Train acc: 0.56 \t| Test acc: 0.53\n",
      "Epoch: 198 \t| Train loss: 0.254 \t| Train acc: 0.55 \t| Test acc: 0.53\n",
      "Epoch: 199 \t| Train loss: 0.254 \t| Train acc: 0.55 \t| Test acc: 0.53\n",
      "Epoch: 200 \t| Train loss: 0.254 \t| Train acc: 0.55 \t| Test acc: 0.53\n",
      "Epoch: 201 \t| Train loss: 0.254 \t| Train acc: 0.55 \t| Test acc: 0.53\n",
      "Epoch: 202 \t| Train loss: 0.254 \t| Train acc: 0.55 \t| Test acc: 0.53\n",
      "Epoch: 203 \t| Train loss: 0.254 \t| Train acc: 0.55 \t| Test acc: 0.54\n",
      "Epoch: 204 \t| Train loss: 0.254 \t| Train acc: 0.55 \t| Test acc: 0.54\n",
      "Epoch: 205 \t| Train loss: 0.254 \t| Train acc: 0.55 \t| Test acc: 0.54\n",
      "Epoch: 206 \t| Train loss: 0.254 \t| Train acc: 0.55 \t| Test acc: 0.54\n",
      "Epoch: 207 \t| Train loss: 0.254 \t| Train acc: 0.55 \t| Test acc: 0.54\n",
      "Epoch: 208 \t| Train loss: 0.254 \t| Train acc: 0.55 \t| Test acc: 0.54\n",
      "Epoch: 209 \t| Train loss: 0.254 \t| Train acc: 0.55 \t| Test acc: 0.54\n",
      "Epoch: 210 \t| Train loss: 0.253 \t| Train acc: 0.55 \t| Test acc: 0.54\n",
      "Epoch: 211 \t| Train loss: 0.253 \t| Train acc: 0.55 \t| Test acc: 0.54\n",
      "Epoch: 212 \t| Train loss: 0.253 \t| Train acc: 0.55 \t| Test acc: 0.54\n",
      "Epoch: 213 \t| Train loss: 0.253 \t| Train acc: 0.55 \t| Test acc: 0.54\n",
      "Epoch: 214 \t| Train loss: 0.253 \t| Train acc: 0.55 \t| Test acc: 0.54\n",
      "Epoch: 215 \t| Train loss: 0.253 \t| Train acc: 0.55 \t| Test acc: 0.54\n",
      "Epoch: 216 \t| Train loss: 0.253 \t| Train acc: 0.55 \t| Test acc: 0.55\n",
      "Epoch: 217 \t| Train loss: 0.253 \t| Train acc: 0.55 \t| Test acc: 0.55\n",
      "Epoch: 218 \t| Train loss: 0.253 \t| Train acc: 0.55 \t| Test acc: 0.55\n",
      "Epoch: 219 \t| Train loss: 0.253 \t| Train acc: 0.55 \t| Test acc: 0.55\n",
      "Epoch: 220 \t| Train loss: 0.253 \t| Train acc: 0.56 \t| Test acc: 0.55\n",
      "Epoch: 221 \t| Train loss: 0.253 \t| Train acc: 0.56 \t| Test acc: 0.55\n",
      "Epoch: 222 \t| Train loss: 0.253 \t| Train acc: 0.56 \t| Test acc: 0.55\n",
      "Epoch: 223 \t| Train loss: 0.253 \t| Train acc: 0.56 \t| Test acc: 0.55\n",
      "Epoch: 224 \t| Train loss: 0.253 \t| Train acc: 0.56 \t| Test acc: 0.55\n",
      "Epoch: 225 \t| Train loss: 0.253 \t| Train acc: 0.57 \t| Test acc: 0.55\n",
      "Epoch: 226 \t| Train loss: 0.253 \t| Train acc: 0.57 \t| Test acc: 0.55\n",
      "Epoch: 227 \t| Train loss: 0.253 \t| Train acc: 0.57 \t| Test acc: 0.55\n",
      "Epoch: 228 \t| Train loss: 0.253 \t| Train acc: 0.57 \t| Test acc: 0.56\n",
      "Epoch: 229 \t| Train loss: 0.252 \t| Train acc: 0.57 \t| Test acc: 0.56\n",
      "Epoch: 230 \t| Train loss: 0.252 \t| Train acc: 0.58 \t| Test acc: 0.56\n",
      "Epoch: 231 \t| Train loss: 0.252 \t| Train acc: 0.58 \t| Test acc: 0.56\n",
      "Epoch: 232 \t| Train loss: 0.252 \t| Train acc: 0.57 \t| Test acc: 0.56\n",
      "Epoch: 233 \t| Train loss: 0.252 \t| Train acc: 0.57 \t| Test acc: 0.56\n",
      "Epoch: 234 \t| Train loss: 0.252 \t| Train acc: 0.58 \t| Test acc: 0.56\n",
      "Epoch: 235 \t| Train loss: 0.252 \t| Train acc: 0.58 \t| Test acc: 0.56\n",
      "Epoch: 236 \t| Train loss: 0.252 \t| Train acc: 0.58 \t| Test acc: 0.56\n",
      "Epoch: 237 \t| Train loss: 0.252 \t| Train acc: 0.58 \t| Test acc: 0.56\n",
      "Epoch: 238 \t| Train loss: 0.252 \t| Train acc: 0.58 \t| Test acc: 0.56\n",
      "Epoch: 239 \t| Train loss: 0.252 \t| Train acc: 0.58 \t| Test acc: 0.56\n",
      "Epoch: 240 \t| Train loss: 0.252 \t| Train acc: 0.58 \t| Test acc: 0.56\n",
      "Epoch: 241 \t| Train loss: 0.252 \t| Train acc: 0.59 \t| Test acc: 0.56\n",
      "Epoch: 242 \t| Train loss: 0.252 \t| Train acc: 0.59 \t| Test acc: 0.56\n",
      "Epoch: 243 \t| Train loss: 0.252 \t| Train acc: 0.59 \t| Test acc: 0.56\n",
      "Epoch: 244 \t| Train loss: 0.252 \t| Train acc: 0.59 \t| Test acc: 0.56\n",
      "Epoch: 245 \t| Train loss: 0.252 \t| Train acc: 0.59 \t| Test acc: 0.56\n",
      "Epoch: 246 \t| Train loss: 0.251 \t| Train acc: 0.6 \t| Test acc: 0.57\n",
      "Epoch: 247 \t| Train loss: 0.251 \t| Train acc: 0.6 \t| Test acc: 0.57\n",
      "Epoch: 248 \t| Train loss: 0.251 \t| Train acc: 0.6 \t| Test acc: 0.57\n",
      "Epoch: 249 \t| Train loss: 0.251 \t| Train acc: 0.59 \t| Test acc: 0.57\n",
      "Epoch: 250 \t| Train loss: 0.251 \t| Train acc: 0.59 \t| Test acc: 0.57\n",
      "Epoch: 251 \t| Train loss: 0.251 \t| Train acc: 0.59 \t| Test acc: 0.57\n",
      "Epoch: 252 \t| Train loss: 0.251 \t| Train acc: 0.59 \t| Test acc: 0.57\n",
      "Epoch: 253 \t| Train loss: 0.251 \t| Train acc: 0.59 \t| Test acc: 0.57\n",
      "Epoch: 254 \t| Train loss: 0.251 \t| Train acc: 0.59 \t| Test acc: 0.57\n",
      "Epoch: 255 \t| Train loss: 0.251 \t| Train acc: 0.59 \t| Test acc: 0.57\n",
      "Epoch: 256 \t| Train loss: 0.251 \t| Train acc: 0.59 \t| Test acc: 0.57\n",
      "Epoch: 257 \t| Train loss: 0.25 \t| Train acc: 0.6 \t| Test acc: 0.57\n",
      "Epoch: 258 \t| Train loss: 0.25 \t| Train acc: 0.6 \t| Test acc: 0.57\n",
      "Epoch: 259 \t| Train loss: 0.25 \t| Train acc: 0.6 \t| Test acc: 0.58\n",
      "Epoch: 260 \t| Train loss: 0.25 \t| Train acc: 0.6 \t| Test acc: 0.58\n",
      "Epoch: 261 \t| Train loss: 0.25 \t| Train acc: 0.6 \t| Test acc: 0.58\n",
      "Epoch: 262 \t| Train loss: 0.25 \t| Train acc: 0.6 \t| Test acc: 0.58\n",
      "Epoch: 263 \t| Train loss: 0.25 \t| Train acc: 0.6 \t| Test acc: 0.58\n",
      "Epoch: 264 \t| Train loss: 0.25 \t| Train acc: 0.6 \t| Test acc: 0.58\n",
      "Epoch: 265 \t| Train loss: 0.25 \t| Train acc: 0.61 \t| Test acc: 0.58\n",
      "Epoch: 266 \t| Train loss: 0.25 \t| Train acc: 0.61 \t| Test acc: 0.58\n",
      "Epoch: 267 \t| Train loss: 0.25 \t| Train acc: 0.61 \t| Test acc: 0.58\n",
      "Epoch: 268 \t| Train loss: 0.25 \t| Train acc: 0.61 \t| Test acc: 0.58\n",
      "Epoch: 269 \t| Train loss: 0.249 \t| Train acc: 0.61 \t| Test acc: 0.58\n",
      "Epoch: 270 \t| Train loss: 0.249 \t| Train acc: 0.61 \t| Test acc: 0.58\n",
      "Epoch: 271 \t| Train loss: 0.249 \t| Train acc: 0.61 \t| Test acc: 0.58\n",
      "Epoch: 272 \t| Train loss: 0.249 \t| Train acc: 0.61 \t| Test acc: 0.58\n",
      "Epoch: 273 \t| Train loss: 0.249 \t| Train acc: 0.61 \t| Test acc: 0.58\n",
      "Epoch: 274 \t| Train loss: 0.249 \t| Train acc: 0.62 \t| Test acc: 0.59\n",
      "Epoch: 275 \t| Train loss: 0.249 \t| Train acc: 0.62 \t| Test acc: 0.59\n",
      "Epoch: 276 \t| Train loss: 0.249 \t| Train acc: 0.62 \t| Test acc: 0.59\n",
      "Epoch: 277 \t| Train loss: 0.249 \t| Train acc: 0.62 \t| Test acc: 0.59\n",
      "Epoch: 278 \t| Train loss: 0.249 \t| Train acc: 0.62 \t| Test acc: 0.59\n",
      "Epoch: 279 \t| Train loss: 0.248 \t| Train acc: 0.62 \t| Test acc: 0.59\n",
      "Epoch: 280 \t| Train loss: 0.248 \t| Train acc: 0.62 \t| Test acc: 0.59\n",
      "Epoch: 281 \t| Train loss: 0.248 \t| Train acc: 0.63 \t| Test acc: 0.59\n",
      "Epoch: 282 \t| Train loss: 0.248 \t| Train acc: 0.63 \t| Test acc: 0.59\n",
      "Epoch: 283 \t| Train loss: 0.248 \t| Train acc: 0.63 \t| Test acc: 0.59\n",
      "Epoch: 284 \t| Train loss: 0.248 \t| Train acc: 0.63 \t| Test acc: 0.59\n",
      "Epoch: 285 \t| Train loss: 0.248 \t| Train acc: 0.63 \t| Test acc: 0.59\n",
      "Epoch: 286 \t| Train loss: 0.248 \t| Train acc: 0.63 \t| Test acc: 0.59\n",
      "Epoch: 287 \t| Train loss: 0.248 \t| Train acc: 0.63 \t| Test acc: 0.59\n",
      "Epoch: 288 \t| Train loss: 0.248 \t| Train acc: 0.63 \t| Test acc: 0.59\n",
      "Epoch: 289 \t| Train loss: 0.247 \t| Train acc: 0.63 \t| Test acc: 0.59\n",
      "Epoch: 290 \t| Train loss: 0.247 \t| Train acc: 0.63 \t| Test acc: 0.59\n",
      "Epoch: 291 \t| Train loss: 0.247 \t| Train acc: 0.63 \t| Test acc: 0.59\n",
      "Epoch: 292 \t| Train loss: 0.247 \t| Train acc: 0.63 \t| Test acc: 0.6\n",
      "Epoch: 293 \t| Train loss: 0.247 \t| Train acc: 0.64 \t| Test acc: 0.6\n",
      "Epoch: 294 \t| Train loss: 0.247 \t| Train acc: 0.64 \t| Test acc: 0.6\n",
      "Epoch: 295 \t| Train loss: 0.247 \t| Train acc: 0.64 \t| Test acc: 0.6\n",
      "Epoch: 296 \t| Train loss: 0.247 \t| Train acc: 0.64 \t| Test acc: 0.6\n",
      "Epoch: 297 \t| Train loss: 0.247 \t| Train acc: 0.64 \t| Test acc: 0.6\n",
      "Epoch: 298 \t| Train loss: 0.246 \t| Train acc: 0.64 \t| Test acc: 0.6\n",
      "Epoch: 299 \t| Train loss: 0.246 \t| Train acc: 0.64 \t| Test acc: 0.6\n",
      "Epoch: 300 \t| Train loss: 0.246 \t| Train acc: 0.64 \t| Test acc: 0.6\n",
      "Epoch: 301 \t| Train loss: 0.246 \t| Train acc: 0.64 \t| Test acc: 0.6\n",
      "Epoch: 302 \t| Train loss: 0.246 \t| Train acc: 0.64 \t| Test acc: 0.6\n",
      "Epoch: 303 \t| Train loss: 0.246 \t| Train acc: 0.64 \t| Test acc: 0.6\n",
      "Epoch: 304 \t| Train loss: 0.246 \t| Train acc: 0.64 \t| Test acc: 0.6\n",
      "Epoch: 305 \t| Train loss: 0.246 \t| Train acc: 0.64 \t| Test acc: 0.6\n",
      "Epoch: 306 \t| Train loss: 0.245 \t| Train acc: 0.64 \t| Test acc: 0.6\n",
      "Epoch: 307 \t| Train loss: 0.245 \t| Train acc: 0.64 \t| Test acc: 0.61\n",
      "Epoch: 308 \t| Train loss: 0.245 \t| Train acc: 0.64 \t| Test acc: 0.61\n",
      "Epoch: 309 \t| Train loss: 0.245 \t| Train acc: 0.64 \t| Test acc: 0.61\n",
      "Epoch: 310 \t| Train loss: 0.245 \t| Train acc: 0.64 \t| Test acc: 0.61\n",
      "Epoch: 311 \t| Train loss: 0.245 \t| Train acc: 0.64 \t| Test acc: 0.61\n",
      "Epoch: 312 \t| Train loss: 0.245 \t| Train acc: 0.64 \t| Test acc: 0.61\n",
      "Epoch: 313 \t| Train loss: 0.245 \t| Train acc: 0.64 \t| Test acc: 0.61\n",
      "Epoch: 314 \t| Train loss: 0.244 \t| Train acc: 0.64 \t| Test acc: 0.61\n",
      "Epoch: 315 \t| Train loss: 0.244 \t| Train acc: 0.65 \t| Test acc: 0.61\n",
      "Epoch: 316 \t| Train loss: 0.244 \t| Train acc: 0.65 \t| Test acc: 0.61\n",
      "Epoch: 317 \t| Train loss: 0.244 \t| Train acc: 0.65 \t| Test acc: 0.61\n",
      "Epoch: 318 \t| Train loss: 0.244 \t| Train acc: 0.65 \t| Test acc: 0.61\n",
      "Epoch: 319 \t| Train loss: 0.244 \t| Train acc: 0.65 \t| Test acc: 0.62\n",
      "Epoch: 320 \t| Train loss: 0.243 \t| Train acc: 0.66 \t| Test acc: 0.62\n",
      "Epoch: 321 \t| Train loss: 0.243 \t| Train acc: 0.66 \t| Test acc: 0.62\n",
      "Epoch: 322 \t| Train loss: 0.243 \t| Train acc: 0.66 \t| Test acc: 0.62\n",
      "Epoch: 323 \t| Train loss: 0.243 \t| Train acc: 0.66 \t| Test acc: 0.62\n",
      "Epoch: 324 \t| Train loss: 0.243 \t| Train acc: 0.67 \t| Test acc: 0.62\n",
      "Epoch: 325 \t| Train loss: 0.243 \t| Train acc: 0.67 \t| Test acc: 0.62\n",
      "Epoch: 326 \t| Train loss: 0.242 \t| Train acc: 0.66 \t| Test acc: 0.62\n",
      "Epoch: 327 \t| Train loss: 0.242 \t| Train acc: 0.66 \t| Test acc: 0.62\n",
      "Epoch: 328 \t| Train loss: 0.242 \t| Train acc: 0.67 \t| Test acc: 0.62\n",
      "Epoch: 329 \t| Train loss: 0.242 \t| Train acc: 0.67 \t| Test acc: 0.63\n",
      "Epoch: 330 \t| Train loss: 0.242 \t| Train acc: 0.67 \t| Test acc: 0.63\n",
      "Epoch: 331 \t| Train loss: 0.242 \t| Train acc: 0.67 \t| Test acc: 0.63\n",
      "Epoch: 332 \t| Train loss: 0.241 \t| Train acc: 0.67 \t| Test acc: 0.63\n",
      "Epoch: 333 \t| Train loss: 0.241 \t| Train acc: 0.67 \t| Test acc: 0.63\n",
      "Epoch: 334 \t| Train loss: 0.241 \t| Train acc: 0.67 \t| Test acc: 0.63\n",
      "Epoch: 335 \t| Train loss: 0.241 \t| Train acc: 0.67 \t| Test acc: 0.63\n",
      "Epoch: 336 \t| Train loss: 0.241 \t| Train acc: 0.67 \t| Test acc: 0.63\n",
      "Epoch: 337 \t| Train loss: 0.241 \t| Train acc: 0.67 \t| Test acc: 0.63\n",
      "Epoch: 338 \t| Train loss: 0.24 \t| Train acc: 0.67 \t| Test acc: 0.63\n",
      "Epoch: 339 \t| Train loss: 0.24 \t| Train acc: 0.67 \t| Test acc: 0.63\n",
      "Epoch: 340 \t| Train loss: 0.24 \t| Train acc: 0.67 \t| Test acc: 0.63\n",
      "Epoch: 341 \t| Train loss: 0.24 \t| Train acc: 0.67 \t| Test acc: 0.63\n",
      "Epoch: 342 \t| Train loss: 0.24 \t| Train acc: 0.67 \t| Test acc: 0.63\n",
      "Epoch: 343 \t| Train loss: 0.24 \t| Train acc: 0.68 \t| Test acc: 0.63\n",
      "Epoch: 344 \t| Train loss: 0.239 \t| Train acc: 0.68 \t| Test acc: 0.64\n",
      "Epoch: 345 \t| Train loss: 0.239 \t| Train acc: 0.68 \t| Test acc: 0.64\n",
      "Epoch: 346 \t| Train loss: 0.239 \t| Train acc: 0.68 \t| Test acc: 0.64\n",
      "Epoch: 347 \t| Train loss: 0.239 \t| Train acc: 0.68 \t| Test acc: 0.64\n",
      "Epoch: 348 \t| Train loss: 0.239 \t| Train acc: 0.68 \t| Test acc: 0.64\n",
      "Epoch: 349 \t| Train loss: 0.239 \t| Train acc: 0.68 \t| Test acc: 0.64\n",
      "Epoch: 350 \t| Train loss: 0.238 \t| Train acc: 0.68 \t| Test acc: 0.64\n",
      "Epoch: 351 \t| Train loss: 0.238 \t| Train acc: 0.68 \t| Test acc: 0.64\n",
      "Epoch: 352 \t| Train loss: 0.238 \t| Train acc: 0.68 \t| Test acc: 0.64\n",
      "Epoch: 353 \t| Train loss: 0.238 \t| Train acc: 0.68 \t| Test acc: 0.64\n",
      "Epoch: 354 \t| Train loss: 0.238 \t| Train acc: 0.68 \t| Test acc: 0.65\n",
      "Epoch: 355 \t| Train loss: 0.238 \t| Train acc: 0.68 \t| Test acc: 0.65\n",
      "Epoch: 356 \t| Train loss: 0.237 \t| Train acc: 0.68 \t| Test acc: 0.65\n",
      "Epoch: 357 \t| Train loss: 0.237 \t| Train acc: 0.68 \t| Test acc: 0.65\n",
      "Epoch: 358 \t| Train loss: 0.237 \t| Train acc: 0.68 \t| Test acc: 0.65\n",
      "Epoch: 359 \t| Train loss: 0.237 \t| Train acc: 0.68 \t| Test acc: 0.65\n",
      "Epoch: 360 \t| Train loss: 0.237 \t| Train acc: 0.68 \t| Test acc: 0.65\n",
      "Epoch: 361 \t| Train loss: 0.237 \t| Train acc: 0.68 \t| Test acc: 0.65\n",
      "Epoch: 362 \t| Train loss: 0.236 \t| Train acc: 0.69 \t| Test acc: 0.65\n",
      "Epoch: 363 \t| Train loss: 0.236 \t| Train acc: 0.69 \t| Test acc: 0.65\n",
      "Epoch: 364 \t| Train loss: 0.236 \t| Train acc: 0.69 \t| Test acc: 0.66\n",
      "Epoch: 365 \t| Train loss: 0.236 \t| Train acc: 0.69 \t| Test acc: 0.66\n",
      "Epoch: 366 \t| Train loss: 0.236 \t| Train acc: 0.69 \t| Test acc: 0.66\n",
      "Epoch: 367 \t| Train loss: 0.236 \t| Train acc: 0.7 \t| Test acc: 0.66\n",
      "Epoch: 368 \t| Train loss: 0.235 \t| Train acc: 0.7 \t| Test acc: 0.66\n",
      "Epoch: 369 \t| Train loss: 0.235 \t| Train acc: 0.7 \t| Test acc: 0.66\n",
      "Epoch: 370 \t| Train loss: 0.235 \t| Train acc: 0.7 \t| Test acc: 0.66\n",
      "Epoch: 371 \t| Train loss: 0.235 \t| Train acc: 0.7 \t| Test acc: 0.66\n",
      "Epoch: 372 \t| Train loss: 0.235 \t| Train acc: 0.7 \t| Test acc: 0.66\n",
      "Epoch: 373 \t| Train loss: 0.235 \t| Train acc: 0.7 \t| Test acc: 0.66\n",
      "Epoch: 374 \t| Train loss: 0.234 \t| Train acc: 0.7 \t| Test acc: 0.66\n",
      "Epoch: 375 \t| Train loss: 0.234 \t| Train acc: 0.7 \t| Test acc: 0.66\n",
      "Epoch: 376 \t| Train loss: 0.234 \t| Train acc: 0.7 \t| Test acc: 0.66\n",
      "Epoch: 377 \t| Train loss: 0.234 \t| Train acc: 0.7 \t| Test acc: 0.66\n",
      "Epoch: 378 \t| Train loss: 0.234 \t| Train acc: 0.7 \t| Test acc: 0.66\n",
      "Epoch: 379 \t| Train loss: 0.234 \t| Train acc: 0.7 \t| Test acc: 0.66\n",
      "Epoch: 380 \t| Train loss: 0.234 \t| Train acc: 0.7 \t| Test acc: 0.66\n",
      "Epoch: 381 \t| Train loss: 0.233 \t| Train acc: 0.7 \t| Test acc: 0.66\n",
      "Epoch: 382 \t| Train loss: 0.233 \t| Train acc: 0.7 \t| Test acc: 0.66\n",
      "Epoch: 383 \t| Train loss: 0.233 \t| Train acc: 0.7 \t| Test acc: 0.66\n",
      "Epoch: 384 \t| Train loss: 0.233 \t| Train acc: 0.7 \t| Test acc: 0.66\n",
      "Epoch: 385 \t| Train loss: 0.233 \t| Train acc: 0.7 \t| Test acc: 0.67\n",
      "Epoch: 386 \t| Train loss: 0.233 \t| Train acc: 0.7 \t| Test acc: 0.67\n",
      "Epoch: 387 \t| Train loss: 0.233 \t| Train acc: 0.7 \t| Test acc: 0.67\n",
      "Epoch: 388 \t| Train loss: 0.232 \t| Train acc: 0.7 \t| Test acc: 0.67\n",
      "Epoch: 389 \t| Train loss: 0.232 \t| Train acc: 0.7 \t| Test acc: 0.67\n",
      "Epoch: 390 \t| Train loss: 0.232 \t| Train acc: 0.7 \t| Test acc: 0.67\n",
      "Epoch: 391 \t| Train loss: 0.232 \t| Train acc: 0.7 \t| Test acc: 0.67\n",
      "Epoch: 392 \t| Train loss: 0.232 \t| Train acc: 0.7 \t| Test acc: 0.67\n",
      "Epoch: 393 \t| Train loss: 0.232 \t| Train acc: 0.7 \t| Test acc: 0.67\n",
      "Epoch: 394 \t| Train loss: 0.232 \t| Train acc: 0.7 \t| Test acc: 0.67\n",
      "Epoch: 395 \t| Train loss: 0.231 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 396 \t| Train loss: 0.231 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 397 \t| Train loss: 0.231 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 398 \t| Train loss: 0.231 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 399 \t| Train loss: 0.231 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 400 \t| Train loss: 0.231 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 401 \t| Train loss: 0.231 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 402 \t| Train loss: 0.231 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 403 \t| Train loss: 0.23 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 404 \t| Train loss: 0.23 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 405 \t| Train loss: 0.23 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 406 \t| Train loss: 0.23 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 407 \t| Train loss: 0.23 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 408 \t| Train loss: 0.23 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 409 \t| Train loss: 0.23 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 410 \t| Train loss: 0.23 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 411 \t| Train loss: 0.229 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 412 \t| Train loss: 0.229 \t| Train acc: 0.69 \t| Test acc: 0.67\n",
      "Epoch: 413 \t| Train loss: 0.229 \t| Train acc: 0.69 \t| Test acc: 0.68\n",
      "Epoch: 414 \t| Train loss: 0.229 \t| Train acc: 0.69 \t| Test acc: 0.68\n",
      "Epoch: 415 \t| Train loss: 0.229 \t| Train acc: 0.69 \t| Test acc: 0.68\n",
      "Epoch: 416 \t| Train loss: 0.229 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 417 \t| Train loss: 0.229 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 418 \t| Train loss: 0.229 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 419 \t| Train loss: 0.229 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 420 \t| Train loss: 0.228 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 421 \t| Train loss: 0.228 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 422 \t| Train loss: 0.228 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 423 \t| Train loss: 0.228 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 424 \t| Train loss: 0.228 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 425 \t| Train loss: 0.228 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 426 \t| Train loss: 0.228 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 427 \t| Train loss: 0.228 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 428 \t| Train loss: 0.228 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 429 \t| Train loss: 0.228 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 430 \t| Train loss: 0.227 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 431 \t| Train loss: 0.227 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 432 \t| Train loss: 0.227 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 433 \t| Train loss: 0.227 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 434 \t| Train loss: 0.227 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 435 \t| Train loss: 0.227 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 436 \t| Train loss: 0.227 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 437 \t| Train loss: 0.227 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 438 \t| Train loss: 0.227 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 439 \t| Train loss: 0.227 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 440 \t| Train loss: 0.227 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 441 \t| Train loss: 0.226 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 442 \t| Train loss: 0.226 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 443 \t| Train loss: 0.226 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 444 \t| Train loss: 0.226 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 445 \t| Train loss: 0.226 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 446 \t| Train loss: 0.226 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 447 \t| Train loss: 0.226 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 448 \t| Train loss: 0.226 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 449 \t| Train loss: 0.226 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 450 \t| Train loss: 0.226 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 451 \t| Train loss: 0.226 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 452 \t| Train loss: 0.226 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 453 \t| Train loss: 0.225 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 454 \t| Train loss: 0.225 \t| Train acc: 0.7 \t| Test acc: 0.68\n",
      "Epoch: 455 \t| Train loss: 0.225 \t| Train acc: 0.71 \t| Test acc: 0.68\n",
      "Epoch: 456 \t| Train loss: 0.225 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 457 \t| Train loss: 0.225 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 458 \t| Train loss: 0.225 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 459 \t| Train loss: 0.225 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 460 \t| Train loss: 0.225 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 461 \t| Train loss: 0.225 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 462 \t| Train loss: 0.225 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 463 \t| Train loss: 0.225 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 464 \t| Train loss: 0.225 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 465 \t| Train loss: 0.224 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 466 \t| Train loss: 0.224 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 467 \t| Train loss: 0.224 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 468 \t| Train loss: 0.224 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 469 \t| Train loss: 0.224 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 470 \t| Train loss: 0.224 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 471 \t| Train loss: 0.224 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 472 \t| Train loss: 0.224 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 473 \t| Train loss: 0.224 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 474 \t| Train loss: 0.224 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 475 \t| Train loss: 0.224 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 476 \t| Train loss: 0.224 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 477 \t| Train loss: 0.223 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 478 \t| Train loss: 0.223 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 479 \t| Train loss: 0.223 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 480 \t| Train loss: 0.223 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 481 \t| Train loss: 0.223 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 482 \t| Train loss: 0.223 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 483 \t| Train loss: 0.223 \t| Train acc: 0.69 \t| Test acc: 0.69\n",
      "Epoch: 484 \t| Train loss: 0.223 \t| Train acc: 0.69 \t| Test acc: 0.69\n",
      "Epoch: 485 \t| Train loss: 0.223 \t| Train acc: 0.69 \t| Test acc: 0.69\n",
      "Epoch: 486 \t| Train loss: 0.223 \t| Train acc: 0.69 \t| Test acc: 0.69\n",
      "Epoch: 487 \t| Train loss: 0.223 \t| Train acc: 0.69 \t| Test acc: 0.69\n",
      "Epoch: 488 \t| Train loss: 0.223 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 489 \t| Train loss: 0.223 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 490 \t| Train loss: 0.223 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 491 \t| Train loss: 0.222 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 492 \t| Train loss: 0.222 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 493 \t| Train loss: 0.222 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 494 \t| Train loss: 0.222 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 495 \t| Train loss: 0.222 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 496 \t| Train loss: 0.222 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 497 \t| Train loss: 0.222 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 498 \t| Train loss: 0.222 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 499 \t| Train loss: 0.222 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 500 \t| Train loss: 0.222 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 501 \t| Train loss: 0.222 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 502 \t| Train loss: 0.222 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 503 \t| Train loss: 0.222 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 504 \t| Train loss: 0.222 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 505 \t| Train loss: 0.222 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 506 \t| Train loss: 0.222 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 507 \t| Train loss: 0.221 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 508 \t| Train loss: 0.221 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 509 \t| Train loss: 0.221 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 510 \t| Train loss: 0.221 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 511 \t| Train loss: 0.221 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 512 \t| Train loss: 0.221 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 513 \t| Train loss: 0.221 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 514 \t| Train loss: 0.221 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 515 \t| Train loss: 0.221 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 516 \t| Train loss: 0.221 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 517 \t| Train loss: 0.221 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 518 \t| Train loss: 0.221 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 519 \t| Train loss: 0.221 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 520 \t| Train loss: 0.221 \t| Train acc: 0.7 \t| Test acc: 0.69\n",
      "Epoch: 521 \t| Train loss: 0.221 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 522 \t| Train loss: 0.221 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 523 \t| Train loss: 0.221 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 524 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 525 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 526 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 527 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 528 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 529 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 530 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 531 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 532 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 533 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 534 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 535 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 536 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 537 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 538 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 539 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 540 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 541 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 542 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 543 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 544 \t| Train loss: 0.22 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 545 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 546 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 547 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 548 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 549 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 550 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 551 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 552 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 553 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 554 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.7\n",
      "Epoch: 555 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.69\n",
      "Epoch: 556 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.7\n",
      "Epoch: 557 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.7\n",
      "Epoch: 558 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.7\n",
      "Epoch: 559 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.7\n",
      "Epoch: 560 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.7\n",
      "Epoch: 561 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.7\n",
      "Epoch: 562 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.7\n",
      "Epoch: 563 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.7\n",
      "Epoch: 564 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.7\n",
      "Epoch: 565 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.7\n",
      "Epoch: 566 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.7\n",
      "Epoch: 567 \t| Train loss: 0.219 \t| Train acc: 0.71 \t| Test acc: 0.7\n",
      "Epoch: 568 \t| Train loss: 0.218 \t| Train acc: 0.71 \t| Test acc: 0.7\n",
      "Epoch: 569 \t| Train loss: 0.218 \t| Train acc: 0.71 \t| Test acc: 0.7\n",
      "Epoch: 570 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 571 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 572 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 573 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 574 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 575 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 576 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 577 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 578 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 579 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 580 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 581 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 582 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 583 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 584 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 585 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 586 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 587 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 588 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 589 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 590 \t| Train loss: 0.218 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 591 \t| Train loss: 0.218 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 592 \t| Train loss: 0.218 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 593 \t| Train loss: 0.218 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 594 \t| Train loss: 0.218 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 595 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 596 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 597 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 598 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 599 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 600 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 601 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 602 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 603 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 604 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 605 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 606 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 607 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 608 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 609 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 610 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 611 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 612 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 613 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 614 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 615 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 616 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 617 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 618 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 619 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 620 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 621 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 622 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 623 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 624 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 625 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 626 \t| Train loss: 0.217 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 627 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 628 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 629 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 630 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 631 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 632 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 633 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 634 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 635 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 636 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 637 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 638 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 639 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 640 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 641 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 642 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 643 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 644 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 645 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 646 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 647 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 648 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 649 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 650 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 651 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 652 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 653 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 654 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 655 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 656 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 657 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 658 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 659 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 660 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 661 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 662 \t| Train loss: 0.216 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 663 \t| Train loss: 0.215 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 664 \t| Train loss: 0.215 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 665 \t| Train loss: 0.215 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 666 \t| Train loss: 0.215 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 667 \t| Train loss: 0.215 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 668 \t| Train loss: 0.215 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 669 \t| Train loss: 0.215 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 670 \t| Train loss: 0.215 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 671 \t| Train loss: 0.215 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 672 \t| Train loss: 0.215 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 673 \t| Train loss: 0.215 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 674 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 675 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 676 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 677 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 678 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 679 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 680 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 681 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 682 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 683 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 684 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 685 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 686 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 687 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 688 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 689 \t| Train loss: 0.215 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 690 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 691 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 692 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 693 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 694 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 695 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 696 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 697 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 698 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 699 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 700 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 701 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 702 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 703 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 704 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 705 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 706 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 707 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 708 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 709 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 710 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 711 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 712 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 713 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 714 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 715 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 716 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 717 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 718 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 719 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 720 \t| Train loss: 0.214 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 721 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 722 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 723 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 724 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 725 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 726 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 727 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 728 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 729 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 730 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 731 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 732 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 733 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 734 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 735 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 736 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 737 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 738 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 739 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 740 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 741 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 742 \t| Train loss: 0.213 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 743 \t| Train loss: 0.213 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 744 \t| Train loss: 0.213 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 745 \t| Train loss: 0.213 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 746 \t| Train loss: 0.213 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 747 \t| Train loss: 0.213 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 748 \t| Train loss: 0.213 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 749 \t| Train loss: 0.213 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 750 \t| Train loss: 0.213 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 751 \t| Train loss: 0.213 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 752 \t| Train loss: 0.213 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 753 \t| Train loss: 0.213 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 754 \t| Train loss: 0.213 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 755 \t| Train loss: 0.213 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 756 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 757 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 758 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 759 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 760 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 761 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 762 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 763 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 764 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 765 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 766 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 767 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 768 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 769 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 770 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 771 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 772 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 773 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 774 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 775 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 776 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 777 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 778 \t| Train loss: 0.212 \t| Train acc: 0.72 \t| Test acc: 0.7\n",
      "Epoch: 779 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 780 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 781 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 782 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 783 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 784 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 785 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 786 \t| Train loss: 0.212 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 787 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 788 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 789 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 790 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 791 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 792 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 793 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 794 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 795 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 796 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 797 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 798 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 799 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 800 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 801 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 802 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 803 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 804 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 805 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 806 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 807 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 808 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 809 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 810 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 811 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 812 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 813 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 814 \t| Train loss: 0.211 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 815 \t| Train loss: 0.211 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 816 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 817 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 818 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 819 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 820 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 821 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 822 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 823 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 824 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 825 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 826 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 827 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 828 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 829 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 830 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 831 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 832 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 833 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 834 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 835 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 836 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 837 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 838 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 839 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 840 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 841 \t| Train loss: 0.21 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 842 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 843 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 844 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 845 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 846 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 847 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 848 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 849 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 850 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 851 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 852 \t| Train loss: 0.209 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 853 \t| Train loss: 0.209 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 854 \t| Train loss: 0.209 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 855 \t| Train loss: 0.209 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 856 \t| Train loss: 0.209 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 857 \t| Train loss: 0.209 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 858 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 859 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 860 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 861 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 862 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 863 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 864 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 865 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 866 \t| Train loss: 0.209 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 867 \t| Train loss: 0.208 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 868 \t| Train loss: 0.208 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 869 \t| Train loss: 0.208 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 870 \t| Train loss: 0.208 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 871 \t| Train loss: 0.208 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 872 \t| Train loss: 0.208 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 873 \t| Train loss: 0.208 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 874 \t| Train loss: 0.208 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 875 \t| Train loss: 0.208 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 876 \t| Train loss: 0.208 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 877 \t| Train loss: 0.208 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 878 \t| Train loss: 0.208 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 879 \t| Train loss: 0.208 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 880 \t| Train loss: 0.208 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 881 \t| Train loss: 0.208 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 882 \t| Train loss: 0.208 \t| Train acc: 0.73 \t| Test acc: 0.7\n",
      "Epoch: 883 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 884 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 885 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 886 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 887 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 888 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 889 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 890 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 891 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 892 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 893 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 894 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 895 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 896 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 897 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 898 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 899 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 900 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 901 \t| Train loss: 0.208 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 902 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 903 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 904 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 905 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 906 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 907 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 908 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 909 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 910 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 911 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 912 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 913 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 914 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 915 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 916 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 917 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 918 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 919 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 920 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 921 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 922 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 923 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 924 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 925 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 926 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 927 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 928 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 929 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 930 \t| Train loss: 0.207 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 931 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 932 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 933 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 934 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 935 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 936 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 937 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 938 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 939 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 940 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 941 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 942 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 943 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 944 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 945 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 946 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 947 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 948 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 949 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 950 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 951 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 952 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 953 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 954 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 955 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 956 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 957 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 958 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 959 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 960 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 961 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 962 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 963 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 964 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 965 \t| Train loss: 0.206 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 966 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 967 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 968 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 969 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 970 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 971 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 972 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 973 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 974 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 975 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 976 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 977 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 978 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 979 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 980 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 981 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 982 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 983 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 984 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 985 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 986 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 987 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 988 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 989 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 990 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 991 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 992 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 993 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 994 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 995 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 996 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 997 \t| Train loss: 0.205 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 998 \t| Train loss: 0.205 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 999 \t| Train loss: 0.205 \t| Train acc: 0.75 \t| Test acc: 0.7\n"
     ]
    }
   ],
   "source": [
    "train_losses_mlp_lim = []\n",
    "#test_losses  = []\n",
    "train_accs_mlp_lim = []\n",
    "test_accs_mlp_lim  = []\n",
    "\n",
    "for epoch in range(1000):\n",
    "    # Forward propagation (predicting train data)\n",
    "    for features, labels in data_loader_lim:\n",
    "        train_preds_mlp_lim = mlp_model_lim(features)\n",
    "        class_weights_batch = class_weights_original[labels.long()]\n",
    "        loss_function = nn.BCELoss(weight=class_weights_batch)\n",
    "\n",
    "        train_loss_mlp_lim  = loss_function(train_preds_mlp_lim, labels)\n",
    "\n",
    "        # Predicting test data #b\n",
    "        with torch.no_grad():\n",
    "            test_preds_mlp_lim = mlp_model_lim(X_validation_tensor_lim)\n",
    "            #test_loss  = loss_function(test_preds, y_test)\n",
    "\n",
    "        # Calculate accuracy #c\n",
    "        train_acc = calculate_accuracy(train_preds_mlp_lim, labels)\n",
    "        test_acc  = calculate_accuracy(test_preds_mlp_lim, y_validation_tensor)\n",
    "\n",
    "        # Backward propagation #d\n",
    "        optimizer_mlp_lim.zero_grad()\n",
    "        train_loss_mlp_lim.backward()\n",
    "\n",
    "        # Gradient descent step #e\n",
    "        optimizer_mlp_lim.step()\n",
    "\n",
    "        # Store training history #f\n",
    "        train_losses_mlp_lim.append(train_loss_mlp_lim.item())\n",
    "        #test_losses.append(test_loss.item())\n",
    "        train_accs_mlp_lim.append(train_acc.item())\n",
    "        test_accs_mlp_lim.append(test_acc.item())\n",
    "\n",
    "    # Print training data #g\n",
    "    #if epoch%100==0:\n",
    "    print(f'Epoch: {epoch} \\t|' \\\n",
    "          f' Train loss: {np.round(train_loss_mlp_lim.item(),3)} \\t|' \\\n",
    "              #f' Test loss: {np.round(test_loss.item(),3)} \\t|' \\\n",
    "          f' Train acc: {np.round(train_acc.item(),2)} \\t|' \\\n",
    "          f' Test acc: {np.round(test_acc.item(),2)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:40:10.603753900Z",
     "start_time": "2024-05-23T15:40:04.144515500Z"
    }
   },
   "id": "6318082f7d63ea1c"
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 70.33%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.815561     0.415535  0.703263     0.615548      0.715829\n",
      "recall        0.781434     0.467890  0.703263     0.624662      0.703263\n",
      "f1-score      0.798133     0.440161  0.703263     0.619147      0.708885\n",
      "support    4923.000000  1635.000000  0.703263  6558.000000   6558.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[3847 1076]\n",
      " [ 870  765]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_nn(y_validation_tensor.clone().detach(), test_preds_mlp_lim.clone().detach().round(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:40:30.804234Z",
     "start_time": "2024-05-23T15:40:30.684150300Z"
    }
   },
   "id": "d8cd464e64eb3c08"
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 70.11%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.818582     0.404762  0.701111     0.611672      0.717271\n",
      "recall        0.776253     0.469325  0.701111     0.622789      0.701111\n",
      "f1-score      0.796856     0.434659  0.701111     0.615757      0.708183\n",
      "support    5028.000000  1630.000000  0.701111  6658.000000   6658.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[3903 1125]\n",
      " [ 865  765]]\n"
     ]
    }
   ],
   "source": [
    "test_preds_mlp_lim = mlp_model_lim(X_test_tensor_lim)\n",
    "evaluate_nn(y_test_tensor.clone().detach(), test_preds_mlp_lim.clone().detach().round(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:40:44.421195300Z",
     "start_time": "2024-05-23T15:40:44.264148500Z"
    }
   },
   "id": "350a03ac2c7768d5"
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nMLP                                      [231, 1]                  --\n├─Sequential: 1-1                        [231, 1]                  --\n│    └─Linear: 2-1                       [231, 3]                  21\n│    └─ReLU: 2-2                         [231, 3]                  --\n│    └─Linear: 2-3                       [231, 1]                  4\n│    └─Sigmoid: 2-4                      [231, 1]                  --\n==========================================================================================\nTotal params: 25\nTrainable params: 25\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 0.01\n==========================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.01\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.01\n=========================================================================================="
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpsl_model_lim = MLP(num_features=6)\n",
    "summary(mlpsl_model_lim, input_size=X_train_lim.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:40:56.463472100Z",
     "start_time": "2024-05-23T15:40:56.384574200Z"
    }
   },
   "id": "bd79e53f6061b768"
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [],
   "source": [
    "optimizer_mlpsl_lim = optim.Adam(mlpsl_model_lim.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:41:08.517552700Z",
     "start_time": "2024-05-23T15:41:08.423244800Z"
    }
   },
   "id": "288be49c8e18972a"
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.68\n",
      "Epoch: 1 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 2 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 3 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 4 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 5 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 6 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 7 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 8 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 9 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 10 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 11 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 12 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 13 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 14 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 15 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 16 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 17 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 18 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 19 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 20 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 21 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 22 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 23 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 24 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 25 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 26 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 27 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 28 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 29 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 30 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 31 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 32 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 33 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 34 \t| Train loss: 0.142 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 35 \t| Train loss: 0.141 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 36 \t| Train loss: 0.141 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 37 \t| Train loss: 0.141 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 38 \t| Train loss: 0.141 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 39 \t| Train loss: 0.141 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 40 \t| Train loss: 0.141 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 41 \t| Train loss: 0.141 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 42 \t| Train loss: 0.141 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 43 \t| Train loss: 0.141 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 44 \t| Train loss: 0.141 \t| Train acc: 0.72 \t| Test acc: 0.69\n",
      "Epoch: 45 \t| Train loss: 0.141 \t| Train acc: 0.73 \t| Test acc: 0.69\n",
      "Epoch: 46 \t| Train loss: 0.141 \t| Train acc: 0.73 \t| Test acc: 0.69\n",
      "Epoch: 47 \t| Train loss: 0.141 \t| Train acc: 0.73 \t| Test acc: 0.69\n",
      "Epoch: 48 \t| Train loss: 0.141 \t| Train acc: 0.73 \t| Test acc: 0.69\n",
      "Epoch: 49 \t| Train loss: 0.141 \t| Train acc: 0.73 \t| Test acc: 0.69\n",
      "Epoch: 50 \t| Train loss: 0.141 \t| Train acc: 0.73 \t| Test acc: 0.69\n",
      "Epoch: 51 \t| Train loss: 0.141 \t| Train acc: 0.73 \t| Test acc: 0.69\n",
      "Epoch: 52 \t| Train loss: 0.141 \t| Train acc: 0.73 \t| Test acc: 0.69\n",
      "Epoch: 53 \t| Train loss: 0.141 \t| Train acc: 0.73 \t| Test acc: 0.69\n",
      "Epoch: 54 \t| Train loss: 0.141 \t| Train acc: 0.73 \t| Test acc: 0.69\n",
      "Epoch: 55 \t| Train loss: 0.141 \t| Train acc: 0.73 \t| Test acc: 0.69\n",
      "Epoch: 56 \t| Train loss: 0.141 \t| Train acc: 0.73 \t| Test acc: 0.69\n",
      "Epoch: 57 \t| Train loss: 0.141 \t| Train acc: 0.73 \t| Test acc: 0.69\n",
      "Epoch: 58 \t| Train loss: 0.141 \t| Train acc: 0.73 \t| Test acc: 0.69\n",
      "Epoch: 59 \t| Train loss: 0.141 \t| Train acc: 0.73 \t| Test acc: 0.69\n",
      "Epoch: 60 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 61 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 62 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 63 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 64 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 65 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 66 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 67 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 68 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 69 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 70 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 71 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 72 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 73 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 74 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 75 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 76 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 77 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 78 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 79 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 80 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 81 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 82 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 83 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 84 \t| Train loss: 0.141 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 85 \t| Train loss: 0.14 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 86 \t| Train loss: 0.14 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 87 \t| Train loss: 0.14 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 88 \t| Train loss: 0.14 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 89 \t| Train loss: 0.14 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 90 \t| Train loss: 0.14 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 91 \t| Train loss: 0.14 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 92 \t| Train loss: 0.14 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 93 \t| Train loss: 0.14 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 94 \t| Train loss: 0.14 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 95 \t| Train loss: 0.14 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 96 \t| Train loss: 0.14 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 97 \t| Train loss: 0.14 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 98 \t| Train loss: 0.14 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 99 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 100 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 101 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 102 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 103 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 104 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 105 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 106 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 107 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 108 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 109 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 110 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 111 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 112 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 113 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 114 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 115 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 116 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 117 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 118 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 119 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 120 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 121 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 122 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 123 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 124 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 125 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 126 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 127 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 128 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 129 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 130 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 131 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 132 \t| Train loss: 0.14 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 133 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 134 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 135 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 136 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 137 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 138 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 139 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 140 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 141 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 142 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 143 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 144 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 145 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 146 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 147 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 148 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 149 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 150 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 151 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 152 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 153 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 154 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 155 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 156 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 157 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 158 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 159 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 160 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 161 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 162 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 163 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 164 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 165 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 166 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 167 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 168 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 169 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 170 \t| Train loss: 0.139 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 171 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 172 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 173 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 174 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 175 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 176 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 177 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 178 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 179 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 180 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 181 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 182 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 183 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 184 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 185 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 186 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 187 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 188 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 189 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 190 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 191 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 192 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 193 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 194 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 195 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 196 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 197 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 198 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 199 \t| Train loss: 0.139 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 200 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 201 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 202 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 203 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 204 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 205 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 206 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 207 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 208 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 209 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 210 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 211 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 212 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 213 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 214 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 215 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 216 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 217 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 218 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 219 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 220 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 221 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 222 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 223 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 224 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 225 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 226 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 227 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 228 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 229 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 230 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 231 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 232 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 233 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 234 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 235 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 236 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 237 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 238 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 239 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 240 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 241 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 242 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 243 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 244 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 245 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 246 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 247 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 248 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 249 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 250 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 251 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 252 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 253 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 254 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 255 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 256 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 257 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 258 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 259 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 260 \t| Train loss: 0.138 \t| Train acc: 0.75 \t| Test acc: 0.69\n",
      "Epoch: 261 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 262 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 263 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 264 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 265 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 266 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 267 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 268 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 269 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 270 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 271 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 272 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 273 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 274 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 275 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.69\n",
      "Epoch: 276 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 277 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 278 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 279 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 280 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 281 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 282 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 283 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 284 \t| Train loss: 0.138 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 285 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 286 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 287 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 288 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 289 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 290 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 291 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 292 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 293 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 294 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 295 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 296 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 297 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 298 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 299 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 300 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 301 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 302 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 303 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 304 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 305 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 306 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 307 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 308 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 309 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 310 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 311 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 312 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 313 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 314 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 315 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 316 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 317 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 318 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 319 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 320 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 321 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 322 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 323 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 324 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 325 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 326 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 327 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 328 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 329 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 330 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 331 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 332 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 333 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 334 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 335 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 336 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 337 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 338 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 339 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 340 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 341 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 342 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 343 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 344 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 345 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 346 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 347 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 348 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 349 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 350 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 351 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 352 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 353 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 354 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 355 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 356 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 357 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 358 \t| Train loss: 0.137 \t| Train acc: 0.74 \t| Test acc: 0.7\n",
      "Epoch: 359 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 360 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 361 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 362 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 363 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 364 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 365 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 366 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 367 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 368 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 369 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 370 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 371 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 372 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 373 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 374 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 375 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 376 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 377 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 378 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 379 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 380 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 381 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 382 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 383 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 384 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 385 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 386 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 387 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 388 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 389 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 390 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 391 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 392 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 393 \t| Train loss: 0.137 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 394 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 395 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 396 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 397 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 398 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 399 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 400 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 401 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 402 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 403 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 404 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 405 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 406 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 407 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 408 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 409 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 410 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 411 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 412 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 413 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 414 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 415 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 416 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 417 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 418 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 419 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 420 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 421 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 422 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 423 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 424 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 425 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 426 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 427 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 428 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 429 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 430 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 431 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 432 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 433 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 434 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 435 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 436 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 437 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 438 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 439 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 440 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 441 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 442 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 443 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 444 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 445 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 446 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 447 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 448 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 449 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 450 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 451 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 452 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 453 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 454 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 455 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 456 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 457 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 458 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 459 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 460 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 461 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 462 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 463 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 464 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 465 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 466 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 467 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 468 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 469 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 470 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 471 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 472 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 473 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 474 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 475 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 476 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 477 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 478 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 479 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 480 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 481 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 482 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 483 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 484 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 485 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 486 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 487 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 488 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 489 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 490 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 491 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 492 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 493 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 494 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 495 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 496 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 497 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 498 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 499 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 500 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 501 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 502 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 503 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 504 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 505 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 506 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 507 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 508 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 509 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 510 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 511 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 512 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 513 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 514 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 515 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 516 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 517 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 518 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 519 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 520 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 521 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 522 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 523 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 524 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 525 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 526 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 527 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 528 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 529 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 530 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 531 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 532 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 533 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 534 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 535 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 536 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 537 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 538 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 539 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 540 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 541 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 542 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 543 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 544 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 545 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 546 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 547 \t| Train loss: 0.136 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 548 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 549 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 550 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 551 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 552 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 553 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 554 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 555 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 556 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 557 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 558 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 559 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 560 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 561 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 562 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 563 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 564 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 565 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 566 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 567 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 568 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 569 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 570 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 571 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 572 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 573 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 574 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 575 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 576 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 577 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 578 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 579 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 580 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 581 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 582 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 583 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 584 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 585 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 586 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 587 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 588 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 589 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 590 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 591 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 592 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 593 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 594 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 595 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 596 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 597 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 598 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 599 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 600 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 601 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 602 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 603 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 604 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 605 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 606 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 607 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.7\n",
      "Epoch: 608 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 609 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 610 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 611 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 612 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 613 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 614 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 615 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 616 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 617 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 618 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 619 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 620 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 621 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 622 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 623 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 624 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 625 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 626 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 627 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 628 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 629 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 630 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 631 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 632 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 633 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 634 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 635 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 636 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 637 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 638 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 639 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 640 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 641 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 642 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 643 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 644 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 645 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 646 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 647 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 648 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 649 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 650 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 651 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 652 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 653 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 654 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 655 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 656 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 657 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 658 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 659 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 660 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 661 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 662 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 663 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 664 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 665 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 666 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 667 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 668 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 669 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 670 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 671 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 672 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 673 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 674 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 675 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 676 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 677 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 678 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 679 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 680 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 681 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 682 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 683 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 684 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 685 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 686 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 687 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 688 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 689 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 690 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 691 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 692 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 693 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 694 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 695 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 696 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 697 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 698 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 699 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 700 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 701 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 702 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 703 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 704 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 705 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 706 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 707 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 708 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 709 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 710 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 711 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 712 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 713 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 714 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 715 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 716 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 717 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 718 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 719 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 720 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 721 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 722 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 723 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 724 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 725 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 726 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 727 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 728 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 729 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 730 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 731 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 732 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 733 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 734 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 735 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 736 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 737 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 738 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 739 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 740 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 741 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 742 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 743 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 744 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 745 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 746 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 747 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 748 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 749 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 750 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 751 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 752 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 753 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 754 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 755 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 756 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 757 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 758 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 759 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 760 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 761 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 762 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 763 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 764 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 765 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 766 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 767 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 768 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 769 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 770 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 771 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 772 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 773 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 774 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 775 \t| Train loss: 0.135 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 776 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 777 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 778 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 779 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 780 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 781 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 782 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 783 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 784 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 785 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 786 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 787 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 788 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 789 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 790 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 791 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 792 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 793 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 794 \t| Train loss: 0.135 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 795 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 796 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 797 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 798 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 799 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 800 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 801 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 802 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 803 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 804 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 805 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 806 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 807 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 808 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 809 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 810 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 811 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 812 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 813 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 814 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 815 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 816 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 817 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 818 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 819 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 820 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 821 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 822 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 823 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 824 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 825 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 826 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 827 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 828 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 829 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 830 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 831 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 832 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 833 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 834 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 835 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 836 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 837 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 838 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 839 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 840 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 841 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 842 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 843 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 844 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 845 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 846 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 847 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 848 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 849 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 850 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 851 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 852 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 853 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 854 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 855 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 856 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 857 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 858 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 859 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 860 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 861 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 862 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 863 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 864 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 865 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 866 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 867 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 868 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 869 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 870 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 871 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 872 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 873 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 874 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 875 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 876 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 877 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 878 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 879 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 880 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 881 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 882 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 883 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 884 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 885 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 886 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 887 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 888 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 889 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 890 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 891 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 892 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 893 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 894 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 895 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 896 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 897 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 898 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 899 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 900 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 901 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 902 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 903 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 904 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 905 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 906 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 907 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 908 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 909 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 910 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 911 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 912 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 913 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 914 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 915 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 916 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 917 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 918 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 919 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 920 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 921 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 922 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 923 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 924 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 925 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 926 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 927 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 928 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 929 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 930 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 931 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 932 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 933 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 934 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 935 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 936 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 937 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 938 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 939 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 940 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 941 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 942 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 943 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 944 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 945 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 946 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 947 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 948 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 949 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 950 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 951 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 952 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 953 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 954 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 955 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 956 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 957 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 958 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 959 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 960 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 961 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 962 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 963 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 964 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 965 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 966 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 967 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 968 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 969 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 970 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 971 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 972 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 973 \t| Train loss: 0.134 \t| Train acc: 0.75 \t| Test acc: 0.71\n",
      "Epoch: 974 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 975 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 976 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 977 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 978 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 979 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 980 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 981 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 982 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 983 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 984 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 985 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 986 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 987 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 988 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 989 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 990 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 991 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 992 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 993 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 994 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 995 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 996 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 997 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 998 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n",
      "Epoch: 999 \t| Train loss: 0.134 \t| Train acc: 0.74 \t| Test acc: 0.71\n"
     ]
    }
   ],
   "source": [
    "train_losses_mlpsl_lim = []\n",
    "#test_losses  = []\n",
    "train_accs_mlpsl_lim = []\n",
    "test_accs_mlpsl_lim  = []\n",
    "\n",
    "for epoch in range(1000):\n",
    "    # Forward propagation (predicting train data)\n",
    "    for features, labels in data_loader_lim:\n",
    "        train_preds_mlpsl_lim = mlpsl_model_lim(features)\n",
    "        class_weights_batch = class_weights_original[labels.long()]\n",
    "        loss_function = nn.BCELoss(weight=class_weights_batch)\n",
    "\n",
    "        credit_score_mlpsl_lim = features[:, credit_score_index_lim].reshape(-1, 1)\n",
    "        short_term_mlpsl_lim = features[:, short_term_index_lim].reshape(-1, 1)\n",
    "        annual_income_mlpsl_lim = features[:, annual_income_index_lim].reshape(-1, 1)\n",
    "\n",
    "        rule_mlpsl_lim= torch.logical_or(credit_score_mlpsl_lim>3300.5, torch.logical_and(credit_score_mlpsl_lim<=3300.5,torch.logical_and(short_term_mlpsl_lim<=0.5, annual_income_mlpsl_lim<=1405107))).float()\n",
    "        \n",
    "        train_loss_mlpsl_lim = semantic_loss(train_preds_mlpsl_lim, labels, rule_mlpsl_lim, class_weights_batch, 0.025)\n",
    "\n",
    "        # Predicting test data #b\n",
    "        with torch.no_grad():\n",
    "            test_preds_mlpsl_lim = mlpsl_model_lim(X_validation_tensor_lim)\n",
    "            #test_loss  = loss_function(test_preds, y_test)\n",
    "\n",
    "        # Calculate accuracy #c\n",
    "        train_acc = calculate_accuracy(train_preds_mlpsl_lim, labels)\n",
    "        test_acc  = calculate_accuracy(test_preds_mlpsl_lim, y_validation_tensor)\n",
    "\n",
    "        # Backward propagation #d\n",
    "        optimizer_mlpsl_lim.zero_grad()\n",
    "        train_loss_mlpsl_lim.backward()\n",
    "\n",
    "        # Gradient descent step #e\n",
    "        optimizer_mlpsl_lim.step()\n",
    "\n",
    "        # Store training history #f\n",
    "        train_losses_mlpsl_lim.append(train_loss_mlpsl_lim.item())\n",
    "        #test_losses.append(test_loss.item())\n",
    "        train_accs_mlpsl_lim.append(train_acc.item())\n",
    "        test_accs_mlpsl_lim.append(test_acc.item())\n",
    "\n",
    "    # Print training data #g\n",
    "    #if epoch%100==0:\n",
    "    print(f'Epoch: {epoch} \\t|' \\\n",
    "          f' Train loss: {np.round(train_loss_mlpsl_lim.item(),3)} \\t|' \\\n",
    "              #f' Test loss: {np.round(test_loss.item(),3)} \\t|' \\\n",
    "          f' Train acc: {np.round(train_acc.item(),2)} \\t|' \\\n",
    "          f' Test acc: {np.round(test_acc.item(),2)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:43:52.306071300Z",
     "start_time": "2024-05-23T15:43:44.449263900Z"
    }
   },
   "id": "18b704485be63434"
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 71.06%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.816887     0.426331  0.710582     0.621609      0.719516\n",
      "recall        0.791997     0.465443  0.710582     0.628720      0.710582\n",
      "f1-score      0.804249     0.445029  0.710582     0.624639      0.714691\n",
      "support    4923.000000  1635.000000  0.710582  6558.000000   6558.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[3899 1024]\n",
      " [ 874  761]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_nn(y_validation_tensor.clone().detach(), test_preds_mlpsl_lim.clone().detach().round(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:44:06.877325Z",
     "start_time": "2024-05-23T15:44:06.688535500Z"
    }
   },
   "id": "1c050ba10d92f23b"
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 70.83%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.822533     0.416756  0.708321     0.619645      0.723192\n",
      "recall        0.782617     0.479141  0.708321     0.630879      0.708321\n",
      "f1-score      0.802079     0.445776  0.708321     0.623928      0.714850\n",
      "support    5028.000000  1630.000000  0.708321  6658.000000   6658.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[3935 1093]\n",
      " [ 849  781]]\n"
     ]
    }
   ],
   "source": [
    "test_preds_mlpsl_lim = mlpsl_model_lim(X_test_tensor_lim)\n",
    "evaluate_nn(y_test_tensor.clone().detach(), test_preds_mlpsl_lim.clone().detach().round(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:44:20.182002200Z",
     "start_time": "2024-05-23T15:44:20.056177Z"
    }
   },
   "id": "f5765a21efc815b3"
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 72.36%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.819055     0.436823  0.723641     0.627939      0.725478\n",
      "recall        0.813842     0.445399  0.723641     0.629621      0.723641\n",
      "f1-score      0.816441     0.441069  0.723641     0.628755      0.724543\n",
      "support    5028.000000  1630.000000  0.723641  6658.000000   6658.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[4092  936]\n",
      " [ 904  726]]\n"
     ]
    }
   ],
   "source": [
    "dt_model_lim = DecisionTreeClassifier(class_weight='balanced')\n",
    "# Fit the model using X_train and y_train\n",
    "dt_model_lim.fit(X_train_lim_scaled, y_train_lim)\n",
    "\n",
    "predictions_dt_lim = dt_model_lim.predict(X_test_lim_scaled)\n",
    "\n",
    "evaluate_nn(y_test_tensor.clone().detach(), predictions_dt_lim.round(), train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:54:07.653772500Z",
     "start_time": "2024-05-23T15:54:07.449499300Z"
    }
   },
   "id": "2a1aa0deb4d47cf0"
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 73.93%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0.0          1.0  accuracy    macro avg  weighted avg\n",
      "precision     0.815205     0.463092  0.739261     0.639148      0.729001\n",
      "recall        0.846659     0.407975  0.739261     0.627317      0.739261\n",
      "f1-score      0.830634     0.433790  0.739261     0.632212      0.733479\n",
      "support    5028.000000  1630.000000  0.739261  6658.000000   6658.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[4257  771]\n",
      " [ 965  665]]\n"
     ]
    }
   ],
   "source": [
    "# Define the XGBoost classifier\n",
    "xgb_model_lim = xgb.XGBClassifier(scale_pos_weight=(len(y_train_lim) - sum(y_train_lim)) / sum(y_train_lim))\n",
    "\n",
    "# Fit the model using X_train_scaled and y_train\n",
    "xgb_model_lim.fit(X_train_lim_scaled, y_train_lim)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions_xgb_lim = xgb_model_lim.predict(X_test_lim_scaled)\n",
    "\n",
    "evaluate_nn(y_test_tensor.clone().detach(), predictions_xgb_lim.round(), train=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:54:23.250670200Z",
     "start_time": "2024-05-23T15:54:22.984020700Z"
    }
   },
   "id": "8c8399f32b0ae82b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating conformal predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67b15a4e0faa64c8"
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [],
   "source": [
    "n = len(X_train)\n",
    "#get the probability predictions\n",
    "predictions = sl_model(X_calibration_tensor)\n",
    "#get the probability for the true class\n",
    "true_class_probs = torch.where(y_calibration_tensor == 1, predictions, 1 - predictions)\n",
    "#Turn scores into uncertainty score\n",
    "scores = 1-true_class_probs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T16:04:21.081927100Z",
     "start_time": "2024-05-23T16:04:21.018785800Z"
    }
   },
   "id": "8cf7f84656fda39"
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [],
   "source": [
    "#Setting the alpha value\n",
    "alpha = 0.05\n",
    "\n",
    "# define quantile\n",
    "q_level = np.ceil((n+1)*(1-alpha))/n\n",
    "qhat = np.quantile(scores.detach().numpy(), q_level, method='higher')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T16:04:21.615136800Z",
     "start_time": "2024-05-23T16:04:21.567981Z"
    }
   },
   "id": "be55d1f8b34108ce"
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(scores.detach().numpy(), bins=30, range=(0, 1))\n",
    "plt.xlabel(\"1 - s(y,x)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of non-conformity scores\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T16:04:22.550591200Z",
     "start_time": "2024-05-23T16:04:22.265606500Z"
    }
   },
   "id": "9529b61016f51223"
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off'], ['Charged Off'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid'], ['Charged Off', 'Fully Paid']]\n"
     ]
    }
   ],
   "source": [
    "prediction_sets = []\n",
    "\n",
    "# Iterating through the probabilities tensor\n",
    "for prob in test_preds_sl:\n",
    "    prediction_set = []\n",
    "    if prob < qhat:\n",
    "        prediction_set.append(\"Charged Off\")\n",
    "    if 1 - prob < qhat:\n",
    "        prediction_set.append(\"Fully Paid\")\n",
    "    prediction_sets.append(prediction_set)\n",
    "\n",
    "print(prediction_sets)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T16:04:23.822785400Z",
     "start_time": "2024-05-23T16:04:22.975835300Z"
    }
   },
   "id": "e204841bc49da198"
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prediction sets of length 1: 2697\n",
      "Number of prediction sets of length 2: 3961\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters for sets of length 1 and length 2\n",
    "count_length_1 = 0\n",
    "count_length_2 = 0\n",
    "\n",
    "# Iterate through the prediction_sets list\n",
    "for prediction_set in prediction_sets:\n",
    "    if len(prediction_set) == 1:\n",
    "        count_length_1 += 1\n",
    "    elif len(prediction_set) == 2:\n",
    "        count_length_2 += 1\n",
    "\n",
    "print(\"Number of prediction sets of length 1:\", count_length_1)\n",
    "print(\"Number of prediction sets of length 2:\", count_length_2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T16:04:23.852525300Z",
     "start_time": "2024-05-23T16:04:23.822785400Z"
    }
   },
   "id": "144f9067a73ba6b6"
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(2957)"
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(credit_score>3300.5).sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T16:23:02.723451Z",
     "start_time": "2024-05-23T16:23:02.645690700Z"
    }
   },
   "id": "1e236d279f9f65d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
